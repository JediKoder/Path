我們使用統計學在很多不同的方式在數據科學裡。 在這堂課中，我想更新您對假設檢定(hypothesis testing)的認識， 這是實驗背後的核心數據分析活動。 我們開始看到使用實驗越來越普遍 在學術科學之外，以及在日常業務環境中。 部分原因是，大數據(big data)和電子商務的興起。 現在您可以容易的更改數位店面， 並為您的某些客戶提供不同的體驗， 然後查看這些客戶反應可能會如何彼此不同。 例如，如果您銷售圖書，您可能希望有一個情況，其中該 圖書的封面在網頁上突出顯示， 另一個情況是焦點在作者和該書的評論。 這通常被稱為A/B測試。 雖然這在歷史上並不是獨一無二的，但現在變得越來越普遍， 如果你使用的是一個網站，那麼你無疑是A/B測試的一部分。 這就引起了一些有趣的道德問題，我已經添加到閱讀 課程資源，我想鼓勵你去看看， 參加討論，但讓我們重新回到統計上。 假設(Hypothesis)，是我們可以測試的聲明。 我舉一個例子，從我自己的研究領域的教育技術和 學習分析。 假設我們有一個期待，當新課程在MOOC平台上推出時， 最敏銳的學生就會發現了，並且都會湧向它。 因此，我們可能會想，那些很快報名的學生 當課程開始時，將會有更高的表現，比那些 MOOC課程已經存在一段時間之後報名的的學生。 在此示例中，我們有我們想要比較的兩個不同組的樣本。 早期註冊和晚期註冊。 當我們進行假設檢測時，我們堅持認為我們的假設是對立(alternative)假設， 我們創建了一個稱為零假設(null hypothesis)的第二個假設， 在這零假設情況下，這兩組之間沒有區別。 然後我們檢查這兩組以確定這個零假設 真實與否。 如果我們發現群體之間存在差異， 那麼我們可以拋棄零假設，而接受我們的對立假設 在這個描述中有微妙之處。 我們不是說我們的假設是對的，而 我們說的是有證據反對零(null)假設。 所以，我們對我們的對立(alternative)假設更有信心。 我們來看個例子 我們可以加載一個名為grade.csv的文件。 如果我們在裡面看看DataFrame， 我們看到我們有六個不同的作業， 每個作業都有一個提交時間。 而且這個數據文件中似乎3,000項以下。 為了這講座的目的，我們把這個群體分成兩部分。 那些在2015年12月底之前完成第一個作業的人 和那些在那段時間之後完成的人。 我編造了這個日期，它給了我們兩個DataFrames， 大致是大小相同的。 如您所見，pandas DataFrame物件有各種各樣的統計 函數與之相關聯。 如果我們直接在DataFrame上調用平均值(mean)函數， 那麼我們可以看到每個平均值在每個作業都被計算出來。 請注意，datetime值將被忽略，Pandas都知道這不是一個數字， 而是一個物件類型。 如果我們看看late DataFrame的平均值 ，我們會得到驚人的相似數字。 雖然有微小的差異。 它看起來像六個作業的結束， 早期的學生做的好一點，大概一個百分點。 那麼，這是否足以繼續下去，做一些干預，以實際的方式來嘗試和 改變一些東西在我們的授課的方式？ 在進行假設檢驗時，我們必須選擇一個顯著(significance)程度(level)作為門檻， 表示多少或然性我們願意接受。 這個顯著程度通常稱為alpha(α)。 它可能會差別很大，這取決於你的結果將要拿來做什麼和 數據中你預期的雜訊量。 例如，在社會科學研究中，通常使用0.05或 0.01的值，這表明寬限在 概率5％到1％的或然性之間。 在物理實驗中，條件受到更多的控制， 因此，舉證責任要高得多，您可能預期看到alpha 層級到十的負五次方，或是十萬分之一。 你也可以從干預觀點來想顯著程度， 這是我經常在我的研究中遇到的問題。 我該怎麼辦時，我發現兩個學生群體是不同的？ 例如，如果我要發送一個輕推的電子郵件來鼓勵學生 繼續努力作作業，那是一個非常低成本的干預。 電子郵件很便宜，而我當然不想惹惱學生， 一個額外的電子郵件不會破壞他們的一天。 但是，如果干預是有點要更多功夫， 好比我們助教與學生通過電話隨訪？ 這突然變得更加昂貴對於機構和 學生 所以，我可能想需要確保更高的舉證責任。 所以你設置的門檻 alpha取決於你的結果將要拿來做什麼。 對於這個例子，我們使用一個0.05的門檻作為我們的alpha，或5％。 現在，我們怎麼實際上來測試這些平均值是否在Python中不同？ SciPy程式庫包含許多不同的統計測試，並且 構成了Python中假設檢定的基礎。 t-test是比較兩種不同種群的平均值(mean)的一種方式。 在SciPy程式庫中，ttest_ind函數將 比較兩個獨立的樣本，看看它們是否有不同的平均值(mean)。 我不會在這裡進行任何這種統計測試的細節， 但是我們建議您查看維基百科頁面上的特定測試， 或考慮上一個完整的統計學課程，如果這是你不熟悉的。 但是我想要注意的是，大多數統計測試都需要 數據符合一定的分佈形狀。 所以你不應該盲目地應用這些測試，首先要調查你的數據。 如果我們想要比較作業的分數 在這兩個群體之間的第一個作業，我們可以產生t-test 將這兩個系列傳遞給ttest_ind函數。 結果是測試統計量(t-statistic)和p值(p-value)的元組(tuple)。 此處的p值是遠遠大於我們的0.05。 所以我們不能拋棄null假設， null假設就是說這兩個群體是一樣的。 在更專業術語，我們會說 沒有統計學上的顯著差異，在這兩個樣本的平均值。 讓我們檢查第二個作業分數。 不，這也是遠遠大於0.05。 作業三怎麼樣呢？ 這更接近了，但仍然超出我們的門檻。 重要的是要停下來，談論嚴重的過程問題，我們如何處理 這兩個群體之間差異的調查。 當我們將alpha設置為0.05時，我們說我們期望它 會有正面結果，5％的時候純粹因為偶然機會。 隨著我們運行越來越多的t-test，我們更有可能找到一個正面的結果， 只是因為我們運行的t-test的數量。 當數據科學家以這種方式進行許多測試時，它被稱為p-hacking或 疏浚(dredging)，這是一個嚴重的方法問題。 P-hacking導致虛假的相關性，而不是一般化的結果。 有幾種不同的方式來處理p-hacking。 第一個被稱為Bonferroni校正。 在這種情況下，您只需緊縮您的Alpha值， 即顯著性的門檻，按照您運行的測試次數。 所以如果你選擇了0.05在一個測試，而你想運行3個測試， 你減少alpha，用0.05乘三分之一，得到一個新的值0.01多 我個人覺得這個做法非常保守。 另一個選擇是，保留您的一些數據進行 測試，以了解您的結果有多一般化。 在這種情況下，我們可能會採用一半我們的數據 在每個DataFrames，用這一半運行我們的t-test， 建立具體的假設，基於這些測試的結果， 然後用其餘的數據，運行非常有限的測試。 這種方法實際上被大量地用於機器學習， 當構建預測模型時，它稱為交叉(cross fold)驗證(validation)， 您將在此專業化的第三課程中更多地了解這一點。 最後一種方法來的是，預先登記你的實驗。 在此步驟中，您將概述您期望找到的內容以及為什麼， 並描述此測試，它將提供一個積極的證明。 您與第三方註冊，在學術界這通常是一個刊物。 他們決定要運行的測試是否合理。 你然後運行你的研究和報告它的結果， 無論它們是否是肯定的。 在這裡有一個更大的負擔來連接到現有的理論， 因為你需要說服審閱者，實驗非常可能完全的測試了 你給定的假設。 在這堂課， 我們只是討論了一些在Python中基本的假設測試。 我向您介紹了SciPy程式庫，您可以用它來進行t-test。 我們討論了一些實際的問題，源自於尋找 在統計學上來講的顯著性。 還有更多假設測試要學習。 例如，不同的測試方法， 取決於數據的形狀，以及不同的方法報告結果， 而不僅僅是p-value，例如置信區間(confidence interval)。 但是，我希望這可以讓您開始比較平均值在兩個 不同群體，對於數據科學家來說是一項常見的任務， 我們將在本系列的第二個課程中跟進一些這方面的工作。 這堂課還完成了第一門的課程 在Python專業化應用數據科學。 我們已經涵蓋基本的Python程式設計， 一些更高級的功能如map、lambda和列表(list)推導。 如何使用Pandas程式庫讀取和操作數據，包括查詢， 加入，分組和處理DataFrames以及建立樞紐分析表(pivot table)。 現在我們已經討論了一些在Python中的統計學， 並深入到了NumPy和SciPy 工具庫中。 在接下來的課程中，我們將討論數據的繪圖和圖表。 使用更多統計數據，以及我們如何向他人呈現數據， 以及我們如何用我們的數據建立一個令人信服的故事。 我們下回再見。