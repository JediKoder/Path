1
00:00:08,965 --> 00:00:12,550
我們使用統計學在很多不同的方式在數據科學裡。

2
00:00:12,550 --> 00:00:17,019
在這堂課中，我想更新您對假設檢定(hypothesis testing)的認識，

3
00:00:17,019 --> 00:00:20,995
這是實驗背後的核心數據分析活動。

4
00:00:20,995 --> 00:00:25,157
我們開始看到使用實驗越來越普遍

5
00:00:25,157 --> 00:00:29,838
在學術科學之外，以及在日常業務環境中。

6
00:00:29,838 --> 00:00:34,510
部分原因是，大數據(big data)和電子商務的興起。

7
00:00:34,510 --> 00:00:37,300
現在您可以容易的更改數位店面，

8
00:00:37,300 --> 00:00:40,620
並為您的某些客戶提供不同的體驗，

9
00:00:40,620 --> 00:00:44,560
然後查看這些客戶反應可能會如何彼此不同。

10
00:00:44,560 --> 00:00:49,298
例如，如果您銷售圖書，您可能希望有一個情況，其中該

11
00:00:49,298 --> 00:00:51,565
圖書的封面在網頁上突出顯示，

12
00:00:51,565 --> 00:00:55,984
另一個情況是焦點在作者和該書的評論。

13
00:00:55,984 --> 00:00:58,382
這通常被稱為A/B測試。

14
00:00:58,382 --> 00:01:03,246
雖然這在歷史上並不是獨一無二的，但現在變得越來越普遍，

15
00:01:03,246 --> 00:01:07,918
如果你使用的是一個網站，那麼你無疑是A/B測試的一部分。

16
00:01:07,918 --> 00:01:12,378
這就引起了一些有趣的道德問題，我已經添加到閱讀

17
00:01:12,378 --> 00:01:16,558
課程資源，我想鼓勵你去看看，

18
00:01:16,558 --> 00:01:20,410
參加討論，但讓我們重新回到統計上。

19
00:01:21,470 --> 00:01:24,347
假設(Hypothesis)，是我們可以測試的聲明。

20
00:01:24,347 --> 00:01:28,542
我舉一個例子，從我自己的研究領域的教育技術和

21
00:01:28,542 --> 00:01:29,858
學習分析。

22
00:01:29,858 --> 00:01:34,567
假設我們有一個期待，當新課程在MOOC平台上推出時，

23
00:01:34,567 --> 00:01:38,739
最敏銳的學生就會發現了，並且都會湧向它。

24
00:01:38,739 --> 00:01:42,507
因此，我們可能會想，那些很快報名的學生

25
00:01:42,507 --> 00:01:45,487
當課程開始時，將會有更高的表現，比那些

26
00:01:45,487 --> 00:01:48,850
MOOC課程已經存在一段時間之後報名的的學生。

27
00:01:48,850 --> 00:01:53,469
在此示例中，我們有我們想要比較的兩個不同組的樣本。

28
00:01:53,469 --> 00:01:55,740
早期註冊和晚期註冊。

29
00:01:56,940 --> 00:02:02,980
當我們進行假設檢測時，我們堅持認為我們的假設是對立(alternative)假設，

30
00:02:02,980 --> 00:02:07,010
我們創建了一個稱為零假設(null hypothesis)的第二個假設，

31
00:02:07,010 --> 00:02:11,100
在這零假設情況下，這兩組之間沒有區別。

32
00:02:11,100 --> 00:02:14,820
然後我們檢查這兩組以確定這個零假設

33
00:02:14,820 --> 00:02:15,430
真實與否。

34
00:02:16,560 --> 00:02:19,371
如果我們發現群體之間存在差異，

35
00:02:19,371 --> 00:02:23,064
那麼我們可以拋棄零假設，而接受我們的對立假設

36
00:02:23,064 --> 00:02:25,035
在這個描述中有微妙之處。

37
00:02:25,035 --> 00:02:28,553
我們不是說我們的假設是對的，而

38
00:02:28,553 --> 00:02:32,822
我們說的是有證據反對零(null)假設。

39
00:02:32,822 --> 00:02:37,396
所以，我們對我們的對立(alternative)假設更有信心。

40
00:02:37,396 --> 00:02:39,685
我們來看個例子

41
00:02:39,685 --> 00:02:42,885
我們可以加載一個名為grade.csv的文件。

42
00:02:42,885 --> 00:02:45,008
如果我們在裡面看看DataFrame，

43
00:02:45,008 --> 00:02:47,203
我們看到我們有六個不同的作業，

44
00:02:47,203 --> 00:02:49,258
每個作業都有一個提交時間。

45
00:02:49,258 --> 00:02:53,853
而且這個數據文件中似乎3,000項以下。

46
00:02:53,853 --> 00:02:58,470
為了這講座的目的，我們把這個群體分成兩部分。

47
00:02:58,470 --> 00:03:01,650
那些在2015年12月底之前完成第一個作業的人

48
00:03:01,650 --> 00:03:04,340
和那些在那段時間之後完成的人。

49
00:03:05,470 --> 00:03:08,120
我編造了這個日期，它給了我們兩個DataFrames，

50
00:03:08,120 --> 00:03:09,530
大致是大小相同的。

51
00:03:11,010 --> 00:03:14,770
如您所見，pandas DataFrame物件有各種各樣的統計

52
00:03:14,770 --> 00:03:17,210
函數與之相關聯。

53
00:03:17,210 --> 00:03:19,860
如果我們直接在DataFrame上調用平均值(mean)函數，

54
00:03:19,860 --> 00:03:22,579
那麼我們可以看到每個平均值在每個作業都被計算出來。

55
00:03:23,640 --> 00:03:28,488
請注意，datetime值將被忽略，Pandas都知道這不是一個數字，

56
00:03:28,488 --> 00:03:29,692
而是一個物件類型。

57
00:03:29,692 --> 00:03:33,165
如果我們看看late DataFrame的平均值

58
00:03:33,165 --> 00:03:35,468
，我們會得到驚人的相似數字。

59
00:03:35,468 --> 00:03:37,180
雖然有微小的差異。

60
00:03:37,180 --> 00:03:39,430
它看起來像六個作業的結束，

61
00:03:39,430 --> 00:03:42,400
早期的學生做的好一點，大概一個百分點。

62
00:03:43,400 --> 00:03:47,100
那麼，這是否足以繼續下去，做一些干預，以實際的方式來嘗試和

63
00:03:47,100 --> 00:03:50,180
改變一些東西在我們的授課的方式？

64
00:03:50,180 --> 00:03:55,370
在進行假設檢驗時，我們必須選擇一個顯著(significance)程度(level)作為門檻，

65
00:03:55,370 --> 00:03:58,930
表示多少或然性我們願意接受。

66
00:03:58,930 --> 00:04:02,140
這個顯著程度通常稱為alpha(α)。

67
00:04:02,140 --> 00:04:05,890
它可能會差別很大，這取決於你的結果將要拿來做什麼和

68
00:04:05,890 --> 00:04:07,850
數據中你預期的雜訊量。

69
00:04:08,870 --> 00:04:13,221
例如，在社會科學研究中，通常使用0.05或

70
00:04:13,221 --> 00:04:17,940
0.01的值，這表明寬限在

71
00:04:17,940 --> 00:04:22,350
概率5％到1％的或然性之間。

72
00:04:22,350 --> 00:04:25,490
在物理實驗中，條件受到更多的控制，

73
00:04:25,490 --> 00:04:29,320
因此，舉證責任要高得多，您可能預期看到alpha

74
00:04:29,320 --> 00:04:33,590
層級到十的負五次方，或是十萬分之一。

75
00:04:35,490 --> 00:04:40,280
你也可以從干預觀點來想顯著程度，

76
00:04:40,280 --> 00:04:44,165
這是我經常在我的研究中遇到的問題。

77
00:04:44,165 --> 00:04:48,637
我該怎麼辦時，我發現兩個學生群體是不同的？

78
00:04:48,637 --> 00:04:52,076
例如，如果我要發送一個輕推的電子郵件來鼓勵學生

79
00:04:52,076 --> 00:04:56,720
繼續努力作作業，那是一個非常低成本的干預。

80
00:04:56,720 --> 00:05:00,540
電子郵件很便宜，而我當然不想惹惱學生，

81
00:05:00,540 --> 00:05:03,140
一個額外的電子郵件不會破壞他們的一天。

82
00:05:03,140 --> 00:05:06,101
但是，如果干預是有點要更多功夫，

83
00:05:06,101 --> 00:05:09,885
好比我們助教與學生通過電話隨訪？

84
00:05:09,885 --> 00:05:13,189
這突然變得更加昂貴對於機構和

85
00:05:13,189 --> 00:05:13,834
學生

86
00:05:13,834 --> 00:05:16,430
所以，我可能想需要確保更高的舉證責任。

87
00:05:17,530 --> 00:05:19,187
所以你設置的門檻

88
00:05:19,187 --> 00:05:22,868
alpha取決於你的結果將要拿來做什麼。

89
00:05:22,868 --> 00:05:29,181
對於這個例子，我們使用一個0.05的門檻作為我們的alpha，或5％。

90
00:05:29,181 --> 00:05:33,693
現在，我們怎麼實際上來測試這些平均值是否在Python中不同？

91
00:05:33,693 --> 00:05:37,782
SciPy程式庫包含許多不同的統計測試，並且

92
00:05:37,782 --> 00:05:40,584
構成了Python中假設檢定的基礎。

93
00:05:40,584 --> 00:05:45,060
t-test是比較兩種不同種群的平均值(mean)的一種方式。

94
00:05:45,060 --> 00:05:48,444
在SciPy程式庫中，ttest_ind函數將

95
00:05:48,444 --> 00:05:53,210
比較兩個獨立的樣本，看看它們是否有不同的平均值(mean)。

96
00:05:53,210 --> 00:05:56,721
我不會在這裡進行任何這種統計測試的細節，

97
00:05:56,721 --> 00:06:01,247
但是我們建議您查看維基百科頁面上的特定測試，

98
00:06:01,247 --> 00:06:06,072
或考慮上一個完整的統計學課程，如果這是你不熟悉的。

99
00:06:06,072 --> 00:06:09,637
但是我想要注意的是，大多數統計測試都需要

100
00:06:09,637 --> 00:06:13,071
數據符合一定的分佈形狀。

101
00:06:13,071 --> 00:06:19,098
所以你不應該盲目地應用這些測試，首先要調查你的數據。

102
00:06:19,098 --> 00:06:21,649
如果我們想要比較作業的分數

103
00:06:21,649 --> 00:06:26,012
在這兩個群體之間的第一個作業，我們可以產生t-test

104
00:06:26,012 --> 00:06:29,182
將這兩個系列傳遞給ttest_ind函數。

105
00:06:29,182 --> 00:06:33,144
結果是測試統計量(t-statistic)和p值(p-value)的元組(tuple)。

106
00:06:33,144 --> 00:06:36,887
此處的p值是遠遠大於我們的0.05。

107
00:06:36,887 --> 00:06:39,591
所以我們不能拋棄null假設，

108
00:06:39,591 --> 00:06:42,690
null假設就是說這兩個群體是一樣的。

109
00:06:42,690 --> 00:06:45,349
在更專業術語，我們會說

110
00:06:45,349 --> 00:06:49,721
沒有統計學上的顯著差異，在這兩個樣本的平均值。

111
00:06:49,721 --> 00:06:51,413
讓我們檢查第二個作業分數。

112
00:06:58,037 --> 00:07:01,118
不，這也是遠遠大於0.05。

113
00:07:01,118 --> 00:07:02,639
作業三怎麼樣呢？

114
00:07:08,857 --> 00:07:13,191
這更接近了，但仍然超出我們的門檻。

115
00:07:13,191 --> 00:07:17,832
重要的是要停下來，談論嚴重的過程問題，我們如何處理

116
00:07:17,832 --> 00:07:22,557
這兩個群體之間差異的調查。

117
00:07:22,557 --> 00:07:27,424
當我們將alpha設置為0.05時，我們說我們期望它

118
00:07:27,424 --> 00:07:31,280
會有正面結果，5％的時候純粹因為偶然機會。

119
00:07:32,440 --> 00:07:36,880
隨著我們運行越來越多的t-test，我們更有可能找到一個正面的結果，

120
00:07:36,880 --> 00:07:39,250
只是因為我們運行的t-test的數量。

121
00:07:40,340 --> 00:07:44,853
當數據科學家以這種方式進行許多測試時，它被稱為p-hacking或

122
00:07:44,853 --> 00:07:48,039
疏浚(dredging)，這是一個嚴重的方法問題。

123
00:07:48,039 --> 00:07:54,875
P-hacking導致虛假的相關性，而不是一般化的結果。

124
00:07:54,875 --> 00:07:57,684
有幾種不同的方式來處理p-hacking。

125
00:07:57,684 --> 00:08:00,490
第一個被稱為Bonferroni校正。

126
00:08:00,490 --> 00:08:03,187
在這種情況下，您只需緊縮您的Alpha值，

127
00:08:03,187 --> 00:08:07,187
即顯著性的門檻，按照您運行的測試次數。

128
00:08:07,187 --> 00:08:12,130
所以如果你選擇了0.05在一個測試，而你想運行3個測試，

129
00:08:12,130 --> 00:08:19,406
你減少alpha，用0.05乘三分之一，得到一個新的值0.01多

130
00:08:19,406 --> 00:08:23,400
我個人覺得這個做法非常保守。

131
00:08:23,400 --> 00:08:26,639
另一個選擇是，保留您的一些數據進行

132
00:08:26,639 --> 00:08:29,799
測試，以了解您的結果有多一般化。

133
00:08:29,799 --> 00:08:32,550
在這種情況下，我們可能會採用一半我們的數據

134
00:08:32,550 --> 00:08:35,741
在每個DataFrames，用這一半運行我們的t-test，

135
00:08:35,741 --> 00:08:39,435
建立具體的假設，基於這些測試的結果，

136
00:08:39,435 --> 00:08:42,500
然後用其餘的數據，運行非常有限的測試。

137
00:08:43,540 --> 00:08:46,400
這種方法實際上被大量地用於機器學習，

138
00:08:46,400 --> 00:08:50,410
當構建預測模型時，它稱為交叉(cross fold)驗證(validation)，

139
00:08:50,410 --> 00:08:53,740
您將在此專業化的第三課程中更多地了解這一點。

140
00:08:55,270 --> 00:08:59,240
最後一種方法來的是，預先登記你的實驗。

141
00:09:00,400 --> 00:09:04,060
在此步驟中，您將概述您期望找到的內容以及為什麼，

142
00:09:04,060 --> 00:09:08,120
並描述此測試，它將提供一個積極的證明。

143
00:09:08,120 --> 00:09:12,150
您與第三方註冊，在學術界這通常是一個刊物。

144
00:09:12,150 --> 00:09:14,330
他們決定要運行的測試是否合理。

145
00:09:15,360 --> 00:09:17,707
你然後運行你的研究和報告它的結果，

146
00:09:17,707 --> 00:09:20,299
無論它們是否是肯定的。

147
00:09:20,299 --> 00:09:25,060
在這裡有一個更大的負擔來連接到現有的理論，

148
00:09:25,060 --> 00:09:29,661
因為你需要說服審閱者，實驗非常可能完全的測試了

149
00:09:29,661 --> 00:09:31,531
你給定的假設。

150
00:09:31,531 --> 00:09:32,611
在這堂課，

151
00:09:32,611 --> 00:09:37,147
我們只是討論了一些在Python中基本的假設測試。

152
00:09:37,147 --> 00:09:41,421
我向您介紹了SciPy程式庫，您可以用它來進行t-test。

153
00:09:41,421 --> 00:09:44,384
我們討論了一些實際的問題，源自於尋找

154
00:09:44,384 --> 00:09:46,420
在統計學上來講的顯著性。

155
00:09:46,420 --> 00:09:49,240
還有更多假設測試要學習。

156
00:09:49,240 --> 00:09:51,120
例如，不同的測試方法，

157
00:09:51,120 --> 00:09:53,800
取決於數據的形狀，以及不同的方法報告結果，

158
00:09:53,800 --> 00:09:57,610
而不僅僅是p-value，例如置信區間(confidence interval)。

159
00:09:57,610 --> 00:10:00,450
但是，我希望這可以讓您開始比較平均值在兩個

160
00:10:00,450 --> 00:10:03,772
不同群體，對於數據科學家來說是一項常見的任務，

161
00:10:03,772 --> 00:10:07,239
我們將在本系列的第二個課程中跟進一些這方面的工作。

162
00:10:09,320 --> 00:10:11,731
這堂課還完成了第一門的課程

163
00:10:11,731 --> 00:10:15,735
在Python專業化應用數據科學。

164
00:10:15,735 --> 00:10:18,350
我們已經涵蓋基本的Python程式設計，

165
00:10:18,350 --> 00:10:22,199
一些更高級的功能如map、lambda和列表(list)推導。

166
00:10:22,199 --> 00:10:26,827
如何使用Pandas程式庫讀取和操作數據，包括查詢，

167
00:10:26,827 --> 00:10:31,538
加入，分組和處理DataFrames以及建立樞紐分析表(pivot table)。

168
00:10:31,538 --> 00:10:35,398
現在我們已經討論了一些在Python中的統計學，

169
00:10:35,398 --> 00:10:38,274
並深入到了NumPy和SciPy 工具庫中。

170
00:10:38,274 --> 00:10:41,717
在接下來的課程中，我們將討論數據的繪圖和圖表。

171
00:10:41,717 --> 00:10:45,056
使用更多統計數據，以及我們如何向他人呈現數據，

172
00:10:45,056 --> 00:10:48,160
以及我們如何用我們的數據建立一個令人信服的故事。

173
00:10:48,160 --> 00:10:48,690
我們下回再見。