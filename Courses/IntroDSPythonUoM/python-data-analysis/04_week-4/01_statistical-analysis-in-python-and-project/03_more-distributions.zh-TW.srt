1
00:00:08,895 --> 00:00:13,571
許多分佈(distribition)你在數據科學中使用的不是離散的二項式(binomial)，

2
00:00:13,571 --> 00:00:17,631
而是連續的，其中的觀察值

3
00:00:17,631 --> 00:00:21,852
不是頭或尾，而可以表示為實數。

4
00:00:21,852 --> 00:00:25,959
在討論這些分佈時，通常會將這些分佈進行圖形化，

5
00:00:25,959 --> 00:00:28,741
其中x軸是觀察值，

6
00:00:28,741 --> 00:00:33,000
y軸代表給定的觀察發生的概率。

7
00:00:34,030 --> 00:00:38,040
如果所有的數字有同樣的可能性被抽選，當取樣時，

8
00:00:38,040 --> 00:00:41,050
應將其畫成水平線。

9
00:00:41,050 --> 00:00:44,519
而這條平線實際上被稱為均勻(uniform)分佈。

10
00:00:45,670 --> 00:00:48,910
還有其他幾個更有趣的分佈。

11
00:00:48,910 --> 00:00:52,910
我們來看一下常態(normal)分佈，也稱為高斯(Gaussian)分佈，

12
00:00:52,910 --> 00:00:54,470
有時，一個鐘形(bell)曲線。

13
00:00:55,570 --> 00:00:58,490
該分佈看起來像一個駝峰，其中數字

14
00:00:58,490 --> 00:01:01,650
繪製在概率最高的地方為零，

15
00:01:01,650 --> 00:01:05,030
並且有兩個遞減曲線在X軸的任一側上。

16
00:01:06,250 --> 00:01:09,930
這種分佈的特徵之一是平均值(mean)為零，

17
00:01:09,930 --> 00:01:12,360
兩邊的兩條曲線是對稱的。

18
00:01:12,360 --> 00:01:16,540
我想向你介紹一下期望(expected)值。

19
00:01:16,540 --> 00:01:20,210
我認為我們大多數人都熟悉的平均值是，所有值的總和

20
00:01:20,210 --> 00:01:22,790
除以值的總數量。

21
00:01:22,790 --> 00:01:26,166
計算平均值是一個計算過程，

22
00:01:26,166 --> 00:01:29,418
它通過查看樣本的分佈來進行。

23
00:01:29,418 --> 00:01:33,950
例如擲骰子三次，可能會給你的數位1，

24
00:01:33,950 --> 00:01:37,266
2和6，平均值是4.5。

25
00:01:37,266 --> 00:01:42,701
預期值是從基本的分佈的概率。它是

26
00:01:42,701 --> 00:01:47,910
骰子點數的平均值，如果我們做了無限數次的擲骰子。

27
00:01:47,910 --> 00:01:53,660
結果是3.5，因為骰子的每個面都同樣可能出現。

28
00:01:53,660 --> 00:01:56,089
因此預期值是3.5，

29
00:01:56,089 --> 00:02:00,620
雖然平均值取決於我們已經採取的樣本，它

30
00:02:00,620 --> 00:02:05,260
將匯集到預期值，如果有一個足夠大的樣本集。

31
00:02:05,260 --> 00:02:08,080
我們將在第三課中詳細討論預期值。

32
00:02:08,080 --> 00:02:10,600
第二個屬性

33
00:02:10,600 --> 00:02:15,490
是分佈的變異數(variance)可以用某種方式來描述。

34
00:02:15,490 --> 00:02:22,152
變異數是衡量樣本值從平均值擴散攤開多寬的度量。

35
00:02:22,152 --> 00:02:26,376
讓我們更加正式地分析五種不同的特徵

36
00:02:26,376 --> 00:02:27,368
在分佈(distribution)上。

37
00:02:27,368 --> 00:02:31,453
首先，我們可以談論分佈的中心集中趨勢，

38
00:02:31,453 --> 00:02:36,510
我們為此使用的衡量是，模式(mode),中位數(median)或平均值(mean)。

39
00:02:36,510 --> 00:02:40,360
這一特性實際上是:大部分的概率是在哪裡的

40
00:02:40,360 --> 00:02:41,729
分佈(distribution)上。

41
00:02:42,900 --> 00:02:46,030
我們也可以談在分佈變異性。

42
00:02:46,030 --> 00:02:49,070
有幾種方法我們可以說這個。

43
00:02:49,070 --> 00:02:52,660
標準差(Standard deviation)是一個，四分之一的範圍(interquartile range)是另一個。

44
00:02:52,660 --> 00:02:57,500
標準差衡量我們樣本中每個項目

45
00:02:57,500 --> 00:02:59,530
與平均值的差異程度。

46
00:03:00,720 --> 00:03:02,520
這裡是標準差的計算公式。

47
00:03:04,040 --> 00:03:07,810
它可能看起來比它實際上更加嚇人

48
00:03:07,810 --> 00:03:10,296
讓我們來看看我們如何寫這個。

49
00:03:10,296 --> 00:03:14,806
我們從正態分佈中抽取1000個樣本，

50
00:03:14,806 --> 00:03:19,156
預期值為0.75，標準偏差為1.

51
00:03:19,156 --> 00:03:23,840
然後使用NumPy的mean特徵計算實際平均值。

52
00:03:23,840 --> 00:03:28,535
總結中的部分表示xi-xbar。

53
00:03:28,535 --> 00:03:32,620
Xi是列表中的當前項，xbar是平均值。

54
00:03:32,620 --> 00:03:35,660
所以我們計算差額，然後我們平方該結果，

55
00:03:35,660 --> 00:03:37,090
然後我們總和所有這些。

56
00:03:38,130 --> 00:03:42,250
這可能是合理的地方來使用map，並應用lambda來計算

57
00:03:42,250 --> 00:03:45,480
平均值和測量樣本值之間的差異，

58
00:03:45,480 --> 00:03:49,620
然後將其轉換回列表，因此NumPy可以使用它。

59
00:03:49,620 --> 00:03:55,140
現在我們只需要對每個值進行平方，將它們相加在一起，並取平方根。

60
00:03:55,140 --> 00:03:58,087
這就是我們的標準差的大小。

61
00:03:58,087 --> 00:04:01,199
它占地大約68%平均值的周圍地區，

62
00:04:01,199 --> 00:04:04,560
均勻分佈在平均值的兩邊。

63
00:04:04,560 --> 00:04:08,057
現在，我們通常不需要自己做所有這些工作，但

64
00:04:08,057 --> 00:04:11,556
是我想向你展示如何從分佈中進行抽樣，

65
00:04:11,556 --> 00:04:16,346
創建一個公式的精確程式描述，並將其應用於你的數據。

66
00:04:16,346 --> 00:04:21,121
但是對於標準差，這只是一個特定的變量度量，

67
00:04:21,121 --> 00:04:24,763
NumPy具有可以應用的內置函數，稱為std。

68
00:04:24,763 --> 00:04:28,805
還有更多一些對分佈的衡量是值得來

69
00:04:28,805 --> 00:04:30,270
談論的。

70
00:04:30,270 --> 00:04:33,590
其中之一是分佈的尾巴的形狀，

71
00:04:33,590 --> 00:04:36,070
這被稱為峰度(kurtosis)。

72
00:04:36,070 --> 00:04:41,050
我們可以測量峰度(kurtosis)使用SciPy 套裝軟體中的統計函數。

73
00:04:41,050 --> 00:04:43,720
負值表示曲線稍微更平坦，

74
00:04:43,720 --> 00:04:47,460
相比於正態分佈(normalnbspdistribution)，正值表示曲線

75
00:04:47,460 --> 00:04:50,760
比正態分佈略高。

76
00:04:50,760 --> 00:04:55,160
記住，我們不是測量分佈本身的峰度，而是

77
00:04:55,160 --> 00:04:59,280
我們從分佈中抽取出來的數千個值。

78
00:04:59,280 --> 00:05:01,600
這是一個微妙但重要的區別。

79
00:05:03,340 --> 00:05:05,890
我們也可以移動正態分佈，

80
00:05:05,890 --> 00:05:08,670
推動曲線的峰值向左或者向右。

81
00:05:08,670 --> 00:05:09,740
這就是所謂的偏斜(skew)。

82
00:05:10,760 --> 00:05:14,736
如果我們測試我們現在的樣本數據，我們看到沒有太多的偏差(skew)。

83
00:05:14,736 --> 00:05:19,619
我們來轉換分佈，看看一種分佈叫做Chi Squared分佈，

84
00:05:19,619 --> 00:05:23,419
這個分佈在統計學中也很常用。

85
00:05:23,419 --> 00:05:28,360
Chi Squared分佈只有一個參數稱為自由度(degree of freedom)。

86
00:05:28,360 --> 00:05:32,740
自由度與你中獲取的樣本數量密切相關，

87
00:05:32,740 --> 00:05:34,640
從標準的樣本群體，

88
00:05:34,640 --> 00:05:37,370
在顯著性的測試很重要。

89
00:05:37,370 --> 00:05:41,870
但是，我想要觀察的是，隨著自由度的增加，

90
00:05:41,870 --> 00:05:45,760
Chi Squared分佈的形狀發生變化。

91
00:05:45,760 --> 00:05:50,570
特別地，左邊的偏斜開始向中心移動。

92
00:05:50,570 --> 00:05:52,580
我們可以通過模擬來觀察。

93
00:05:53,630 --> 00:05:57,540
首先，我們將從Chi Squared分佈中挑選1,000個值，

94
00:05:57,540 --> 00:05:59,010
用自由度2。

95
00:05:59,010 --> 00:06:01,961
現在我們可以看到，偏差(skew)是相當大的。

96
00:06:01,961 --> 00:06:05,604
現在，如果我們重新採樣，把自由度改變為5。

97
00:06:08,687 --> 00:06:10,960
我們看到偏差顯著下降。

98
00:06:12,030 --> 00:06:15,560
我們實際上可以在Jupyter筆記本中繪製這個。

99
00:06:15,560 --> 00:06:18,880
我不會談論太多關於我們這裡用於繪圖的程式庫，

100
00:06:18,880 --> 00:06:20,810
因為這是下一課程的主題。

101
00:06:21,890 --> 00:06:25,580
但是你可以看到一個histogram，我們兩個自由度的曲線，

102
00:06:25,580 --> 00:06:27,140
非常向左偏斜，

103
00:06:27,140 --> 00:06:30,430
而我們五個自由度的曲線並沒有那麼高度的偏斜。

104
00:06:31,490 --> 00:06:34,500
我會像往常一樣鼓勵你在這筆記本練習，

105
00:06:34,500 --> 00:06:35,820
改變參數，

106
00:06:35,820 --> 00:06:39,819
看看自由度如何改變分佈的偏差(skew)。

107
00:06:40,960 --> 00:06:45,340
我想討論分佈的最後一個是模式(modality)。

108
00:06:45,340 --> 00:06:50,460
到目前為止，我已經展示的分佈都有一個高點，一個高峰。

109
00:06:50,460 --> 00:06:52,930
但是如果我們有多個峰值呢？

110
00:06:52,930 --> 00:06:56,925
這個分佈有兩個高點，所以我們稱之為雙峰(bimodal)。

111
00:06:56,925 --> 00:07:01,698
這些是真正有趣的分佈，並在數據挖掘中經常發生。

112
00:07:01,698 --> 00:07:04,770
我們將在第三個課程中談更多關於他們，

113
00:07:04,770 --> 00:07:08,110
但有用的理解是，我們其實可以模仿這些使用

114
00:07:08,110 --> 00:07:11,720
兩個帶有不同參數的正常分佈。

115
00:07:11,720 --> 00:07:14,210
這些被稱為高斯混合(Gaussian Mixture)模型，

116
00:07:14,210 --> 00:07:16,840
在聚類(clustering)數據時特別有用。

117
00:07:18,310 --> 00:07:21,470
好的，這一直是漫長的課堂，但我認為它很難分開

118
00:07:21,470 --> 00:07:26,000
分佈來討論，而仍然瞭解主要的觀點。

119
00:07:26,000 --> 00:07:30,770
請記住，分佈是只是一個形狀，描述它的概率

120
00:07:30,770 --> 00:07:34,730
用我們抽取的群體樣本的值。

121
00:07:34,730 --> 00:07:39,690
NumPy和SciPy各有一些不同的分佈內置函數

122
00:07:39,690 --> 00:07:41,060
讓我們能夠從中取樣。

123
00:07:42,510 --> 00:07:45,080
最後一點我想離開你這裡的是一個參考書，

124
00:07:45,080 --> 00:07:49,210
如果你發現這種方式來探索統計很有趣。

125
00:07:49,210 --> 00:07:53,810
艾倫·唐尼（Alan Downey）寫了一本名叫“Think stats”由出版社O'Reilly的書。

126
00:07:53,810 --> 00:07:57,230
我覺得他真的做的很好來教導如何思考有關統計

127
00:07:57,230 --> 00:07:59,520
從程式設計的角度來看。

128
00:07:59,520 --> 00:08:03,360
一個你編寫功能，應用背後的統計方法。

129
00:08:03,360 --> 00:08:04,920
這不是一本參考書，但

130
00:08:04,920 --> 00:08:08,240
它是一個有趣的方式來學習統計的基礎知識。

131
00:08:09,470 --> 00:08:13,730
Allen甚至在他的網站上以PDF格式提供這本書的免費副本，

132
00:08:13,730 --> 00:08:16,330
當然所有的程式都是用Python完成的。