1
00:00:09,478 --> 00:00:13,042
我們看到，即使Pandas允許我們遍歷DataFrame中的每一行

2
00:00:13,042 --> 00:00:15,904
這通常是較慢的方法來完成某個給定的任務和

3
00:00:15,904 --> 00:00:17,950
它不是很pandorable。

4
00:00:17,950 --> 00:00:20,868
例如，如果我們想要寫一些程式來遍歷所有的

5
00:00:20,868 --> 00:00:23,944
州，並產生一個平均的人口普查數字的列表。

6
00:00:23,944 --> 00:00:27,370
我們可以使用unique功能在循環(loop)中來實現。

7
00:00:27,370 --> 00:00:30,710
另一個選擇是使用DataFrame中groupby函數(通過...分組)。

8
00:00:30,710 --> 00:00:35,137
此函數接受一些列(column)名稱，然後拆分DataFrame

9
00:00:35,137 --> 00:00:39,170
成為塊塊按照這些名稱，它返回一個根據groupby的DataFrame物件。

10
00:00:39,170 --> 00:00:40,825
這可以迭代運算，

11
00:00:40,825 --> 00:00:44,197
然後返回一個元組(tuple)，其中第一個項目是分組(group)的條件，

12
00:00:44,197 --> 00:00:48,100
第二個項目是通過該分組(grouping)而減小的dataframe。

13
00:00:48,100 --> 00:00:50,940
由於它由兩個值組成，您可以拆開它們，

14
00:00:50,940 --> 00:00:54,220
僅提取您感興趣的列，以計算平均值。

15
00:00:56,290 --> 00:00:59,090
這裡是一些例子說明這兩種方法怎麼做的。

16
00:00:59,090 --> 00:01:04,442
我們首先加載人口普查數據，然後排除州級的摘要，

17
00:01:04,442 --> 00:01:06,741
其SUMLEV值是40.

18
00:01:06,741 --> 00:01:09,905
這裡是一些例子說明這兩種方法怎麼做的。

19
00:01:09,905 --> 00:01:13,911
我們首先加載人口普查數據，然後排除州級的

20
00:01:13,911 --> 00:01:16,815
摘要，其SUMLEV值是40.

21
00:01:16,815 --> 00:01:19,135
首先我們使用人口普查的州名。

22
00:01:19,135 --> 00:01:21,075
我們得到一個獨特的州名的列表。

23
00:01:21,075 --> 00:01:25,355
然後，對於每個州，我們減小DataFrame併計算人口平均值。

24
00:01:26,595 --> 00:01:28,695
如果我們量這時間，我們看到它需要一段時間。

25
00:01:28,695 --> 00:01:31,605
我已經設置了循環的次數，timeit將要十次

26
00:01:31,605 --> 00:01:32,465
因為我是現場載入

27
00:01:33,780 --> 00:01:36,800
這裡是一個同樣的方法採用groupby。

28
00:01:36,800 --> 00:01:40,210
我們告訴Pandas我們有興趣州名稱進行分組，然後我們

29
00:01:40,210 --> 00:01:44,780
只使用一列和該列中的所有數據來計算平均值。

30
00:01:44,780 --> 00:01:47,100
當我們量時間，我們看到速度的巨大差異

31
00:02:04,196 --> 00:02:08,248
現在，99％的時侯，您將使用groupby在一列或多列上。

32
00:02:08,248 --> 00:02:11,375
但是，您實際上可以提供一個函數給groupby，

33
00:02:11,375 --> 00:02:13,760
並使用它來分割數據。

34
00:02:13,760 --> 00:02:15,910
這是一個有點虛構的例子，但

35
00:02:15,910 --> 00:02:19,430
但讓我們說，你有大批的工作與大量的數據處理，

36
00:02:19,430 --> 00:02:23,210
你想在一定時間內只處理三分之一左右的州。

37
00:02:23,210 --> 00:02:26,130
我們可以創建一個返回0到2之間的數字的函數，

38
00:02:26,130 --> 00:02:29,530
根據於州名稱的第一個字母。

39
00:02:29,530 --> 00:02:33,300
然後我們可以告訴groupby要使用此函數來分開我們DataFrame。

40
00:02:33,300 --> 00:02:36,250
請注意，為了做到這一點，您需要首先將

41
00:02:36,250 --> 00:02:38,970
DataFrame的索引設置為groupby要用的列。

42
00:02:40,810 --> 00:02:41,930
這裡有個例子，這裡有個例子，

43
00:02:41,930 --> 00:02:44,301
我們將創建一個名為fun的新函數，

44
00:02:44,301 --> 00:02:47,840
如果參數的第一個字母是(少於)大寫M，我們將返回0.

45
00:02:47,840 --> 00:02:52,010
如果是(少於)大寫Q，我們將返回1，否則我們返回2.

46
00:02:52,010 --> 00:02:54,620
然後我們將這個函數傳遞給DataFrame去應用，

47
00:02:54,620 --> 00:02:58,470
然後看到DataFrame被分段，按照計算的組號。

48
00:02:58,470 --> 00:03:01,753
這種技術，可以叫做輕量級的散列法(hashing)

49
00:03:01,753 --> 00:03:04,989
通常用於分配任務跨越多個工作者。

50
00:03:04,989 --> 00:03:09,690
它們或是核心處理器，超級計算機中的節點(node)

51
00:03:09,690 --> 00:03:11,156
還是數據庫中的磁盤。

52
00:03:11,156 --> 00:03:14,381
groupby的常見工作流程是分割數據，

53
00:03:14,381 --> 00:03:17,540
應用一些功能函數，然後結合結果。

54
00:03:17,540 --> 00:03:19,548
這被稱為拆分(split),應用(apply),組合(combine)模式。

55
00:03:19,548 --> 00:03:22,840
我們已經看到了拆分方法，但是關於應用呢？

56
00:03:22,840 --> 00:03:25,900
當然，我們已經看到的迭代方法可以做到這一點，但是

57
00:03:25,900 --> 00:03:30,890
groupby也有一個稱為agg的方法，它是aggregate(聚合)的縮寫。

58
00:03:30,890 --> 00:03:33,030
此方法將函數應用於一個列或

59
00:03:33,030 --> 00:03:35,460
一組數據列和返回結果。

60
00:03:36,600 --> 00:03:40,650
使用agg，你只需傳遞進字典，你感興趣的列的名稱，

61
00:03:40,650 --> 00:03:43,140
以及你要應用的函數。

62
00:03:43,140 --> 00:03:46,720
例如，構建一個總結DataFrame，用每個州的平均人口，

63
00:03:46,720 --> 00:03:51,304
我們可以給agg一個字典，用'CENSUS2010POP'為鍵(key)和

64
00:03:51,304 --> 00:03:59,110
NumPy平均(average)功能函數(為value)。

65
00:04:03,496 --> 00:04:05,393
現在，我想提到一個潛在的問題，

66
00:04:05,393 --> 00:04:07,860
使用agg方法在groupby的物件。

67
00:04:07,860 --> 00:04:10,930
您可以看到，您傳入字典的，它或可以用來識別

68
00:04:10,930 --> 00:04:13,160
你要在其上應用函數的列(column)，

69
00:04:13,160 --> 00:04:16,980
或命名輸出的列，如果有多個要應用的函數。

70
00:04:16,980 --> 00:04:20,950
差異取決於您傳入字典的鍵(keys)及

71
00:04:20,950 --> 00:04:21,520
其命名方式。

72
00:04:22,570 --> 00:04:26,230
簡而言之，儘管許多文檔和示例將會討論一個單獨的

73
00:04:26,230 --> 00:04:29,190
groupby物件，但實際上有兩種不同的物件。

74
00:04:29,190 --> 00:04:31,584
DataFrameGroupBy和SeriesGroupBy物件。

75
00:04:31,584 --> 00:04:34,499
這兩種物件的表現有一點不同，當與agg使用時。

76
00:04:35,580 --> 00:04:39,700
例如，我們採取人口普查數據，將其轉換為以州名稱

77
00:04:39,700 --> 00:04:44,110
為索引(index)的系列，僅用列CENSUS2010POP作為數據。

78
00:04:44,110 --> 00:04:47,860
然後我們可以對它進行分組，通過索引，使用level參數。

79
00:04:47,860 --> 00:04:50,800
然後我們調用agg方法，其中的字典包括NumPy

80
00:04:50,800 --> 00:04:53,445
平均值(average)和NumPy總和(sum)功能函數。

81
00:04:53,445 --> 00:04:57,317
Pandas將這些功能應用於系列物件，並且由於只有

82
00:04:57,317 --> 00:05:01,145
一列數據，它將兩個功能應用於該列，同時打印出來。

83
00:05:14,743 --> 00:05:17,750
我們可以用DataFrame而不是一個系列來做同樣的事情。

84
00:05:17,750 --> 00:05:20,890
我們將索引設置為州名稱，我們按索引分組，並且

85
00:05:20,890 --> 00:05:22,540
我們採用兩個列。

86
00:05:22,540 --> 00:05:26,830
'POPESTIMATE2010'以及'POPESTIMATE2011'。

87
00:05:26,830 --> 00:05:28,969
當我們調用agg使用兩個參數時，

88
00:05:28,969 --> 00:05:33,670
它構建了一個很好的分層列空間，並且我們的所有功能都被應用。

89
00:05:33,670 --> 00:05:37,630
混淆可能會出現，當我們改變在字典中標籤我們傳遞

90
00:05:37,630 --> 00:05:41,980
給agg的，對應了我們DataFrame中的groupby標籤。

91
00:05:41,980 --> 00:05:46,050
在這種情況下，Pandas認識到它們是相同的，並將功能

92
00:05:46,050 --> 00:05:50,620
直接應用到列，而不是創建一個分層標記的列。

93
00:05:50,620 --> 00:05:52,980
從我的角度來看，這是非常奇怪的行為，

94
00:05:52,980 --> 00:05:55,770
而不是我期望的當標籤變化。

95
00:05:55,770 --> 00:05:58,510
所以當使用聚合(aggregate/agg)函數時，請注意這一點。

96
00:05:59,690 --> 00:06:01,360
因此 在這兩組中因此 在這兩組中

97
00:06:01,360 --> 00:06:05,390
我經常使用groupby功能在我的工作中，它非常方便

98
00:06:05,390 --> 00:06:08,650
分割資料幀，工作小塊的資料幀，

99
00:06:08,650 --> 00:06:10,980
然後稍後再創建更大的DataFrames。