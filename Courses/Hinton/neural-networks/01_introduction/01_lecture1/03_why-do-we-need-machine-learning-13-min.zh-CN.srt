1
00:00:00,000 --> 00:00:03,075
大家好, 欢迎来到Coursera上的

2
00:00:03,075 --> 00:00:09,006
机器学习的神经网络课程。在我们学习神经网络学习算法的细节之前，

3
00:00:09,006 --> 00:00:14,004
我想先谈一谈机器学习，

4
00:00:14,004 --> 00:00:19,015
为什么我们需要机器学习，我们利用其所做的事情，此外我还会

5
00:00:19,015 --> 00:00:23,087
展示一些具体例子。我们需要机器学习，是因为

6
00:00:23,087 --> 00:00:29,010
有些问题，非常难以（直接）编写代码来解决, 比如

7
00:00:29,010 --> 00:00:33,059
识别三维物体。在杂乱无章的场景，每个视角和

8
00:00:33,059 --> 00:00:37,026
光照的变化都让问题无比困难。

9
00:00:37,026 --> 00:00:42,018
我们不知道如何编写代码，是因为我们还不知道我们的大脑是如何做到这一点的。

10
00:00:42,018 --> 00:00:45,005
就算我们知道如何编写这个程序，

11
00:00:45,005 --> 00:00:49,010
其势必会异常的复杂。

12
00:00:50,029 --> 00:00:55,083
另一个例子是检测信用卡交易中的欺诈行为，这里应该

13
00:00:55,083 --> 00:01:00,014
不存在任何简单，可靠的规则来判断一笔交易是否欺诈。

14
00:01:00,014 --> 00:01:05,014
你必须组合大量不那么可靠的规则来实现判断。

15
00:01:05,014 --> 00:01:10,060
还有，这些规则必须时时更新，因为坏人也会变化欺诈的手法。

16
00:01:10,060 --> 00:01:13,084
所以，我们需要实现一个复杂的程序

17
00:01:13,084 --> 00:01:17,062
其能够组合不可靠的规则，
同时我们能够方便的对规则进行修改。

18
00:01:18,087 --> 00:01:24,027
机器学习，简言之，并不针对每一个特定的任务

19
00:01:24,027 --> 00:01:29,040
来编写特定的程序，
相反，我们收集了大量的样例，

20
00:01:29,040 --> 00:01:32,029
对给定的输入给出正确的输出。

21
00:01:32,062 --> 00:01:37,080
然后机器学习算法可以利用这些样例，
生成一个能够完成指定任务的程序。

22
00:01:37,080 --> 00:01:41,029
线性算法产生的程序

23
00:01:41,029 --> 00:01:45,035
和典型的手工完成的程序有着非常大的差异。

24
00:01:45,035 --> 00:01:49,093
比如，其可能包含了上百万个参数，
这些参数定义了各种输入证据的权重。

25
00:01:49,093 --> 00:01:54,014
如果一切顺利，这个程序应该能够

26
00:01:54,014 --> 00:01:57,004
不仅在训练数据，同时在新的数据上也工作的很好。

27
00:01:57,051 --> 00:02:03,047
如果数据发生变化，我们能够很容易的
通过重新训练来对程序进行升级。

28
00:02:03,047 --> 00:02:09,627
如今大规模计算所需代价越来越小

29
00:02:09,627 --> 00:02:14,084
如今大规模计算所需代价越来越小

30
00:02:14,084 --> 00:02:20,000
所以我们能够负担使用复杂的机器学习程序
来产生针对特定任务的程序。

31
00:02:20,000 --> 00:02:26,023
机器学习最擅长的事情，

32
00:02:26,023 --> 00:02:32,050
比如模式识别，

33
00:02:32,050 --> 00:02:38,095
在真实的场景中识别物体，
人脸或者表情

34
00:02:38,095 --> 00:02:42,053
或者所说的话。
此外还有异常检测，

35
00:02:42,053 --> 00:02:46,084
比如一系列不寻常的信用卡交易
可能是异常的。

36
00:02:47,002 --> 00:02:51,098
在比如核电站传感器上读取出来的不寻常的模式
也是异常的一个例子。

37
00:02:51,098 --> 00:02:55,062
这些场景监督学习

38
00:02:55,062 --> 00:02:58,034
往往不是很适用。

39
00:02:58,034 --> 00:03:03,025
当什么地方出了差错，
你试图找出其中的原因。

40
00:03:03,025 --> 00:03:07,067
你要在没有任何样本信号的情况下找出

41
00:03:07,067 --> 00:03:11,097
让人感兴趣的东西，它们表现的和正常情况大不一样。

42
00:03:12,059 --> 00:03:16,047
第三种任务是预测。比如预测股票价格

43
00:03:16,047 --> 00:03:21,333
或者外汇牌价，
或者根据人们喜欢的电影来预测

44
00:03:21,333 --> 00:03:25,812
其对其他电影的喜好。
或者预测那些电影是被特定人群喜欢的。

45
00:03:25,812 --> 00:03:31,226
在这个课程里，我们使用一个标准的例子

46
00:03:31,226 --> 00:03:36,306
来解释一系列的机器学习算法。

47
00:03:36,306 --> 00:03:41,669
在科学研究中这是很普遍的情形。
比如在基因研究中，

48
00:03:41,669 --> 00:03:45,809
很多工作在果蝇上进行。
原因是这样很方便。

49
00:03:45,809 --> 00:03:51,760
果蝇繁殖很快，而且我们对果蝇的基因
所知甚多。

50
00:03:51,760 --> 00:03:58,840
MNIST手写数字数据集
在机器学习领域等同于果蝇。

51
00:03:58,840 --> 00:04:04,573
其可以公开获取。
我们可以让机器学习算法

52
00:04:04,573 --> 00:04:09,769
快速的学习如何识别这些手写体，
从而让我们可以尝试算法的多种变化。

53
00:04:09,769 --> 00:04:13,500
我们已经对各种算法

54
00:04:13,500 --> 00:04:16,425
在MNIST数据集上的表现所知甚多。

55
00:04:16,425 --> 00:04:21,036
特别的，这些特定算法都是由相信它们的人来实现的，

56
00:04:21,036 --> 00:04:24,492
我们可以信任相应的结果。

57
00:04:24,492 --> 00:04:29,395
所以，我们会使用MNIST作为我们的标准任务。

58
00:04:29,395 --> 00:04:33,499
这里是MNIST数据集中的一些例子。

59
00:04:33,499 --> 00:04:38,566
神经网络可以在第一次看见这些
数字的时候就可以准确的识别他们，

60
00:04:38,566 --> 00:04:42,958
但是神经网络对识别结果的置信度并不高。

61
00:04:42,958 --> 00:04:45,819
这样也是显而易见的。

62
00:04:45,819 --> 00:04:50,205
我安装标准扫描线次序排列了这些数字。

63
00:04:50,205 --> 00:04:57,163
这里有0，1，2以及其他的数字。

64
00:04:57,163 --> 00:05:02,025
如果你已经知道这里有100个数字，

65
00:05:02,025 --> 00:05:04,086
你可能会猜测这些是2.

66
00:05:04,086 --> 00:05:08,038
如果你已经知道这里有100个数字，

67
00:05:08,038 --> 00:05:11,046
他们之间并没有共同的简单特征。

68
00:05:11,046 --> 00:05:16,019
如果将这些符号两两重叠起来，
你会发现他们并不重合。

69
00:05:16,019 --> 00:05:21,021
你甚至可以将符号进行轻微的扭曲，
但是还是很难将其两年重叠在一起。

70
00:05:21,021 --> 00:05:25,087
所以，模板在这里并不能解决问题。
一个特定的模板

71
00:05:25,087 --> 00:05:30,090
很难识别绿色方框中的‘2’，
但却有误识别红色方框中的其他符号。

72
00:05:30,090 --> 00:05:35,074
这就使得手写数字识别

73
00:05:35,074 --> 00:05:38,075
是机器学习能够解决的一个好任务。

74
00:05:39,062 --> 00:05:43,076
这些梳理

75
00:05:43,096 --> 00:05:48,043
实际上，这对我们的机器学习系统而言，
是相对简单的事。

76
00:05:48,043 --> 00:05:53,078
为了让大家更了解课程

77
00:05:53,078 --> 00:05:57,039
比如当前我们的神经网络具有上亿个参数，
能够识别

78
00:05:57,059 --> 00:06:02,087
具有上亿个参数，
能够识别

79
00:06:02,087 --> 00:06:08,028
从网络上获取的130万张高清图片中的
1千种不同的物体类别。

80
00:06:08,028 --> 00:06:12,006
2010年开始，有一个相关的竞赛

81
00:06:12,006 --> 00:06:17,001
当时最好的系统在只输出一个选择的时候
能达到47%的错误率。

82
00:06:17,001 --> 00:06:21,089
在输出5个选择，只要其中之一命中的情况下，
错误率为25%

83
00:06:21,089 --> 00:06:24,087
对于1000个类别来说，这个成绩算不错了。

84
00:06:25,008 --> 00:06:30,070
Jitendra Malik是一个著名的神经网络怀疑论者，
计算机视觉研究的领军人物，

85
00:06:30,070 --> 00:06:36,046
曾经说这个竞赛是一个
验证深度神经网络能否很好的适用于

86
00:06:36,046 --> 00:06:39,066
物体识别的好机会

87
00:06:39,066 --> 00:06:44,068
如今，深度神经网络能

88
00:06:44,068 --> 00:06:48,000
赢得竞赛的系统做的更好。
输出一个结果的时候，错误率低于40%

89
00:06:48,000 --> 00:06:52,023
输出5个结果的时候，
错误率低于20%。

90
00:06:52,023 --> 00:06:55,060
我将在讲座5进行更详细的介绍。

91
00:06:55,060 --> 00:06:59,065
这里有有一些你要识别的
图像的例子

92
00:06:59,065 --> 00:07:03,026
这些图像来自测试集，
之前（即训练时）没有出现过。

93
00:07:03,026 --> 00:07:08,062
在图片下方，
是神经网络输出其认为的正确结果。

94
00:07:08,062 --> 00:07:12,030
横条的长度代表

95
00:07:12,030 --> 00:07:16,006
相应答案的可靠程度，然后正确的
答案会被标红。

96
00:07:16,006 --> 00:07:20,061
所以中间一幅图片中，雪犁
被正确的识别了出来。

97
00:07:20,061 --> 00:07:23,086
但是你如果观察其他答案，
其实也是相关的。

98
00:07:23,086 --> 00:07:26,067
其看上去很像一个钻井
平台。

99
00:07:26,067 --> 00:07:30,091
如果你看第三个答案，
救生艇，这个图片看上去很像救生艇。

100
00:07:30,091 --> 00:07:33,067
你可以看到救生艇首的旗帜,

101
00:07:33,067 --> 00:07:38,018
救生艇的舰桥，艇尾的旗帜

102
00:07:38,018 --> 00:07:41,011
所以这个错误答案能够告诉我们很多

103
00:07:41,011 --> 00:07:43,097
其是如何工作

104
00:07:43,097 --> 00:07:48,049
如果你观察左边的图片，
其出错大概是因为鸟的嘴部不在图片内，

105
00:07:48,049 --> 00:07:52,475
而且鸟的羽毛
看上去很像潮湿的水濑的皮毛。

106
00:07:52,475 --> 00:07:56,027
但是正确答案在最高的五个输出中，
而且其表现的比我好。

107
00:07:56,027 --> 00:07:59,853
我并不知道这张图片是否是鹌鹑，
流苏松鸡或者是鹧鸪。

108
00:07:59,853 --> 00:08:03,214
如果你看右边，
答案完全错误。

109
00:08:03,214 --> 00:08:07,827
一个断头台，你应该知道其为什说。
你也应该能够知道

110
00:08:07,827 --> 00:08:12,430
猩猩也是答案，因为
背景中大片的丛林以及中间的橙色。

111
00:08:12,430 --> 00:08:15,449
但是其没有给出正确的答案。

112
00:08:15,449 --> 00:08:19,286
但是，其能够识别很大范围内的不同物体。

113
00:08:19,286 --> 00:08:23,888
如果看左侧，
我会说微波炉是我的首选答案

114
00:08:23,888 --> 00:08:28,225
标签并没有体系化，
所以正确的答案是电磁炉灶。

115
00:08:28,225 --> 00:08:30,955
这个答案在5个输出中。

116
00:08:30,955 --> 00:08:34,822
中间，是十字闸机，
是一个分体的物体。

117
00:08:34,822 --> 00:08:38,661
所以其不仅仅能够识别
紧凑的物体。

118
00:08:38,661 --> 00:08:43,699
起不仅仅能处理图片，
也能在真实场景有效，比如右侧的防弹背心。

119
00:08:43,699 --> 00:08:46,959
其也能犯一些非常有意思的错误，

120
00:08:46,959 --> 00:08:49,976
看左边的图片，
这是一副耳机。

121
00:08:49,976 --> 00:08:54,101
没有任何输出结果和耳机相似，
但是如果请注意第四个答案，

122
00:08:54,101 --> 00:08:57,316
其认为这是蚂蚁。
这真让人惊叹！

123
00:08:57,316 --> 00:09:01,581
如果你仔细观察，
你可以看到这是一个从地下视角看到的蚂蚁。

124
00:09:01,581 --> 00:09:04,350
蚂蚁的眼睛向下盯着你，

125
00:09:04,350 --> 00:09:08,698
你能看到之后的触角。
It's not the kind of view of an ant you'd

126
00:09:08,698 --> 00:09:12,777
不是你希望看到的蚂蚁。
如果你看右侧，

127
00:09:12,777 --> 00:09:16,547
其并没有输出正确答案。
但是其所有的答案都是圆柱体。

128
00:09:16,547 --> 00:09:22,002
神经网络现在擅长的另一个领域

129
00:09:22,002 --> 00:09:27,441
是语音识别，或者说语音识别系统的一部分。

130
00:09:27,441 --> 00:09:30,643
一个语音识别系统可以有几个步骤，

131
00:09:30,643 --> 00:09:34,051
首先是声波的预处理，

132
00:09:34,051 --> 00:09:39,916
将每10毫秒的声波
转换成声音系数的向量。

133
00:09:39,916 --> 00:09:43,638
我们每秒中可以得到100个这种向量。

134
00:09:43,638 --> 00:09:49,418
然后取出相邻的一系列向量，
开始判断

135
00:09:49,418 --> 00:09:52,965
这是发音的那个音素的那一部分。

136
00:09:52,965 --> 00:09:57,894
所以他们考察这个小窗口，
在窗口的中间

137
00:09:57,894 --> 00:10:01,889
这是应该是哪一个音素，
是音素的那一部分？

138
00:10:01,889 --> 00:10:06,507
一个好的语音识别系统
对于一个音素，应该有许多供选择的模型。

139
00:10:06,507 --> 00:10:09,131
每个模型，有三个不同的部分。

140
00:10:09,131 --> 00:10:12,341
所以你可能会有成千上万个

141
00:10:12,341 --> 00:10:15,609
供选择的片段。

142
00:10:15,609 --> 00:10:20,075
你不得不对其都进行相应的判断。

143
00:10:20,075 --> 00:10:26,171
进行判断后，
进入解码阶段，

144
00:10:26,171 --> 00:10:32,211
选择合情合理的判断，
将其组织成一个判断结果的序列

145
00:10:32,211 --> 00:10:37,641
从而和人们所说的话对应起来。

146
00:10:37,641 --> 00:10:44,094
目前, George Dahl 和 Abdel-rahman Mohammed
探索的深度神经网络

147
00:10:44,094 --> 00:10:48,410
比之前其他机器学习声学模型表现都要好。

148
00:10:48,410 --> 00:10:52,783
并已经开始在实际系统中使用。

149
00:10:52,783 --> 00:10:58,529
Dahl和Mohammed，开发了一个系统

150
00:10:58,529 --> 00:11:05,214
使用了很多层二元神经元的网络，
以声学

151
00:11:05,214 --> 00:11:09,986
他们是在一个相对很小的数据库上实现的

152
00:11:09,986 --> 00:11:13,656
使用了183个可选的标签。

153
00:11:13,656 --> 00:11:20,094
为了让系统更好的工作，
他们做了预训练，这将

154
00:11:20,094 --> 00:11:23,825
在课程的后半部分进行描述。

155
00:11:23,825 --> 00:11:30,471
使用标准的后处理环节后，
他们得到20.7%的错误率。

156
00:11:30,471 --> 00:11:34,154
该基础测试相当于语音领域的MNIST。

157
00:11:34,154 --> 00:11:39,704
之前在该基础测试集上最好的语音识别结果

158
00:11:39,704 --> 00:11:43,467
是24.4%。
来自微软的资深语音识别专家

159
00:11:43,467 --> 00:11:49,369
意识到，
这是一个突破性的提高，

160
00:11:49,369 --> 00:11:54,698
足以改变语音识别系统的构建方式。

161
00:11:54,698 --> 00:11:58,951
实际上的确是这样。

162
00:11:58,951 --> 00:12:04,811
微软展示了这种深度神经网络

163
00:12:04,811 --> 00:12:09,651
将其用于语音识别系统的声学模型

164
00:12:09,651 --> 00:12:14,927
将错误率从27.4%降为18.5%，
或者换算成所需的训练数据，

165
00:12:14,927 --> 00:12:21,018
你所需的训练数据将从2,000小时减少到309小时

166
00:12:21,018 --> 00:12:26,814
但是还能得到相似的性能。
IBM拥有最好的

167
00:12:26,814 --> 00:12:33,058
标准语音识别系统，

168
00:12:33,058 --> 00:12:38,297
高度优化以后错误率为18.8%，
可以被

169
00:12:38,297 --> 00:12:41,613
深度神经网络击败。

170
00:12:41,613 --> 00:12:46,768
此外，Google最近使用了
近5800小时的语音数据

171
00:12:46,768 --> 00:12:51,301
训练了一个神经网络，
这比他们训练混合模型使用的数据小得多。

172
00:12:51,301 --> 00:12:55,769
即使用了少的多的数据，

173
00:12:55,769 --> 00:12:58,708
其性能要不之前的模型好得多。

174
00:12:58,708 --> 00:13:03,291
其将错误率从16%降至12.3%, 
并还在持续改进中。

175
00:13:03,291 --> 00:13:07,284
在最新一代Android中，
如果你

176
00:13:07,284 --> 00:13:12,770
使用语音搜索，
深度神经网络将会被用到，

177
00:13:12,770 --> 00:13:14,017
以提供很好的语音识别。