В этом видео я собираюсь описать некоторые относительно простые модели нейронов. Я опишу несколько разных моделей, начиная с простых линейных пороговых нейронов, и затем, описывая немного более сложные модели. Они намного проще, чем реальные нейроны, но они всё же достаточно сложные, чтобы позволить нам построить нейронные сети, которые реализуют некоторые очень интересные виды машинного обучения. Чтобы понять что-либо сложное, необходимо идеализировать это. То есть, мы должны произвести упрощения, которые мозволят нам разобраться в том, как оно может работать. В случае атомов, например, мы принимаем упрощение, что они ведут себя как маленькие солнечные системы. Идеализация убирает сложные детали, которые не важны для понимания основных принципов. Это позволяет нам применять математику и проводить аналогии с другими известными нам системами. И как только мы поймем основные принципы, становится легко увеличить сложность и сделать модель более правдоподобной. Конечно, нам нужно быть осторожными, когда мы что-то идеализируем, чтобы не устранить то, что служит основным свойством. Зачастую стоит понимать модели, о которых известно, что они не верны, до тех пор пока мы не забываем, что они не верны. Так, например, многие работы по нейросетям используют нейроны, которые используют во взаимодействии вещественные значения вместо дискретных импульсов,и мы знаем, что кортикальные нейроны так себя не ведут, но все же лучше понять такую систему, и на практике она может быть очень полезна для машинного обучения. Первый тип нейронов, о котором я расскажу вам, самый простой - это линейный нейрон. Он простой. Он вычислительно ограничен в своих возможностях. Он позволит нам заглянуть в более сложные нейроны. Но он может быть несколько вводящимв заблуждение. Итак, это линейный нейрон, с выходом Y. Y - функция смещения вашего прогона B и суммы всех входящих связей с импульсами на входе, умноженными на веса этих связей, которые являются синаптическими весами входных линий, и если вы построите график этой функции, а затем вы спроецируете его на ось X, смещение плюс взвешенные импульсы на входе, вы получите прямую линию, проходящую через ноль. Очень отличается от линейного нейрона бинарный пороговый нейрон, который был представлен Мак-Каллоком и Питтсом. Они же и вдохновили Фон Неймана, когда он размышлял о том, как разработать универсальный компьютер. В бинарном пороговом нейроне вы сначала вычисляете взвешенную сумму входных импульсов и затем вы посылаете нервный импульс, если эта взвешенная сумма превышает пороговое значение. Мак-Каллок и Питтс думали, что импульсы - это как истинное значение выражения. И каждый нейрон комбинирует истинные значения, получаемые от других нейронов, чтобы составить истинное свое значение. И это как комбинация некоторых выражений для вычисления истинности другого выражения. В то время, в 1940х, логика была основной парадигмой работы мышления. С тех пор люди, думающие о том, как работает мозг, стали гораздо больше интересоваться идеей того, что мозг сочетает множество различных источников ненадежной информации. И поэтому логика - не такая уж хорошая парадигма для мозга. В случае бинарного порогового нейрона вы можете считать, что его входная/выходная функция - если взвешенный входной импульс превышает пороговое значение, то на выходе единица. Иначе, на выходе ноль. На самом деле есть два равнозначных способа записать выражение для бинарного порогового нейрона. Мы можем сказать, что общий входной импульс Z - просто произведение входных импульсов и весов. И затем, выход Y - единица, если Z больше порогового значения, и ноль в других случаях. Иначе, мы могли бы сказать, что общий входной импульс включает в себя слагаемое смещения. Тогда общий входной импульс - это то, что приходит на вход, умноженное на веса, плюс смещение. И затем мы могли бы сказать, что на выходе единица, если общий входной импульс больше нуля, и ноль в остальных случаях. И равнозначность в том, что пороговое значение в первой формуле равно минус смещение во второй формуле. Тип нейрона, который комбинирует свойства линейного и бинарного порогового нейронов - выпрямленный линейный нейрон. Сначала вычисляется линейная взвешенная сумма входов нейрона, но затем на выходе получается нелинейная функция от этой взвешенной суммы. То есть мы вычисляем Z так же, как и раньше. Если Z меньше нуля, мы получаем нулевой выход. Иначе, мы получаем выход, равный Z. То есть, выше нуля функция линейная, а в нуле она принимает серьезное решение. То есть, кривая входа/выхода выглядит так. Она действительно не линейная, но выше нуля она линейная. И с таким нейроном мы можем получить много полезных свойств линейных систем, в области выше нуля. Мы можем также получить способность принимать решения, в нуле. Нейроны, которые мы будет много использовать в этои курсе, и которые, возможно, наиболее распространенные среди использующихся в искуственных нейронных [сетях], сигмоидные нейроны. Они дают вещественное значение на выходе и их ограниченная функция вычисляется от их общего входного импульса. Обычно используют логистическую функцию, в которой общий входной импульс вычисляется как раньше, как смещение плюс то, что идет на вход нейрона, умноженное на вес. Выход логистического нейрона - единица разделенная на сумму единицы и e в степени минус общий входной импульс. Если подумать, то если общий входной импульс большой и положительный, то е в степени минус большое положительное число равно нулю. И тогда выход будет единица. Если общий входной импульс отрицательный, то е в степени минус большое отрицательное число равно большому числу и выход будет ноль. Итак, функция входа/выхода выглядит так. Когда общий входной импульс равен нулю, е в степени минус ноль равно единица, тогда на выходе будет одна вторая. И что хорошо в сигмоиде, это то, что он имеет гладкие производные. Производные непрерывно меняются. И то, что они ведут себя подходящим образом, делает их легкообучающимися, как мы увидим в третьей лекции. И накрнец, стохастические бинарные нейроны. Они используют точно такое же выражение, как логистические нейроны. Они вычисляют общий входной импульс также и используют логистическую функцию для вычисления вещественного значения, которое является вероятностью того, что они пошлют нервный импульс. Но затем вместо подачи на выход этой вероятности как вещественного числа, они на самом деле принимают вероятностное решение, и на выход они в действительности посылают либо единицу, либо ноль. Они по природе своей действуют случайным образом. Так, они рассматривают P как вероятность единицы на выходе, а не как вещественное число. Конечно, если входной импульс очень большой и положительный, они почти всегда дадут единицу. Если вход большой и отрицательный, они почти всегда дадут ноль. Мы можем делать то же самое с выпрямленным линейным нейроном. Мы можем сказать, что выход, в данном случае вещественное число, которое получается в выпрямленном линейном нейроне, если вход больше нуля, это скорость испускания импульсов. То есть он определен. Но однажды рассчитав эту скорость испускания импульсов, реальный момент времени, в который импульс будет произведен - случайно определяется. Это поток Пуассона. Итак, выпрямленные линейные нейроныопределяют скорость, но им присуща случайность в том, как нейрон определяет, когда именно будет произведен импульс.