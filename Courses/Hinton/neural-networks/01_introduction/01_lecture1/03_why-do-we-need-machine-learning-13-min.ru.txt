Здраствуйте, добро пожаловать на Курсеровский курс по нейронным сетям для машинного обучения. Перед тем как углублятся в детали алгоритмов обучения нейронных сетей, я хочу немного поговорить о машинном обучении, почему нам нужно машинное обучение, для каких вещей мы его используем, и показать вам некторые примеры того что оно может. Итак, причина по которой нам нужно машинное обучение это то, что для некторых проблем очень сложно написать программы. Например распознование трёхмерного объекта. Когда объект видно с новой точки зрения, с другим освещением и в загромождённой сцене это очень трудно сделать. Мы не знаем какую программу написать потому что мы не знаем как это происходит у нас в мозге. И даже если бы мы знали какую программу написать, это может оказатся ужасно сложная программа. Другой пример это обнаружение мошеннических транзакций по кредитным картам, где может не быть неких хороших, простых правил которые скажут вам что транзакция мошенническая. Вам действительно придётся объединить большое количество не очень надёжных правил. А также эти правила постоянно изменяются поскольку люди меняют свои методы мошенничества. Таким образом нам нужна сложная программа, которая объединяет ненадёжные правила, которые мы с лёгкостью изменять. Таким образом подход машинного обучения это, когда вместо того что бы писать программу вручную для каждой отдельной задачи, мы собираем много примеров и определяем правильные выходные данные для входных. Затем алгоритм машинного обучения берёт эти примеры и создаёт программу, которая делает работу. Программа, созданная алгоритмом обучения может выглядить совершенно по другому чем написанная вручную программа. Например она может содержать миллионы чисел о том как взвешивать различные виды фактов. Если мы сделаем это правильно, то программа должна работать для новых случаев так же хорошо как и для тех на которые использовались для тренировки. И если данные изменятся, мы должны быть способны с лёгкостью изменить то как программа работает перетренировав её на новых данных. Кроме того сегодня большие объёмы вычислений стоят меньше чем платить кому-то что бы он написал программу для конкретной задачи. Так что мы можем позволить себе использовать большие сложные алогритмы машинного обучения для создания этих специализизированных систем. Примерами задач которые лучше всего решаются с помощью алгоритмов обучение это разпознавание паттернов, таких как например объектов в реальной сцене, или человеческая речь. Также существуют задачи распознавания аномалий. Так, необычная последовательность транзакций по кредитной карте могла бы быть аномалией. Другим примером аномалии могут служить необычные показания датчиков на атомной электростанции. И вряд ли вам хотелось бы разбираться с этими аномалиями путём обучения с учителем. Плохая идея посылать людей смотреть, что же конкретно взорвалось и почему это произошло. Гораздо лучше узнать о том, что происходит нечто странное не по уведомлению от сотрудника. Просто есть некие отклонения от стандартного поведения. И затем предсказание. Так, обычно, предсказывают будущую стоимость акций, или курсы обмена валют, или фильмы, которые вероятно понравятся зрителю, зная другие понравившиеся ему фильмы, и какие фильмы понравились большому количеству людей. Итак, в этом курсе я использую типичный пример для объяснения многих алгоритмов машинного обучения. Так делают во многих науках. Например, в генетике. Многие эксперименты проводятся на плодовых мушках. А причины просты: они доступны. Они быстро плодятся и многое о них уже известно. База данных рукописных цифр от MNIST является цифровым эквивалентом плодовых мушек. Она находится в открытом доступе. И мы можем заставить алгоритмы машинного обучения научиться распознавать эти рукописные цифры достаточно быстро. Легко попробовать различные варианты. И у нас есть много сведений о том, насколько хорошо различные методы машинного обучения работают с этой базой. Различные методы машинного обучения были реализованы людьми, которые в них верили, так что мы можем положиться на эти результаты. Поэтому мы будем использовать базу MNIST для нашей типовой задачи. Вот пример некоторых цифр из MNIST. Вот цифры, которые были верно распознанны нейронной сетью, когда она впервые увидела их. Но система не была одинаково уверена во всех цифрах. И это понятно, смотрите на цифры. Я упорядочил цифры в естественном порядке. Нули, единицы, двойки и так далее. Если вы взглянете на кучу закорючек как те, что обведены зелёной рамкой, вы увидите, что зная на 100 процентов, что это цифры, вы вероятно предположите, что это двойки. Но очень сложно сказать, что же делает их двойками. Непросто сказать, что между ними общего. Например, если вы попробуете наложить одну двойку поверх другой, вы увидите, что они не совпадают. И даже если вы попробуете их слегка наклонить, всё равно будет сложно совместить их. Так что трафарет или шаблон здесь не поможет.
Кроме того сложно будет подобрать такой шаблон, с которым совпадут двойки из зелёной рамки, но не совпадут фигуры, помеченные красным. Именно это и делает распознавание рукописных цифр подходящей задачей для машинного обучения. Но я не хочу, чтоб вы думали, что это всё, что мы можем сделать. Это относительно просто для нашей системы машинного обучения. И чтобы вдохновить вас пройти этот курс, я покажу примеры гораздо более сложных задач. Сегодня существуют нейронные сети с сотнями миллионов параметров, способные распознавать тысячи различных типов объектов на 1.3 миллионах изображений высокого разрешения, скачанных из интернета. В 2010 было устроено соревнование и лучшая система показала 47% ошибок при первом распознавании и 25% ошибок, если вы указывали, что распознавание верно, если угадывание происходило в первые пять попыток, что неплохо для тысяч различных объектов. Джитендра Малик, скептически настроенный по отношению к нейронным сетям исследователь коспьютерного зрения, сказала, что это соревнование — хороший показатель того, что глубокие нейронные сети могут хорошо справляться с задачей распознавания объектов. А очень глубокие нейронные сети сегодня способны справляться с этой задачей значительно лучше, чем та что выиграла соревнование. Они способны при первом же распознавании показать менее 40% ошибок, а для первых пяти распознаваний — менее 20% ошибок. Я опишу всё это более детально в лекции номер 5. Вот примеры некоторых типов изображений, которые вам предстоит распознать. Это изображения из тестового набора, который система никогда раньше не видела. А под изображениями я изобразил ответ нейронной сети. Длина столбца говорит о том, насколько система была уверена в варианте ответа. А красным помечен правильный ответ. Как видите, система верно разпознала снегоуборочный плуг на центральном изображении. Но как видите и в остальных ответах по этой картинке есть смысл. Картинка действительно несколько напоминает буровую платформу. А третье предположение — спасательная шлюпка — плуг действительно очень напоминает спасательную шлюпку. Вы можете видеть флаг спереди шлюпки, мостик и флаг позади шлюпки и высокую волну где-то позади. Так что эти ошибки говорят вам много о том как ведёт себя система и эти ошибки вполне разумны. Как видим, левое изображение было распознано неверно, вероятно, потому что клюв птицы не попал в кадр и потому что перья сильно похожи на мокры мех выдры. Но система предположила верный вариант в первой пятерке, что лучше моего показателя. Я не представляю перепёлка это, рябчик или куропатка. С правой картинкой система совсем "промахнулась". Вы можете предположить почему система считает, что на изображении гильотина. Вы также возможно скажете, почему это похоже на орангутана. Возможно из-за зелени на фоне и чего-то рыжего в середине. Но система всё же не дала правильного ответа. Тем не менее она способна справиться с широким спектром объектов. Взглянем на левую фотография, мой первый ответ был бы "микроволновая печь". Метки не особенно систематизированы. Так что на самом деле правильным считается ответ "электрическая плита". И система включила этот вариант среди первых пяти. На средней картинке система определила турникет — составной объект. Система справляется не только с цельными объектами. И она также может распознавать объекты на картинках, а не только в контексте реальных сцен. Например, бронежилет. И она допускает некоторые занимательные ошибки. Посмотрите на левое изображение, это наушники. Система не распознала ничего подобного, но если посмотрите на её четвертое предположение это муравей. Вы можете подумать, что это нонсенс. Но если приглядеться, то можно представить, что это вид муравья снизу. Глаза его как бы смотрят сверху вниз на вас, а позади можно видеть его усики. Если б вы были тлёй, вам бы это ракурс не понравился. Если взглянуть на правую фотографию, то видно, что правильного ответа система не дала. Но все ответы — объекты цилиндрической формы. Другой вид задач, где нейронные сети преуспели в последнее время — распознавание речи. Или хотя бы как часть системы распознавания речи. Система распозначания речи имеет несколько стадий. Сначала обрабатывается звуковая волна, чтобы получить вектор акустических коэффициентов для каждых 10 милисекунд звука. Таким образом они получают 100 таких векторов в секунду. Затем берутся несколько смежных векторов акустических коэффициентов и делаются предположения какая часть фонемы произнесена в этой части звука. Итак система берёт мелкий отрезок и пытается угадать, какая часть какой фонемы находится в центре этого отрезка. И у хорошей системы распознавания речи будет множество разных моделей для фонемы. А у каждой модели может быть три различные части. Таким образом она может содержать тысячи различных потенциальных фрагментов. И системе нужно распредлить вероятности по всем этим тысячам альтернатив. А после того, как вероятности будут распределены, мы переходим к стадии декодирования, на которой просиходит совмещение предположений в последовательности, которые соответствуют типичной речи людей. В настоящий момент, глубокие нейронные сети под предводительством Джорджа Дала и Абделя-рахман Мухаммеда из Университета Торонто показывают лучшие результаты, чем предшествующие методы машинного обучения для аккустических моделей и теперь эти сети находят на практике. Так Дал и Мухаммед разработали систему, которая использует много слоёв бинайрных нейронов, с тем, чтобы взять отдельные звуковые отрезки и сделать предположения о фонемах. Они использовали в своей работе сравнительно малую базу данных и затем использовали всего 183 различные фонемы. И чтобы заставить свою систему работать хорошо, они провели предварительную тренировку, которая будет описана во второй части этого курса. После стандартной постобработки они получили процент ошибок 20.7 на стандартном тесте, вроде NMIST, но не для рукописных букв, а для устной речи. Лучший результат, полученный ранее при распознавании речи был 24.4%. И весьма опытный исследователь речевых технологий в отделе исследований Майкрософт осознал, что это достаточно серьезное усовершенствование, чтобы изменить всю архитектуру систем распознавания речи. И так и получилось. Если изучить последние результаты, полученные несколькими ведущими группами, занимающимися этим вопросом,  то в Майкрософт утверждают, что этот тип глубоких нейронных сетей, при использовании в качестве модели в системе распознавания речи, уменьшил процент ошибок с 27.4 до 18.5, другими словами теперь вам требуется 309 часов тренировки вместо 2000, чтобы достичь аналогичного результата. IBM, обладающая лучшей системой для одной из типичных задач по распознаванию речи — распознавание слитно произносимой речи — показала что даже их очень хорошо настроенная система с 18.8% ошибок уступает этим глубоким нейронным сетям. И Google совсем недавно натренировали глубокую нейронную сеть на большом объёме устной речи около 5800 часов. Это меньше, чем длительность тренировки их предыдущей системы. Но даже с меньшим набором данных, новая система показала себя гораздо лучше предшествующей. Процент ошибок уменьшился с 16 до 12.3 и до сих пор продолжает снижаться. А в последней операционной системе Android, если вы используете голосовой поиск, задействуется одна из этих глубоких нейронных сетей, чтобы дать вам доступ к очень качественному распознаванию речи.