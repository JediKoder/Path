1
00:00:00,000 --> 00:00:03,075
Здраствуйте, добро пожаловать на Курсеровский курс по нейронным

2
00:00:03,075 --> 00:00:09,006
сетям для машинного обучения. Перед тем как углублятся в детали алгоритмов

3
00:00:09,006 --> 00:00:14,004
обучения нейронных сетей, я хочу немного поговорить о машинном обучении,

4
00:00:14,004 --> 00:00:19,015
почему нам нужно машинное обучение, для каких вещей мы его используем, и показать вам

5
00:00:19,015 --> 00:00:23,087
некторые примеры того что оно может. Итак, причина по которой нам нужно машинное обучение это

6
00:00:23,087 --> 00:00:29,010
то, что для некторых проблем очень сложно написать программы. Например распознование трёхмерного

7
00:00:29,010 --> 00:00:33,059
объекта. Когда объект видно с новой точки зрения, с

8
00:00:33,059 --> 00:00:37,026
другим освещением и в загромождённой сцене это очень трудно сделать.

9
00:00:37,026 --> 00:00:42,018
Мы не знаем какую программу написать потому что мы не знаем как это происходит у нас

10
00:00:42,018 --> 00:00:45,005
в мозге. И даже если бы мы знали какую программу

11
00:00:45,005 --> 00:00:49,010
написать, это может оказатся ужасно сложная программа.

12
00:00:50,029 --> 00:00:55,083
Другой пример это обнаружение мошеннических транзакций по кредитным картам, где может

13
00:00:55,083 --> 00:01:00,014
не быть неких хороших, простых правил которые скажут вам что транзакция мошенническая.

14
00:01:00,014 --> 00:01:05,014
Вам действительно придётся объединить большое количество не очень надёжных правил.

15
00:01:05,014 --> 00:01:10,060
А также эти правила постоянно изменяются поскольку люди меняют свои методы

16
00:01:10,060 --> 00:01:13,084
мошенничества. Таким образом нам нужна сложная программа, которая

17
00:01:13,084 --> 00:01:17,062
объединяет ненадёжные правила, которые мы с лёгкостью изменять.

18
00:01:18,087 --> 00:01:24,027
Таким образом подход машинного обучения это, когда вместо того что бы писать программу вручную

19
00:01:24,027 --> 00:01:29,040
для каждой отдельной задачи, мы собираем много примеров и

20
00:01:29,040 --> 00:01:32,029
определяем правильные выходные данные для входных.

21
00:01:32,062 --> 00:01:37,080
Затем алгоритм машинного обучения берёт эти примеры и создаёт программу, которая

22
00:01:37,080 --> 00:01:41,029
делает работу. Программа, созданная алгоритмом

23
00:01:41,029 --> 00:01:45,035
обучения может выглядить совершенно по другому чем написанная вручную программа.

24
00:01:45,035 --> 00:01:49,093
Например она может содержать миллионы чисел о том как взвешивать различные

25
00:01:49,093 --> 00:01:54,014
виды фактов. Если мы сделаем это правильно, то программа должна работать

26
00:01:54,014 --> 00:01:57,004
для новых случаев так же хорошо как и для тех на которые использовались для тренировки.

27
00:01:57,051 --> 00:02:03,047
И если данные изменятся, мы должны быть способны с лёгкостью изменить то как программа работает

28
00:02:03,047 --> 00:02:09,627
перетренировав её на новых данных. Кроме того сегодня большие объёмы вычислений

29
00:02:09,627 --> 00:02:14,084
стоят меньше чем платить кому-то что бы он написал программу для конкретной задачи. Так что мы можем

30
00:02:14,084 --> 00:02:20,000
позволить себе использовать большие сложные алогритмы машинного обучения для создания этих

31
00:02:20,000 --> 00:02:26,023
специализизированных систем. Примерами задач которые лучше всего

32
00:02:26,023 --> 00:02:32,050
решаются с помощью алгоритмов обучение это разпознавание паттернов, таких как например

33
00:02:32,050 --> 00:02:38,095
объектов в реальной сцене, или

34
00:02:38,095 --> 00:02:42,053
человеческая речь. Также существуют задачи распознавания аномалий.

35
00:02:42,053 --> 00:02:46,084
Так, необычная последовательность транзакций по кредитной карте могла бы быть аномалией.

36
00:02:47,002 --> 00:02:51,098
Другим примером аномалии могут служить необычные показания датчиков

37
00:02:51,098 --> 00:02:55,062
на атомной электростанции. И вряд ли вам хотелось бы

38
00:02:55,062 --> 00:02:58,034
разбираться с этими аномалиями путём обучения с учителем.

39
00:02:58,034 --> 00:03:03,025
Плохая идея посылать людей смотреть, что же конкретно взорвалось и почему это произошло.

40
00:03:03,025 --> 00:03:07,067
Гораздо лучше узнать о том, что происходит нечто странное

41
00:03:07,067 --> 00:03:11,097
не по уведомлению от сотрудника. Просто есть некие отклонения от стандартного поведения.

42
00:03:12,059 --> 00:03:16,047
И затем предсказание. Так, обычно, предсказывают будущую стоимость акций,

43
00:03:16,047 --> 00:03:21,333
или курсы обмена валют, или фильмы, которые вероятно понравятся зрителю,

44
00:03:21,333 --> 00:03:25,812
зная другие понравившиеся ему фильмы, и какие фильмы понравились большому количеству людей.

45
00:03:25,812 --> 00:03:31,226
Итак, в этом курсе я использую типичный пример

46
00:03:31,226 --> 00:03:36,306
для объяснения многих алгоритмов машинного обучения.

47
00:03:36,306 --> 00:03:41,669
Так делают во многих науках. Например, в генетике. Многие эксперименты проводятся на плодовых мушках.

48
00:03:41,669 --> 00:03:45,809
А причины просты: они доступны.

49
00:03:45,809 --> 00:03:51,760
Они быстро плодятся и многое о них уже известно.

50
00:03:51,760 --> 00:03:58,840
База данных рукописных цифр от MNIST является цифровым эквивалентом плодовых мушек.

51
00:03:58,840 --> 00:04:04,573
Она находится в открытом доступе. И мы можем заставить алгоритмы машинного обучения

52
00:04:04,573 --> 00:04:09,769
научиться распознавать эти рукописные цифры достаточно быстро. Легко попробовать

53
00:04:09,769 --> 00:04:13,500
различные варианты. И у нас есть много сведений о том, насколько хорошо

54
00:04:13,500 --> 00:04:16,425
различные методы машинного обучения работают с этой базой.

55
00:04:16,425 --> 00:04:21,036
Различные методы машинного обучения были реализованы

56
00:04:21,036 --> 00:04:24,492
людьми, которые в них верили, так что мы можем положиться на эти результаты.

57
00:04:24,492 --> 00:04:29,395
Поэтому мы будем использовать базу MNIST для нашей типовой задачи.

58
00:04:29,395 --> 00:04:33,499
Вот пример некоторых цифр из MNIST.

59
00:04:33,499 --> 00:04:38,566
Вот цифры, которые были верно распознанны нейронной сетью, когда она впервые

60
00:04:38,566 --> 00:04:42,958
увидела их. Но система не была одинаково уверена

61
00:04:42,958 --> 00:04:45,819
во всех цифрах. И это понятно, смотрите на цифры.

62
00:04:45,819 --> 00:04:50,205
Я упорядочил цифры в естественном порядке.

63
00:04:50,205 --> 00:04:57,163
Нули, единицы, двойки и так далее. Если вы взглянете на кучу закорючек как те,

64
00:04:57,163 --> 00:05:02,025
что обведены зелёной рамкой, вы увидите, что зная на 100 процентов, что это цифры,

65
00:05:02,025 --> 00:05:04,086
вы вероятно предположите, что это двойки.

66
00:05:04,086 --> 00:05:08,038
Но очень сложно сказать, что же делает их двойками.

67
00:05:08,038 --> 00:05:11,046
Непросто сказать, что между ними общего.

68
00:05:11,046 --> 00:05:16,019
Например, если вы попробуете наложить одну двойку поверх другой, вы увидите, что они не совпадают.

69
00:05:16,019 --> 00:05:21,021
И даже если вы попробуете их слегка наклонить, всё равно будет сложно совместить их.

70
00:05:21,021 --> 00:05:25,087
Так что трафарет или шаблон здесь не поможет.
Кроме того сложно будет

71
00:05:25,087 --> 00:05:30,090
подобрать такой шаблон, с которым совпадут двойки из зелёной рамки, но не совпадут

72
00:05:30,090 --> 00:05:35,074
фигуры, помеченные красным. Именно это и делает распознавание

73
00:05:35,074 --> 00:05:38,075
рукописных цифр подходящей задачей для машинного обучения.

74
00:05:39,062 --> 00:05:43,076
Но я не хочу, чтоб вы думали, что это всё, что мы можем сделать.

75
00:05:43,096 --> 00:05:48,043
Это относительно просто для нашей системы машинного обучения.

76
00:05:48,043 --> 00:05:53,078
И чтобы вдохновить вас пройти этот курс, я покажу примеры гораздо более сложных задач.

77
00:05:53,078 --> 00:05:57,039
Сегодня существуют нейронные сети

78
00:05:57,059 --> 00:06:02,087
с сотнями миллионов параметров, способные распознавать тысячи

79
00:06:02,087 --> 00:06:08,028
различных типов объектов на 1.3 миллионах изображений высокого разрешения, скачанных из интернета.

80
00:06:08,028 --> 00:06:12,006
В 2010 было устроено соревнование

81
00:06:12,006 --> 00:06:17,001
и лучшая система показала 47% ошибок при первом распознавании и 25%

82
00:06:17,001 --> 00:06:21,089
ошибок, если вы указывали, что распознавание верно, если угадывание происходило в первые пять попыток,

83
00:06:21,089 --> 00:06:24,087
что неплохо для тысяч различных объектов.

84
00:06:25,008 --> 00:06:30,070
Джитендра Малик, скептически настроенный по отношению к нейронным сетям исследователь коспьютерного зрения,

85
00:06:30,070 --> 00:06:36,046
сказала, что это соревнование — хороший показатель того, что глубокие нейронные сети

86
00:06:36,046 --> 00:06:39,066
могут хорошо справляться с задачей распознавания объектов.

87
00:06:39,066 --> 00:06:44,068
А очень глубокие нейронные сети сегодня способны справляться с этой задачей значительно лучше, чем та

88
00:06:44,068 --> 00:06:48,000
что выиграла соревнование. Они способны при первом же распознавании показать менее 40% ошибок,

89
00:06:48,000 --> 00:06:52,023
а для первых пяти распознаваний — менее 20% ошибок.

90
00:06:52,023 --> 00:06:55,060
Я опишу всё это более детально в лекции номер 5.

91
00:06:55,060 --> 00:06:59,065
Вот примеры некоторых типов изображений, которые вам предстоит распознать.

92
00:06:59,065 --> 00:07:03,026
Это изображения из тестового набора, который система никогда раньше не видела.

93
00:07:03,026 --> 00:07:08,062
А под изображениями я изобразил ответ нейронной сети.

94
00:07:08,062 --> 00:07:12,030
Длина столбца говорит о том,

95
00:07:12,030 --> 00:07:16,006
насколько система была уверена в варианте ответа. А красным помечен правильный ответ.

96
00:07:16,006 --> 00:07:20,061
Как видите, система верно разпознала снегоуборочный плуг на центральном изображении.

97
00:07:20,061 --> 00:07:23,086
Но как видите и в остальных ответах по этой картинке есть смысл.

98
00:07:23,086 --> 00:07:26,067
Картинка действительно несколько напоминает буровую платформу.

99
00:07:26,067 --> 00:07:30,091
А третье предположение — спасательная шлюпка — плуг действительно очень напоминает

100
00:07:30,091 --> 00:07:33,067
спасательную шлюпку. Вы можете видеть флаг спереди

101
00:07:33,067 --> 00:07:38,018
шлюпки, мостик и флаг позади шлюпки и высокую волну где-то позади.

102
00:07:38,018 --> 00:07:41,011
Так что эти ошибки говорят вам много о том

103
00:07:41,011 --> 00:07:43,097
как ведёт себя система и эти ошибки вполне разумны.

104
00:07:43,097 --> 00:07:48,049
Как видим, левое изображение было распознано неверно, вероятно, потому что клюв птицы

105
00:07:48,049 --> 00:07:52,475
не попал в кадр и потому что перья сильно похожи на мокры мех выдры.

106
00:07:52,475 --> 00:07:56,027
Но система предположила верный вариант в первой пятерке, что лучше моего показателя.

107
00:07:56,027 --> 00:07:59,853
Я не представляю перепёлка это, рябчик или куропатка.

108
00:07:59,853 --> 00:08:03,214
С правой картинкой система совсем "промахнулась".

109
00:08:03,214 --> 00:08:07,827
Вы можете предположить почему система считает, что на изображении гильотина. Вы также возможно скажете,

110
00:08:07,827 --> 00:08:12,430
почему это похоже на орангутана. Возможно из-за зелени на фоне и чего-то рыжего в середине.

111
00:08:12,430 --> 00:08:15,449
Но система всё же не дала правильного ответа.

112
00:08:15,449 --> 00:08:19,286
Тем не менее она способна справиться с широким спектром объектов.

113
00:08:19,286 --> 00:08:23,888
Взглянем на левую фотография, мой первый ответ был бы "микроволновая печь".

114
00:08:23,888 --> 00:08:28,225
Метки не особенно систематизированы. Так что на самом деле правильным считается ответ

115
00:08:28,225 --> 00:08:30,955
"электрическая плита". И система включила этот вариант среди первых пяти.

116
00:08:30,955 --> 00:08:34,822
На средней картинке система определила турникет — составной объект.

117
00:08:34,822 --> 00:08:38,661
Система справляется не только с цельными объектами.

118
00:08:38,661 --> 00:08:43,699
И она также может распознавать объекты на картинках, а не только в контексте реальных сцен. Например, бронежилет.

119
00:08:43,699 --> 00:08:46,959
И она допускает некоторые занимательные ошибки.

120
00:08:46,959 --> 00:08:49,976
Посмотрите на левое изображение, это наушники.

121
00:08:49,976 --> 00:08:54,101
Система не распознала ничего подобного, но если посмотрите на её четвертое предположение

122
00:08:54,101 --> 00:08:57,316
это муравей. Вы можете подумать, что это нонсенс.

123
00:08:57,316 --> 00:09:01,581
Но если приглядеться, то можно представить, что это вид муравья снизу.

124
00:09:01,581 --> 00:09:04,350
Глаза его как бы смотрят сверху вниз на вас,

125
00:09:04,350 --> 00:09:08,698
а позади можно видеть его усики. Если б вы были тлёй, вам бы это ракурс не понравился.

126
00:09:08,698 --> 00:09:12,777
Если взглянуть на правую фотографию,

127
00:09:12,777 --> 00:09:16,547
то видно, что правильного ответа система не дала. Но все ответы — объекты цилиндрической формы.

128
00:09:16,547 --> 00:09:22,002
Другой вид задач, где нейронные сети преуспели в последнее время —

129
00:09:22,002 --> 00:09:27,441
распознавание речи. Или хотя бы как часть системы распознавания речи.

130
00:09:27,441 --> 00:09:30,643
Система распозначания речи имеет несколько стадий.

131
00:09:30,643 --> 00:09:34,051
Сначала обрабатывается звуковая волна,

132
00:09:34,051 --> 00:09:39,916
чтобы получить вектор акустических коэффициентов для каждых 10 милисекунд звука.

133
00:09:39,916 --> 00:09:43,638
Таким образом они получают 100 таких векторов в секунду.

134
00:09:43,638 --> 00:09:49,418
Затем берутся несколько смежных векторов акустических коэффициентов

135
00:09:49,418 --> 00:09:52,965
и делаются предположения какая часть фонемы произнесена в этой части звука.

136
00:09:52,965 --> 00:09:57,894
Итак система берёт мелкий отрезок и пытается угадать,

137
00:09:57,894 --> 00:10:01,889
какая часть какой фонемы находится в центре этого отрезка.

138
00:10:01,889 --> 00:10:06,507
И у хорошей системы распознавания речи будет множество разных моделей для фонемы.

139
00:10:06,507 --> 00:10:09,131
А у каждой модели может быть три различные части.

140
00:10:09,131 --> 00:10:12,341
Таким образом она может содержать тысячи

141
00:10:12,341 --> 00:10:15,609
различных потенциальных фрагментов.

142
00:10:15,609 --> 00:10:20,075
И системе нужно распредлить вероятности по всем этим тысячам альтернатив.

143
00:10:20,075 --> 00:10:26,171
А после того, как вероятности будут распределены, мы переходим к стадии декодирования,

144
00:10:26,171 --> 00:10:32,211
на которой просиходит совмещение предположений в последовательности,

145
00:10:32,211 --> 00:10:37,641
которые соответствуют типичной речи людей.

146
00:10:37,641 --> 00:10:44,094
В настоящий момент, глубокие нейронные сети под предводительством Джорджа Дала и Абделя-рахман Мухаммеда

147
00:10:44,094 --> 00:10:48,410
из Университета Торонто показывают лучшие результаты, чем предшествующие

148
00:10:48,410 --> 00:10:52,783
методы машинного обучения для аккустических моделей и теперь эти сети находят

149
00:10:52,783 --> 00:10:58,529
на практике. Так Дал и Мухаммед разработали систему,

150
00:10:58,529 --> 00:11:05,214
которая использует много слоёв бинайрных нейронов, с тем, чтобы взять отдельные звуковые отрезки и сделать

151
00:11:05,214 --> 00:11:09,986
предположения о фонемах. Они использовали в своей работе сравнительно малую

152
00:11:09,986 --> 00:11:13,656
базу данных и затем использовали всего 183 различные фонемы.

153
00:11:13,656 --> 00:11:20,094
И чтобы заставить свою систему работать хорошо, они провели предварительную тренировку, которая

154
00:11:20,094 --> 00:11:23,825
будет описана во второй части этого курса.

155
00:11:23,825 --> 00:11:30,471
После стандартной постобработки они получили процент ошибок 20.7 на стандартном

156
00:11:30,471 --> 00:11:34,154
тесте, вроде NMIST, но не для рукописных букв, а для устной речи.

157
00:11:34,154 --> 00:11:39,704
Лучший результат, полученный ранее при распознавании речи

158
00:11:39,704 --> 00:11:43,467
был 24.4%. И весьма опытный исследователь речевых технологий

159
00:11:43,467 --> 00:11:49,369
в отделе исследований Майкрософт осознал, что это достаточно серьезное усовершенствование,

160
00:11:49,369 --> 00:11:54,698
чтобы изменить всю архитектуру систем распознавания речи.

161
00:11:54,698 --> 00:11:58,951
И так и получилось. Если изучить последние результаты,

162
00:11:58,951 --> 00:12:04,811
полученные несколькими ведущими группами, занимающимися этим вопросом,  то в Майкрософт утверждают, что этот тип

163
00:12:04,811 --> 00:12:09,651
глубоких нейронных сетей, при использовании в качестве модели в системе распознавания речи,

164
00:12:09,651 --> 00:12:14,927
уменьшил процент ошибок с 27.4 до 18.5, другими словами

165
00:12:14,927 --> 00:12:21,018
теперь вам требуется 309 часов тренировки вместо 2000,

166
00:12:21,018 --> 00:12:26,814
чтобы достичь аналогичного результата. IBM, обладающая лучшей системой для одной из

167
00:12:26,814 --> 00:12:33,058
типичных задач по распознаванию речи — распознавание слитно произносимой речи — показала

168
00:12:33,058 --> 00:12:38,297
что даже их очень хорошо настроенная система с 18.8% ошибок

169
00:12:38,297 --> 00:12:41,613
уступает этим глубоким нейронным сетям.

170
00:12:41,613 --> 00:12:46,768
И Google совсем недавно натренировали глубокую нейронную сеть на большом объёме устной речи

171
00:12:46,768 --> 00:12:51,301
около 5800 часов. Это меньше, чем длительность тренировки

172
00:12:51,301 --> 00:12:55,769
их предыдущей системы. Но даже с меньшим набором данных, новая система

173
00:12:55,769 --> 00:12:58,708
показала себя гораздо лучше предшествующей.

174
00:12:58,708 --> 00:13:03,291
Процент ошибок уменьшился с 16 до 12.3 и до сих пор

175
00:13:03,291 --> 00:13:07,284
продолжает снижаться. А в последней операционной системе Android, если вы используете

176
00:13:07,284 --> 00:13:12,770
голосовой поиск, задействуется одна из этих глубоких нейронных сетей, чтобы дать вам доступ к очень качественному

177
00:13:12,770 --> 00:13:14,017
распознаванию речи.