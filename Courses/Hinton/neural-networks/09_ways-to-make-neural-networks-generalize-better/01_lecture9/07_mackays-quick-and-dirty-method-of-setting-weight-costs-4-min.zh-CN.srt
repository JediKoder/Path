1
00:00:00,000 --> 00:00:06,074
在这段视频中，我将要描述一种在20世纪90年代，由大卫麦基开发的方法。

2
00:00:06,074 --> 00:00:12,771
这种方法用作决定神经网络所用的权值衰减

3
00:00:12,771 --> 00:00:17,152
而不需要使用验证集。它是基于一种想法，我们能够

4
00:00:17,152 --> 00:00:23,671
边进行估值预算，边理解全职衰减，由此

5
00:00:23,671 --> 00:00:30,028
权值衰减的量值能关联至前权重分布的紧密程度。

6
00:00:30,028 --> 00:00:34,265
麦基展示了我们能经验性的同时

7
00:00:34,265 --> 00:00:39,891
将权值衰减和已假设噪音两者同时代入神经网络的输出中，以此而得到一种

8
00:00:39,891 --> 00:00:45,181
不需验证集的拟合权重损失的方法，而且

9
00:00:45,181 --> 00:00:50,539
同时，也允许我们对不同的子集有不同的权重损失，

10
00:00:50,539 --> 00:00:55,227
因为神经网络中的链接，要付出非常大的代价而

11
00:00:55,227 --> 00:00:59,580
使用验证集来进行。麦基进而使用这种方法而赢取了一些竞赛。

12
00:00:59,580 --> 00:01:04,062
现在，我将要描述一种简单而

13
00:01:04,062 --> 00:01:09,624
有实际应用的方法，它由大卫麦基所开发，基于这样一种事实，我们能够

14
00:01:09,624 --> 00:01:13,490
将权值损失理解为两种方差之比。

15
00:01:13,490 --> 00:01:18,985
在我们学习了一种能最小化方差的模型之后，我们能够找到针对输出方差的最佳值

16
00:01:18,985 --> 00:01:24,683
而这最佳值则是通过简单应残留误差的方差而找到的。

17
00:01:24,683 --> 00:01:31,264
我们也可以在获得权值之前，而估计高斯方差。

18
00:01:31,264 --> 00:01:36,796
我们必须由猜测方差应该为多少而出发，

19
00:01:36,796 --> 00:01:41,923
然后，我们进行一些学习，继而我们能使用

20
00:01:41,923 --> 00:01:48,687
一种非常简易的名叫实用贝叶斯的方法。我们将前方差设定为

21
00:01:48,687 --> 00:01:53,636
学习后模型权重的方差，因为那个方差

22
00:01:53,636 --> 00:01:58,742
最有可能对应生成权重。这很大程度上违反了

23
00:01:58,742 --> 00:02:03,514
许多贝叶斯方法的假定预设。我们是通过使用数据来决定我们的前设猜想。

24
00:02:03,514 --> 00:02:06,989
因此，一旦我们知道了权重，我们将

25
00:02:06,989 --> 00:02:10,641
一个平均值为0的高斯分布拟合至学习到的权重的一维分布。

26
00:02:10,641 --> 00:02:13,822
然后，我们使用高斯方差，

27
00:02:13,822 --> 00:02:20,733
而将它应为我们的前设猜想。现在，有一件非常好的事情，就是

28
00:02:20,733 --> 00:02:25,172
不同子集的权重，譬如在不同层，我们

29
00:02:25,172 --> 00:02:28,840
能许熙道不同层的方差。

30
00:02:30,760 --> 00:02:36,900
我们不需要一个验证集，因此我们能使用所有非测试数据而用于训练。

31
00:02:36,900 --> 00:02:42,744
以为我们不需要验证集就能决定不同层面的权重损失，

32
00:02:42,744 --> 00:02:47,923
我能实际上能有不同的权重损失。

33
00:02:47,923 --> 00:02:51,622
通过验证集，这将会非常困难。

34
00:02:51,622 --> 00:02:57,687
综上，这是麦基方法。你首先猜测噪音方差和

35
00:02:57,687 --> 00:03:02,647
前权重方差。实际上，你只需要猜测它们的比值。

36
00:03:02,647 --> 00:03:06,132
继而，你使用梯度下降学习

37
00:03:06,132 --> 00:03:11,427
而提高权重质量。然后，你将噪音方差重设至

38
00:03:11,427 --> 00:03:18,230
残留误差的方差，然后你将前权重方差设置为

39
00:03:18,230 --> 00:03:22,060
实际学习权重的分布。

40
00:03:22,880 --> 00:03:25,660
然后，你需要重新循环这段过程。

41
00:03:26,220 --> 00:03:28,843
其实这种方法在应用中相当有效。

42
00:03:28,843 --> 00:03:31,696
麦基也因此而赢取了许多竞赛。