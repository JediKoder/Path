这总是个问题 推测被用作 手写数字识别的神经网络是否可以大规模的被用作 人们所称的实际任务 也就是 识别物体于 高分辨率的颜色图像中 而且场景是杂乱无章时 所以你不得不做一些事情 比如图像分割 处理3D 视角 处理5-foot list 很多不同的物体在周围 你不是很确定哪一个是想要的 诸如此类 自从本课程开始 我们已经得到 让方面一些有意思的新结论 在我第一节课中 我描述了 Alex Krizhevsky建立的网络 展示了它善于识别物体 但是在那个时候它还没有被 最好的计算机视觉系统进行标准测试 现在有了 人们致力于研究Emenise很多年了 渐渐地提升了它们识别手写数字的能力 很多计算机视觉研究者认为这是浪费时间 如果你想要 能够在有颜色的图片中识别真实的物体 因为他们认为 从Emnise中学到的东西无法推广到那个领域 这样想是很合理的 这里有很多原因来解释为什么这是一个更加困难的任务 首先 这里有很多很多不同的物体 尽管我们仅仅识别一千种类别 这仍然是一百的倍数 第二 这里有很多的像素点 尽管 我们使用大量仅仅是256*256像素的图片 这仍然是 100或者300倍于28*28的灰度图像 
另外一个因素是在真实的场景中 你不得不 处理三维世界中的二维图片 这样很多信息都会丢失 真实场景有杂乱的类别 可能在手写中没有出现 在手写中可能有重叠的字母 这需要分割 但是 你没有东西模糊其他物体来遮挡物体的一大部分 你没有很多不同种类的 物体 在同一场景下 你也没有一些 在真实场景中的光照变化 所以问题是同种 在手写数字识别中表现的很好的卷积神经网络 也会在真实颜色的图片中表现的很好吗 
在真实颜色图片的领域我们很可能 需要去结合一些先验知识
因为 如果我们努力用sera san的方法去做 而不结合一些知识 通过 产生额外的训练样本来得到知识 则计算量 对于现在的计算机来说是很大的 所以最近有一个竞赛 基于ImageNet的数据库 ImageNet事实上有超过 一百万的图片 但是有120万图片的子集 被选来做分类的任务 正确的为这些图片贴上标签 现在这些图片被手工标签 有一千种不同的类别 但是这不 太可靠 一张图片里可能有两个 在这一千种类别中出现的物体 但仅仅标记了一个 所以 为了让这个任务更可行 
计算机视觉系统被允许做五个预测 它被认为是正确的 如果这五个之中有一个 与人工给的标签一致 这里也有一个定位任务 理由是 很多计算机视觉系统使用特征袋方法 对于整个图片或者四分之一图片 它们知道特征 是什么 但是不知道特征在哪里
这使得它们识别物体的同时 但是并不知道物体究竟在哪里
这不像人类的行为 除非是大脑好奇部位损伤 即平衡综合征的人 他们可以识别物体但是不确定在哪 所以对于定位任务 
你不得不在物体周围放一个盒子 一旦你已经 识别到了它 然后把它放进盒子 
至少与正确的盒子有50%的交集 在这个任务中 人们尝试了一些 现存最好的计算机视觉方法 
牛津大学的领头团队和 法国国家信息与自动化研究所 和 施乐欧洲研究中心 以及其他不同的大学努力 都觉得这很难 计算机视觉系统通常使用复杂的多级系统 这些系统早期时通常使用手工调节来 使用一些数据优化参数
现在这些系统是 使用的学习算法
但是他们不能学习到所有的东西 方式是深度神经网络被训练来做后向传播 他们没有端到端的学习 在早期特征检测器中使用的参数 被制定决策分类中的作用大小所影响 因此这里有一些测试集的样本 来告诉你数据是怎么样的
你已经看到一些例子 在第一个课程里 但是这里还有一些
所以你可以很明显的看到 图像中的物体是什么 虽然很多东西都缺失了 它没有耳朵 没有腿 预测结果是在Alex Krizhevsky的深度神经网络中
没有归一化的概率 你可以看到它有十足的把握说 这是一只猎豹 如果不是猎豹 
它会认为可能是一只豹子 它也给出了其他的可能性 比如一只雪豹 这不是一只雪豹的颜色 也不是埃及猫 这是另外一个例子
这张图片中有很多物体 但是感兴趣的只占很小一部分像素 神经网络正确的将它归为子弹头列车
但是他也有其他的假设 比如地铁 或者电力动车 这都是有可能的假设 如果你看图片 有很多物体都可以被作为标签 比如 屋顶 占了图片很大一部分空间 比列车或者 支撑屋顶和人行道的柱子 或者背景部分的公寓楼 在这种图片中 你不得不处理这种情况 图片中有很多可以选择地目标 最后一张图片展示了不同种类的 例子 这里没有背景杂物 物体被很好的分离出来 可能是目录用的图片或者什么 神经网络第一次没有预测正确 但是在最可能的五个预测中 但是这里神经网络并不是很有把握 他们的概率都近似 网络正确的意识到他 不是真的清楚 如果你看另外左边两个的 概率 他们都有很好的把握 如果你眯起你的眼睛以至于你不能很好地看到图片
你就知道它为什么 可能认为这是一个煎锅或者听筒 那么系统如何处理这些数据呢
计算机视觉系统有差错率 你能注意到的一件事是最好的 系统都很相似 所以东京大学得到了 26.1%的差错率 这里我只是报道每个团队最好的系统 牛津大学有很好的计算机视觉团队 通常 被认为是欧洲最好的团队 但是还是有26%的差错率 位于施乐公园中心的法国国家信息与自动化研究所 也是 一个很好的计算机视觉团队 得到了27%的差错率
所以你可以从中猜测得到 26%是很难得的 如果能超过26%你就能与最好的 计算机视觉系统并驾齐驱了
Alex Krizhevsky的神经网络得到了 16%的差错率 这是一个很大的飞跃 通常 在这样的竞争中你不会看到像这么大的飞跃 因此Alex Krizhevsky的网络像这样工作的 它是一个很深的卷积神经网络 由Yann Le Cu所创始 率先被由于数字识别 然后Yann应用它来识别真实 物体 我们将用所有的 从Yann和[未知]各个不同的团队学习的课 来为做真正的视觉建立深度神经网络 它有七个隐藏层 这比
通常都深 而且没有计算 一些最大池化层 靠前的是卷积层 我们很可能不需要本地感受野 不用任何 权重 如果我们有一个很强的计算机的话
但是通过使他们卷积 你减少了 很多参数 所以减少了很多你需要的训练数据 这同时也减少了计算所花的时间 最后两层总是被连接着的
这也是大多数参数所处的地方 我想这里大约有一千六百万 的参数介于每两层之间 最后两层所做的是寻找到本地特征的组合 这些特征是被之前的层提取出来的
显然这通常也是很多 组合所寻找的 这解释了为什么你需要很多 参数 激活函数是修正过的 线性单元位于每个隐藏层中 这比逻辑 单元训练的更快 也更加有效
大多数人都谨慎的使用深度 神经网络 来从真实图片中识别物体
用我定义过的 线性单元 我们也用竞争规则化 在层内抑制一个单元的活跃性
如果附近的其他的单元 十分活跃 这对于强度差异性有很大帮助 因此 你可能有一个边缘检测器 因为一些微弱的边缘而变得有些活跃 这是很不相关的 
如果这附近有更多强烈的活动 这里也有很多其他的技巧
我们用来有效的提升网络的普适性 首先 我们使用 通过变换强化数据的技巧 这里有一个方法用来对图片在竞争中下采样到256*256维 但相反 Alex Krizhevsky从这些图片
随机取了224*224 的分块 这给他更多图片去训练 也帮助他处理了平移和变化 尽管它们是卷积网络 但还是有用的 它也使用了图片的左右翻转 这再一次加倍了数据量 他没有使用角反射 
因为重力是很重要的 左右翻转其实没有改变事物表面的样子 除非 它们是书写类的事物
在测试的时候 他没有只用一个 分块 他使用了很多不同的分块 四个角 中间部分 这给他了五个区域
然后是所有的左右翻转 这一共有十个 他在网络中用了所有的十张图片 然后结合他们的观点 
在顶层 大多数参数在的地方 他使用了一个新的规则化方法 叫做Dropout层 这是很有用的 帮助防止网络过拟合 这在他的结果中占了一定的比例 我将在以后的课程中详细的描述Dropout 但是现在 dropout的基本想法是
在每次给出一个训练样本的时候 你从一层中忽略一半的隐藏单元 这意味着其他存活下来的隐含单元不能依赖 他们得到的总和
他们不能学会修补错误 被其他隐含层遗留下来的错误
因为其他隐含单元可能 被忽视了 无论是修复一个不存在的错误 所以他们不得不变得更加利己
他们不得不各自做有用的事情 但是他们仍然不得不去做有用的事情
不同于那些留存下来的单元做的 所以dropout阻止了太多 隐含单元之间的合作
很多合作对 拟合数据很有用
但是如果测试集的分布 显著不同 那么所有的合作
都会造成过拟合 Alex没法不用强大的硬件来完成这个工作 但是硬件 现在只需要几千美元 
Alex是一个很厉害的程序员 它使用了高效的方法实现卷积和神经单元 在两个英伟达 GTX 580的图形处理器上
每一个都有500个快速的核 它们擅长于数学运算 而不擅长于其他任务 图形处理器很擅长于做矩阵运算 矩阵乘法 所以如果你把隐含层的激励向量堆在一起 并基于很多训练样本 这样得到一个矩阵 现在你将这个矩阵和权重矩阵相乘来得到 下一隐含层的所有训练样本的激励 如果这些矩阵都很大
GPU会有很大的优势 他们给你大约30倍的速度
他们到内存间也有很高的带宽 这对神经网络是很需要的
因为在神经网络中你一直希望 得到另外一个权重 这样你可以用激励乘上它 这里有上百万的权重 因此你无法将他们保存在高速缓存中 用所有的这些硬件优势 他可以一周内训练出最终的网络 你也可以把十个分块联系起来 在测试时 很快 所以测试时你可以用帧频来运行 在未来我们将能够 将这种神经网络延伸到很多核心上 随着核价格的降低 Google已经能用这个实验了 而且如果我们能在状态间通讯的足够快 我们将能 在更多的核心上做更大的网络
Google已经模拟了 17亿连接的网络 我认为这还会继续增大 随着核心变得越来越便宜 数据集越来越大 
这些深度神经网络将 比老式计算机视觉系统改进得更快 因为他们没有涉及太多的人工操作 他们可以更好地 使用大规模数据集和大规模运算 所以我们已经开启了一个大的突破口 我认为没有必要往回看了 我想 从现在开始所有最好的物体 识别系统 至少对于一些静态图片
将会使用大的深度神经网络 这里有其他的应用领域 
我们可以学到同样的东西 Vladimir Nee使用了一个本地区域的网络 没有用卷积去从航拍照片中提取道路 这些事很杂乱的城市地区的航拍图 他也使用了多层修正线性单元 他使用了一张相对大的图片分块 预测了中央16*16 像素区域是道路的一块或者不是 比较好的事情是训练数据有很多标签 可用 这是因为地图告诉你哪里 是道路中心线 哪里是差不多固定的宽度 地图中的向量可以告诉你道路的中心线在哪 你可以估测哪些像素可能是道路 然而 这个任务很难
这通常有一个视觉 问题 道路会被建筑物所遮挡
因为飞机不是 垂直往下拍照的 他们被树挡住了 也被那些 停在路边的车挡住 建筑物旁的阴影 主要的光照取决于是晴天还是阴天 举个例子 这里有很小的视角点变化 飞机基本上是朝下看的
但是在任何一个大的照片中它无法 保证每一个像素点都是垂直向下看的 数据中最坏的问题是不正确的标签 你得到错误的标签 因为地图不是完美无缺的被记录 对于大多数的目的 你不需要地图被记录精准到几米 在这个数据中的一个像素大约是一平方米 如果地图的记录偏差超过三米 你将会得到 三个错误的标签 对每条路的像素来说 另外 一个严重的问题
人们制作地图的时候不得不武断地 决定哪个被记为道路 哪个被记为巷道 因此在大多数的地图中 你看到一些东西
你不知道怎么判断 这是被记为一条道路还是一条巷道 因此你很容易困惑 不知道从地图中得到哪个标签 在很大图片块上训练的大规模神经网络
使用几百万个样例 我认为 这是在这个任务上真正的希望 很难说人们可以做什么 这里是数据的样子 这是多伦多的一部分 如果你了解多伦多 你可以通过道路的角度来判断 在多伦多照片上方 我放了从图片中提取的两个分块 如果你看到那些分块 你可以 知道很难去判断这是哪条路 在右边 这是[UNKNOWN]系统的输出 绿色是被正确识别出来的道路 红色代表系统 认为可能是路 但是实际上不是 事实上 那是一个停车场 
但是可以看到为什么它可能认为 是一条路 翻译 Naiding Zhou