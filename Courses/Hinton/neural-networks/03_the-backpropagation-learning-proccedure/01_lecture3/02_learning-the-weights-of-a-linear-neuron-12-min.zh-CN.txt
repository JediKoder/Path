这个视频将介绍线性神经元学习算法。 其形式和感知器算法很类似，
但是达成的结果不一样。 感知器中，参数发生变化， 参数不停向好的参数集合逼近。 在线性神经元算法中，
输出不停的向目标输出逼近。 感知器算法收敛，
是因为我们确保了每次我们改变参数权重， 我们都向好的参数集合逼近。 这个保证不能扩展到复杂的网络。 在复杂的网络中，
当你对两个好的参数的集合取平均时， 你有可能得到一个坏的参数集合。
所以在多层神经网络中， 我们不使用感知器学习算法。 要证明复杂神经网络在提高其学习效果，
我们不能使用同样的证明方法。 他们不能被称为多层感知器。 这部分也有我的错在里面，抱歉了。 对于多层神经网络，
我们需要使用其他方法来证明算法的确在工作。 这里我们不再证明参数正在逼近正确的参数， 相反，我们会证明实际的输出正在逼近真实的输出。 这种证明方式，对于 非凸问题也有效，
非凸问题中，两个好的解的平均值并不能给出一个好的解。 感知器不是这样。 在感知器学习中，
当参数向好的参数逼近时， 输出作为一个整体有可能更加偏离实际的输出。 让输出逼近实际输出的最简单的例子 就是平方误差度量下线性神经元学习。 线性神经元，在电气工程中被称为线性滤波， 简单的讲输入带权重加和以后输出。 神经元对于目标输出的估计，输出Y， 等于所有输入i上，输入向量乘以权重向量后的加和。 我们可以将其用加法公式或者使用矢量公式形式化下来。 学习的目标是使所有的训练样本上错误的加和最小。 我们需要一个错误的度量，为了简单起见， 我们使用真实输出和实际输出误差的平方。 有个问题是我们干嘛不直接求解， 对于每一个训练样本，我们都可以写下一个等式， 然后很直接的对其进行求解，得到最优的权重。 这是标准的工程方法，为什么不这么做捏？ 第一个答案，或者说从科研而言，
我们试图理解真正的神经元如何工作， 其应该不是去推导求解了一堆等式。 从工程角度， 我们希望得到一种能泛化到多层，非线性网络的方法。 解析解局限于线性神经元和平方误差度量。 下面要谈的迭代法，效率较低， 但是容易泛化到复杂的系统。 下面我要讲解一个简单的例子，
说明迭代法是如何求解线性神经元的权重参数的。 假设每天中午你都在一个咖啡厅吃午餐。 你的食谱是鱼，薯条和番茄酱。 每天你都点不同份的鱼，薯条和番茄酱， 每天都不同份。 收银员仅仅告诉你这一餐的总价，
一些日子以后， 你应该能够说出每一种食物的单价。 迭代法中，你一开始随机的猜测食品的价格， 然后你对猜测进行调整 使得其更加符合收银员给出的价格， 即这一餐的总价。 所以每一餐，你都得到一个总价，
其给出了单个食品价格的一个线性约束。 这一餐的总价，等于 鱼的份数，x fish，乘以每份鱼的价格，w sifh， 对于薯条和番茄酱，同样如此。 食品的价格在这里类似于线性神经元的权重。 我们可以把整个权重向量看作为一份鱼， 一份薯条，一份番茄酱的价格。 我们开始猜测这些价格， 对其微调，使得其符合收银员给出的数字。 假设收银员收钱时使用的真实权重为 150一份鱼，50一份薯条，100一份番茄酱。 图示的一餐，花费了850。 这是我们的目标值， 假设我们开始猜测，每种食物的价格都是50。 对于两份鱼，5份薯条，3份番茄酱的一餐， 我们初始认为其价格是500。 这个使得我们有了350的残差， 残差试着我们使用目前的权重猜测的价格和
收银员给出来的价格的差异。 然后我们使用德尔塔定律来修正食品的价格。 我们对权重进行变化，delta Wi 等于学习率epsilon乘以第i个食品的份数，乘以残差， 即目标输出和我们估计值的差值。 这里我们将学习率设为1/35， 在这里学习率乘以残差等于10，计算会简单， 所以，鱼价格权重的变化应该为2乘以10， 我们要把鱼的价格加20. 薯条价格权重的变化是5乘以10。 番茄酱价格权重的变化为3乘以10。 这里我们得到70,100和80。 请注意，薯条的价格权重变得错误了。 这种学习算法不能保证每个单独的权重始终会变好。 变好的是收银员给出的价格 和我们估计的价格的差异。 现在我们来推导德尔塔定律， 我们从定义箭头所指的误差度量开始，
即训练集上的残差平方和。 其是目标值和神经网络或者线性神经元预测值差的平方。 其是目标值和神经网络或者线性神经元预测值差的平方。 我们在前面放置了一个1/2，其可以消去求导时的2。 然后我们开始用某个权重，Wi，对误导度量进行求导。 求导时我们需要使用链式法则。 链式法则说明了我们改变权重时错误度量是如何改变的， 其等于我们变化改变权重时输出的变化， 乘以我们改变输出是错误度量的变化。 链式法则很容易记忆，
你可以消去这两个DY， 不过有数学家在场可不要这么做哦。 第一个DY对DW，用了花体的D，这是因为其是偏导。 就是说，你可以改变很多的权重来改变输出， 在这里，你仅仅改变权重 i。 所以 DY 对DWi 求导，等于Xi。 因为 Y等于 Wi乘以Xi。DE对DY求导，等于T减去Y， 这是因为我们对T减去Y的平方求导，然后用1/2消去了2，
最后得到了T减去Y。 所以我们得到了学习的规则， 我们使用学习率 epsilon乘以错误度量E对权重wi的导数， 来对权重进行调整。 最前方加了负号，是因为我们想让错误变小。 这个负号可以和我们上面公式中得到的负号对消。 权重的变化等于所有训练样本上 学习率乘以输入值，乘以目标值和实际输出值之差的总和。 我们现在可以问，这个学习过程，德尔塔定律，是如何运行的咧？ 其最终能给出正确结果么？ 也许没有完美的答案。
我们可以给线性神经元一系列的训练样本 以及期望的输出， 但是并不存在能够产生期望输出的权重。 但是仍然存在一些权重，能够最好的近似训练样本， 最小化错误度量。 如果学习率最够的小， 学习时间最够长，我们是能逼近最好的解的。 另一个问题是我们多块能得到最优解。 即便是一个线性系统， 在这种复杂的学习过程中，学习也可能很慢。 如果两个输入维度高度相关，就很难 把两者之和分别对应到每个输入维度上去。 比如说，你总是点同样分数的番茄酱和薯条， 你就无法说明总价中那部分来自番茄酱， 那部分来自薯条。 如果它们总是保持这个比例 要想学到正确的 来正确区分番茄酱和薯条的价格。 在德尔塔定律和感知器学习定律之间，存在有趣的联系。 如果你使用德尔塔定律的在线版本， 在每个训练样本上修改权重， 就和感知器学习很相似了。 感知器学习中，预测错误时， 我们使用输入向量来增加或者减小权重向量。
德尔塔定律的在线版中， 我们也根据输入向量来增加或者减小权重向量， 不过还要乘以学习率和残差。 这里令人恼怒的是我们要选择一个合适的学习率。 如果选得太大，系统会不稳定。 如果选择的太小，则会花费很长时间才能 得到有意义的权重。