1
00:00:00,000 --> 00:00:05,312
在这个视频中 我将探讨为什么我们想要使用多个模型的结合

2
00:00:05,312 --> 00:00:09,360
进行预测 如果我有一个模型 我必须

3
00:00:09,360 --> 00:00:13,787
选择模型的容量 如果模型的容量太小 该模型

4
00:00:13,787 --> 00:00:17,140
将不能适应训练数据的一致性

5
00:00:17,140 --> 00:00:22,563
如果模型的容量过大 该模型将不能适应训练数据的样本错误

6
00:00:22,563 --> 00:00:27,784
通过结合多个模型 我们可以

7
00:00:27,784 --> 00:00:33,546
在拟合数据的一致性和过度拟合样本的误差之间

8
00:00:33,546 --> 00:00:36,530
取得一个更好的权衡 在这一讲的视频的开头

9
00:00:36,530 --> 00:00:41,841
我将证明当你一起使用各个模型
你可以期待这些模型

10
00:00:41,841 --> 00:00:45,340
将会比任何单一模型有更好性能 当这些模型

11
00:00:45,340 --> 00:00:48,339
每个模型都做出了非常不同的预测

12
00:00:48,339 --> 00:00:53,650
在这一讲视频的结束 我将会讨论

13
00:00:53,650 --> 00:00:56,900
可以鼓励不同模型
做出非常不同的预测的多个方法

14
00:00:57,340 --> 00:01:02,169
正如我们之前所见
当我们的训练数据有限 我们容易

15
00:01:02,169 --> 00:01:06,652
过度拟合这些数据 如果我们平均各个模型的

16
00:01:06,652 --> 00:01:10,240
不同预测 我们通常可以减少过度拟合

17
00:01:11,320 --> 00:01:16,220
这非常有用 特别是当各个模型都做出了非常不同的预测

18
00:01:17,620 --> 00:01:23,529
对于回归分析
squared arrow可以被分解为一个偏差项和

19
00:01:23,529 --> 00:01:26,946
一个方差项 这可以帮助我们分析正在发生什么

20
00:01:26,946 --> 00:01:30,768
如果模型只有很小的容量去适应数据

21
00:01:30,768 --> 00:01:35,177
偏差项会比较大 它能测量这个模型

22
00:01:35,177 --> 00:01:40,314
与真正的函数有多么不同 如果模型

23
00:01:40,314 --> 00:01:44,171
的容量很大 在我们特定的训练集里
可以很好地处理样本误差

24
00:01:44,171 --> 00:01:47,753
方差项会比较大 所以称之为方差 

25
00:01:47,753 --> 00:01:52,327
因为如果我们有另外一个训练集
有着相同的大小和分布 我们的模型

26
00:01:52,327 --> 00:01:56,846
将会对这个训练集有非常不同的拟合 因为它有不同的样本误差

27
00:01:56,846 --> 00:02:01,200
因此当用模型拟合不同的训练集时
我们将会得到方差

28
00:02:03,240 --> 00:02:08,067
如果我们将多个模型放到一起平均
我们正在做的是平均掉方差

29
00:02:08,067 --> 00:02:11,028
这将允许我们使用单独的

30
00:02:11,028 --> 00:02:14,825
有着大容量 以及高方差的模型 

31
00:02:14,825 --> 00:02:18,044
这些大容量模型通常有较低的偏差

32
00:02:18,044 --> 00:02:22,678
所以当我们有了更低的偏差
并且可以使用平均减少方差

33
00:02:22,678 --> 00:02:30,383
避免出现高方差
现在我们尝试一下并分析

34
00:02:30,383 --> 00:02:34,780
比较独立的模型和多个模型的平均吧

35
00:02:36,120 --> 00:02:41,275
在任何测试下 一些独立模型可能会比

36
00:02:41,275 --> 00:02:45,673
混合模型有更好的预测结果
不同的独立模型会

37
00:02:45,673 --> 00:02:50,497
在不同的情况下有更好的结果
如果这些独立模型的结果非常不同

38
00:02:50,497 --> 00:02:55,125
当我们平均所有测试例

39
00:02:55,125 --> 00:02:57,744
混合模型通常会有更好的预测结果

40
00:02:57,744 --> 00:03:02,616
所以我们要使独立模型有不同的结果
并且不会使他们

41
00:03:02,616 --> 00:03:06,270
性能下降
方法是使每个独立模型

42
00:03:06,270 --> 00:03:11,020
之间都有非常不同的误差
但是它们每个都是相当准确的

43
00:03:13,240 --> 00:03:17,603
现在我们来看看数学
已经当我们组合网络时会发生什么

44
00:03:17,603 --> 00:03:20,693
我们将会比较两种期望平方误差

45
00:03:20,693 --> 00:03:25,117
第一个期望平方误差是
如果我们随机选择一个模型

46
00:03:25,117 --> 00:03:28,814
用它做出预测

47
00:03:28,814 --> 00:03:33,843
然后我们平均所有的模型
如果我们按照这个方式

48
00:03:33,843 --> 00:03:39,899
得到的误差就是第一个期望平方误差
所以Y平均是

49
00:03:39,899 --> 00:03:44,145
所有模型预测结果的平均
Yi是其中一个模型的结果

50
00:03:44,145 --> 00:03:50,191
所以Y平均只是对Yi中所有独立模型i的总体期望

51
00:03:50,191 --> 00:03:56,093
我将会用这些尖括号表示期望

52
00:03:56,093 --> 00:04:00,700
所以尖括号就是表示
它是一个总期望

53
00:04:01,020 --> 00:04:06,560
我们可以将它写成
N分之1乘上所有N个模型的和

54
00:04:09,620 --> 00:04:14,405
现在如果我们观察期望平方误差
将会知道我们是否随机选择了

55
00:04:14,405 --> 00:04:17,005
模型
我们需要做的是比较

56
00:04:17,005 --> 00:04:20,195
模型和目标的
并对差进行平方

57
00:04:20,195 --> 00:04:25,040
再对所有模型平均
它也在左手边

58
00:04:25,300 --> 00:04:30,448
如果我简单得加上一个Y平均再减去一个Y平均
我不会改变它的值

59
00:04:30,448 --> 00:04:34,420
现在我们可以更容易地
对式子做一些整理

60
00:04:36,360 --> 00:04:43,753
我现在可以展开平方式
在期望括号里有t

61
00:04:43,753 --> 00:04:50,702
减去y平均并平方 yi减去y平均
t减去y平均 乘上yi减去y平均

62
00:04:50,702 --> 00:04:58,310
这样c会消失
所以第一项 T减去Y平均的差的平方

63
00:04:58,310 --> 00:05:03,457
不再有i
所以我们可以将这一项从期望括号里面提出来

64
00:05:03,457 --> 00:05:06,275
然后得到单独的T减去Y平均的差的平方

65
00:05:06,275 --> 00:05:11,238
如果你比较模型的平均和目标
这就是平方误差

66
00:05:11,238 --> 00:05:14,669
我们的目标是

67
00:05:14,669 --> 00:05:19,570
证明左边部分更大
就是通过使用平均 我们可以减少

68
00:05:19,570 --> 00:05:24,299
期望平方误差 所以右边的多余的项

69
00:05:24,299 --> 00:05:28,205
是y i 减去y平均的差的平方的期望 

70
00:05:28,205 --> 00:05:33,575
也就是yi的平方差
它是yi和y平均之间的

71
00:05:33,575 --> 00:05:37,849
期望平方差 然后消掉最后一项

72
00:05:37,849 --> 00:05:43,846
我们可以消掉它是因为
我们期望的Y到Yi的差是与

73
00:05:43,846 --> 00:05:50,065
网络的平均产生的误差和目标之间的差
是无关的

74
00:05:50,065 --> 00:05:53,397
所以我们乘上两个部分的

75
00:05:53,397 --> 00:05:59,320
平均是0 且无关的
我们期望平均是0

76
00:05:59,660 --> 00:06:06,321
所以结果我们通过随机选择模型
得到的期望平方误差

77
00:06:06,321 --> 00:06:12,904
它比我们通过平均模型的输出方差
得到期望平方误差大

78
00:06:12,904 --> 00:06:18,233
这是我们通过一个平均提高的量

79
00:06:18,233 --> 00:06:23,846
现在来看看这个图示

80
00:06:23,846 --> 00:06:28,755
沿着平行的线
我们有输出的可能值

81
00:06:28,755 --> 00:06:32,660
在这种情况下
所有不同的模型预测的值都太高

82
00:06:33,260 --> 00:06:38,078
这些离平均t很远的预测
会产生更大的平均方差

83
00:06:38,078 --> 00:06:43,210
就像那个红色的bad guy
那些比平均值离t更近的模型

84
00:06:43,210 --> 00:06:47,278
会产生更小的平方差

85
00:06:47,278 --> 00:06:51,346
第一种影响占主要位置
因为我们将会用方差

86
00:06:51,346 --> 00:06:56,352
所以从数学角度来说
让我们假设good guy和bad guy

87
00:06:56,352 --> 00:07:01,628
距离平均同样远
所以他们产生的平均方差

88
00:07:01,628 --> 00:07:06,182
是Y平均减去epsilon的平方加上
Y的平均加上epsilon的平方

89
00:07:06,182 --> 00:07:11,648
当我们算出这个式子
我们就得到的方差就是

90
00:07:11,648 --> 00:07:17,873
模型预测结果平均的平方加上epsilon的平方
所以我们通过平均预测结果

91
00:07:17,873 --> 00:07:22,048
在将他们与目标比较前得到我们想要的
这并不总是对的

92
00:07:22,048 --> 00:07:25,540
这非常依赖于使用平方差

93
00:07:25,840 --> 00:07:28,985
举例来说 如果你有很多钟表

94
00:07:28,985 --> 00:07:33,048
你想通过平均它们显示时间的方式
将它们调得更精确

95
00:07:33,048 --> 00:07:37,242
这无疑是一场灾难
因为你所期待的这些钟表的误差

96
00:07:37,242 --> 00:07:42,746
并不是高斯分布
你期待的是 很多表只有很小的误差

97
00:07:42,746 --> 00:07:48,185
其中很少一部分不走
或者有很大误差

98
00:07:48,185 --> 00:07:53,690
如果你平均的话
你只会让他们的误差更加错得离谱

99
00:07:53,690 --> 00:07:56,972
这同样可以应用到离散分布

100
00:07:56,972 --> 00:08:00,700
因为我们有标记分级的概率

101
00:08:01,760 --> 00:08:07,416
所以假设我们有两个模型
其中一个给了Pi概率一个正确的标签

102
00:08:07,416 --> 00:08:11,900
另外一个给了Pj概率一个正确的标签

103
00:08:13,120 --> 00:08:18,262
这时候最好随机选择
还是最好将两者的概率平均

104
00:08:18,262 --> 00:08:21,500
并预测Pi和Pj的平均

105
00:08:21,780 --> 00:08:26,820
如果我有一个log概率的可能性得到正确的结果
会怎么样?

106
00:08:27,200 --> 00:08:34,231
那么Pi和Pj的平均的log
将会好过Pi的log加上Pj的log然后再平均

107
00:08:34,231 --> 00:08:40,550
使用图像的话更好理解

108
00:08:40,550 --> 00:08:48,238
因为它是一个log函数的形状
所以黑色的线是log函数

109
00:08:48,238 --> 00:08:52,600
在水平轴上 我画了Pi和Pj

110
00:08:53,000 --> 00:08:57,500
那条黄色线 连接log Pi到log Pj

111
00:08:57,940 --> 00:09:04,608
你可以看到如果你首先从Pi和Pj一起开始

112
00:09:04,608 --> 00:09:10,100
在蓝色箭头上得到的平均
然后我们计算log 得到蓝色点

113
00:09:10,480 --> 00:09:16,103
虽然如果你首先计算Pi的log
并分开计算Pj的log

114
00:09:16,103 --> 00:09:21,215
然后我们平均两个log
得到黄色线的中点

115
00:09:21,215 --> 00:09:28,334
这个点比蓝色点低
所以我们那样做非常有优势

116
00:09:28,334 --> 00:09:33,252
我们希望我们的模型非常不同
要达到这个目的有很多种方式

117
00:09:33,252 --> 00:09:36,624
你可以直接依赖学习算法

118
00:09:36,624 --> 00:09:41,652
但效果并不好
每次都会卡在不同的局部优化

119
00:09:41,652 --> 00:09:44,412
所以说这样方式很不明智

120
00:09:44,412 --> 00:09:50,056
但是它依然值得去尝试
你可以尝试很多不同类型的模型

121
00:09:50,056 --> 00:09:53,509
包括不是神经网络的那些

122
00:09:53,509 --> 00:09:58,858
这使得尝试决策树变得很有意义
高斯处理模型 支持向量机

123
00:09:58,858 --> 00:10:02,176
我不会在这个课程中介绍它们

124
00:10:02,176 --> 00:10:05,765
在Coursera上Andrew Ng的机器学习课程中

125
00:10:05,765 --> 00:10:10,709
你可以学到那些知识
虽然你可以尝试很多不同的模型

126
00:10:10,709 --> 00:10:15,478
如果你真的想用一堆不同的神经网络模型

127
00:10:15,478 --> 00:10:20,115
你可以把它们变得不同
通过使用不同数量的

128
00:10:20,115 --> 00:10:24,580
隐藏层
或在每个层使用不同数量的单元

129
00:10:24,580 --> 00:10:27,214
或者不同类型的单元
类似于你在一些网络中可以使用

130
00:10:27,214 --> 00:10:30,649
修正线性单元
在另外一些网络你使用逻辑单元

131
00:10:30,649 --> 00:10:33,454
可以使用不同类型或强度的权重衰减

132
00:10:33,454 --> 00:10:36,831
所以你可能对一些网络使用提前停止策略

133
00:10:36,831 --> 00:10:41,240
以及对一些的一个L2权重惩罚
对另外一些的一个L1权重惩罚

134
00:10:42,320 --> 00:10:44,485
你可以使用不同的学习算法

135
00:10:44,485 --> 00:10:48,816
所以如果你的数据集足够小
对于一些例子来说你可以使用全批量full batch

136
00:10:48,816 --> 00:10:51,260
对另外一些实用迷你全量

137
00:10:51,260 --> 00:10:56,575
你也可以通过使用不同训练数据训练模型的方式
得到不同的模型

138
00:10:56,575 --> 00:10:59,397
有一种方式最初由Leo Breiman介绍

139
00:10:59,397 --> 00:11:04,646
称为套袋
你可以使用不同的数据子集得到不同的模型

140
00:11:04,646 --> 00:11:07,993
并且你能通过对训练集取样替换
得到子集

141
00:11:07,993 --> 00:11:12,456
所以我们对一个有样本A B C D的训练集取样

142
00:11:12,456 --> 00:11:16,590
得到五个样本

143
00:11:16,590 --> 00:11:21,315
但是我们会漏掉一些或者重复一些
我们训练一个模型在这个特定的训练集上

144
00:11:21,315 --> 00:11:25,328
这些会在一个称为随机森林的方法下完成

145
00:11:25,328 --> 00:11:30,330
它使用bagging结合了决策树
这也是由Leo Breiman参与发明的

146
00:11:30,330 --> 00:11:33,832
当你使用bagging训练决策树

147
00:11:33,832 --> 00:11:39,022
然后将它们平均
会好过任何单个决策树的

148
00:11:39,022 --> 00:11:41,887
事实上 连接箱子使用了随机森林

149
00:11:41,887 --> 00:11:46,848
来将关于深度的信息转换成
关于你的主体部分在哪的信息

150
00:11:46,848 --> 00:11:49,994
我们可以使用bagging结合神经网络

151
00:11:49,994 --> 00:11:53,261
但是这样代价很大
如果你想使用这种方式训练 比如说20个

152
00:11:53,261 --> 00:11:58,101
不同的神经网络
你需要有20个不同的训练集

153
00:11:58,101 --> 00:12:00,763
与训练单个网络相比
这将花费20倍的时间

154
00:12:00,763 --> 00:12:04,695
这对于决策树是没有关系的

155
00:12:04,695 --> 00:12:08,707
因为它们训练速度很快
并且在测试时 你需要运行

156
00:12:08,707 --> 00:12:12,908
20个不同的网络
对于决策树来说 这依然不是问题

157
00:12:12,908 --> 00:12:15,981
因为他们在测试时运行非常快

158
00:12:15,981 --> 00:12:20,997
另外一个制作不同训练数据的方法是
使用整个数据集训练每个模型

159
00:12:20,997 --> 00:12:24,948
但是给不同列子不同的权重

160
00:12:24,948 --> 00:12:29,337
所以在boosting 我们通常使用一系列
更小容量的模型

161
00:12:29,337 --> 00:12:33,100
然后我们给每个模型的训练例不同的权重

162
00:12:33,460 --> 00:12:38,079
我们将要做的事就是在前一个模型出错的时候
提高权重

163
00:12:38,079 --> 00:12:40,685
在前一个模型正确的时候
降低权重

164
00:12:40,685 --> 00:12:45,660
所以序列中的下一个模型
不会浪费它自己的时间去尝试对

165
00:12:45,660 --> 00:12:49,331
已经正确的情况做匹配
它使用它的资源去处理那些其他模型出错的例子

166
00:12:49,331 --> 00:12:55,721
boosting的一个早期使用目的是结合神经网络
处理MNIST

167
00:12:55,721 --> 00:12:59,138
在电脑非常慢的时候

168
00:12:59,138 --> 00:13:02,059
其中一个大优势就是它

169
00:13:02,059 --> 00:13:06,098
集中使用它的资源处理那些需要处理的例

170
00:13:06,098 --> 00:13:10,386
这样不会浪费很多时间
一次又一次得处理简单的例子