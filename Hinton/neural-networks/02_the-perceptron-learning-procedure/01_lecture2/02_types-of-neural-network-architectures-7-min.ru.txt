В этом видео я хочу описать различные типы архитектур нейронных сетей. Под архитектурой я подразумеваю способ связи нейронов между собой. На сегодняшний день наиболее распространенным типом архитектуры, применяемым на практике, является нейронная сеть прямого распространения, в которой вся информация приходит во входные элементы и движется в одном направлении через скрытые слои до тех пор пока не достигнет выходных элементов. Гораздо более интересной представляется архитектура рекуррентных нейронных сетей, в которых информация может двигаться циклично по кругу. Эти нейронные сети могу надолго запоминать информацию. Они способны выявлять самые разнообразные колебания, но они гораздо сложнее поддаются тренировке отчасти из-за того, что они могут решать гораздо более сложные задачи. Хотя, в последнее время человечество достигло значительных результатов в области тренировки рекуррентных нейронных сетей и сегодня такие сети способны делать действительно впечатляющие вещи.
Последний тип архитектуры, которую я опишу, это сеть с симметричной матрицей связей, такая, в которой весовые коэффициенты связи между нейронами равнозначны в обоих направлениях для двух связанных нейронов.
Наиболее часто применяются на практике нейронные сети прямого распространения. У такой сети есть несколько входных рецепторов — в первом слое снизу. Несколько выходных нейронов наверху и один или несколько скрытых слоёв. Если у сети более одного скрытого слоя, мы называем такую сеть глубокой нейронной сетью. Эти сети производят ряд изменений сигнала между входным и выходным слоями. Таким образом на каждом слое, вы получаете новое представление входных данных, в котором то, что было схожим в предыдущем слое, может стать менее схожим, либо данные, которые были различными в предыдущем слое, могут стать более схожими. Например, в распознавании речи мы хотим, чтобы одна и та же фраза произнесённая разными людьми, становилась всё более схожей, а разные фразы, произнесённые одним человеком, , становились бы всё менее схожими по мере прохождения слоёв в нейронной сети. Чтобы достичь этого, нам нужно, чтобы активность нейронов каждого слоя была нелинейной функцией активности предыдущего слоя. Рекуррентные нейронные сети - намного более мощный инструмент, чем нейросети прямого распространения. У них есть направленные циклы в графе их связей. Это значит, что если вы начинаете движение с вершины или нейрона и следуете по стрелкам, вы можете иногда возвращаться к нейрону, с которого вы начинали. У этих сетей может быть очень сложная динамика, и это может сделать их очень труднообучаемыми. В настоящее время есть много интересного в нахождении эффективных путей обучения данных [сетей], так как они очень производительны, если мы сможем их обучить. К тому же, они более реалистичны с бтологической точки зрения. Рекуррентные нейросети с множественными скрытыми слоями, в действительности, только частный случай рекуррентных нейросетей в целом, у которых потеряна часть связей между скрытыми слоями. Рекурентные нейронные сети - очень натуралистичный способ моделирования последовательных данных. Для этого мы устанавливаем связи между скрытыми элементами, и скрытые элементы со временем действуют как очень глубокая сеть. Так, в каждый момент времени состояния скрытых элементов определяют состояния скрытых элементов в следующий момент времени. Отличие от сетей прямого распространения в том, что здесь мы используем одни и те же веса связей в каждый момент времени. Таким образом, если вы посмотрите на эти красные стрелки, которые показывают как скрытые элементы определяют состояния следующих скрытых элементов, то матрица весовых коэффициентов, изображенная каждой из красных стрелок, одна и та же в каждый момент времени. Эти сети также принимают входные данные в каждый момент времени и часто выдают результат в каждый момент времени, и там тоже будут использованы одни и теже матрицы весов. Рекуррентные сети имеют возможность запоминать информацию в скрытом слое на долгое время. К сожалению, достаточно сложно обучить их использовать эту способность. Однако, последние алгоритмы стали способны это сделать. Итак, просто чтобы показать вам, что сейчас могут делать рекуррентные нейронные сети, я собираюсь показать вам сеть, разработанную Ильей Суцкевером. Это особый тип рекуррентной нейросети, немного отличающийся от типа, изображенного на диаграмме на предыдущем слайде, и она используется, чтобы предсказать следующую букву в последовательности. Итак, Илья обучал её на множестве и множестве строк из англоязычной википедии. Сеть видит английские буквы и пытается предугадать следующую английскую букву. На самом деле он использовал 86 различных символов, для учета пунктуации, и цифр, и заглавных букв и так далее. После обучения, один из способов увидеть, насколько хорошо сеть может работать, это посмотреть, присвоит ли она высокую вероятность следующему символу, который имеет место в действительности. Другой способ увидеть, что сеть может делать, это сгенерировать с её помощью текст. Что нужно сделать, это дать сети строку символов и позволить ей угадывать вероятности следующего символа. Затем вы выбираете следующий символ из этого вероятностного распределения. Не следует выбирать наиболее вероятный символ. Если вы будете так делать, то через некоторое время сеть начнет говорить: Соединенные Штаты Соединенных Штатов Соединенных Штатов Соединенных Штатов. Это говорит вам что-то о википедии. Но если вы выбираете из вероятностного распределения, то если сеть говорит, что у Z шанс 1 из 100, вы выбитаете Z один раз из 100, так вы узнаете гораздо больше о том, что сеть изучила. Следующий слайд содержит пример текста, который сгенерировала сеть, и интересно отметить, как много выучено только путем чтения википедии и в попытке предсказать следующий символ. Итак, помните, что этот текст был сгенерирован по одной букве за раз. Обратите внимание, что сеть составила разумные осмысленные предложения, и они все составлены полностью из реальных английских слов. Местами у неё получились неверно образованные слова, но они обычно понятны. И обратите внимание, что внутри предложения выдержана какая-либо тематика. Так, фраза: "Несколько ирландских спецслужб в Средиземноморском регионе", имеет проблемы, но написана на почти хорошем английском. Ещё заметьте, что говорится в конце о нечеткости изображения на любом дорогостоящем типе коробки принтера. Прослеживается определенная тематика, такая как изображения и принтеры, и синтаксис весьма хорош. И помните, что это - один символ за прогон. Весьма отличными от этих сетей являются нейросети с симметричной матрицей связей. В них связи между элементами имеют одинаковый вес в обоих направлениях. Джон Хопфилд и другие обнаружили, что сети с симметричной матрицей связей намного легче анализировать, чем рекуррентные сети. Так происходит главным образом потому, что они более ограничены в том, что они могут делать, так как они зависят от функции энергии сети. Так они не могут, к примеру, моделировать циклы. Вы не можете вернутося туда, откуда в начали, в одной из этих симметричных сетей.