В этом видео я собираюсь рассказать о трёх типах машинного обучения: обучение с учителем, обучение с подкреплением и обучение без учителя. Вообще-то всю первую половину курса мы будем обсуждать обучение с учителем. Вторая половина будет посвящена обучению без учителя. А обучение с подкреплением не будет затронуто в этом курсе, так как мы не можем охватить всё. Обучение может быть разделено на три больших группы алгоритмов. В обучении с учителем вы пытаетесь предсказать выходной сигнал исходя из входного вектора, так что смысл обучения с учителем ясен. В обучении с подкреплением, вы пытаетесь выбрать действия или их последовательность, которые ведут к получению наибольшего количества "поощрений", а поощрения могут возникать лишь время от времени.
При обучении без учителя вы пытаетесь выяснить наиболее приемлемое представление входных данных, а что это значит мы выясним позже. Обучение с учителем в свою очередь можно разделить на два различных направления. В регрессионном анализе целевым результатом является вещественное число или целый вектор вещественных чисел, к примеру цена акции через шесть месяцев или температура завтра в полдень. И цель - получить результат чтоль близкий, насколько это возможно, к верному значению. В классификации целью является метка класса. Простейший пример - выбор между единицей и нулем, между позитивным и негативным случаями. Но очевидно, что мы можем иметь несколько различных меток, как если мы классифицируем рукописные цифры. Обучение с учителем работает, изначально выбирая модель отношений, на всем наборе прецедентов, которые мы подготовили в качестве кандидатов. Модель отношений сожно считать функцией, которая на входе получает вектор и некоторые параметры и на выходе дает результат - y. То есть, модель отношений - это просто способ выявления соответствия входных данных и результата с использованием числовых параметров W. Затем мы подгоняем эти числовые параметры, чтобы соответствие подходило для обучающей выборке данных. Под словом "подходить" мы имеем ввиду минимизацию расхождения между целевым результатом по каждому обучающему примеру и реальным результатом, полученным системой машинного обучения. И очевидным измерением этого расхождения, если мы используем вещественные значения в качестве выходных данных, является квадрат разности между выходом нашей системы y и правильным результатом t, разделенный пополам, чтобы сократить двойку в производной. Для классификации вы могли бы использовать эту меру, но есть другие более подходящие способы, о которых мы поговорим позднее, и эти более подходящие способы обычно, к тому же, работают лучше. В обучении с подкреплением результатом является последовательность сигналов, и вы должны принимать решение по этим сигналам на основании спонтанных сигналов подкрепления. Цель, преследуемая при выборе каждого сигнала, в максимизации ожидаемой суммы будущих поощрений, и мы обычно используем дисконтирующий множитель, так что не нужно заглядывать слишком далеко в будущее. Мы считаем, что поощрения из далекого будущего не так важны, как поощрения, которые вы получите достаточно скоро. Обучение с подкреплением трудное. Оно трудно потому, что поощрения обычно отстают во времени, по этому сложно узнать, какой именно сигнал был ошибочным в длинной последовательности сигналов. Оно также трудно из-за того, что единичный сигнал подкрепления, особенно тот, что появляется лишь спонтанно, не дает много информации, на основании которой происходят изменения параметров. Так, обычно, вы не можете обучить миллионы параметров, используя обучение с подкреплением, в то время как при обучении с учителем и без учителя, можете. Обычно, в обучении с подкреплением вы пытаетесь обучить десятки параметров, или, может быть, 1000 параметров, но не миллионы. В этом курсе мы не можем затронуть всё, и поэтому мы не будем изучать обучение с подкреплением, дае несмотря на то, что это важная тема. Обучение без учителя будет рассмотрено во второй половине этого курса. На протяжении почти 40 лет сообщество машинного обучения в основном игнорировало обучение без учителя, за исключением некоторых очень ограниченных его форм, называющихся кластерами. Фактически, они использовали те определения машинного обучения, которые исключали его. Так, они определили машинное обучение в некоторых книгах как установление соответствия между входными и выходными данными. И многие исследователи считали, что кластеризация - единственная форма обучения без учителя. Одной из причин этого является то, что сложно сформулировать цель обучения без учителя. Одна из главных целей - получить внутреннее представление входных данных, это полезно для последующего обучения с учителем или обучения с подкреплением. И причина, по которой мы хотим делать это двумя стадиями, в том, что мы не хотим использовать, например, результаты обучения с подкреплением, для установки параметров нашей визуальной системы. Так вы можете вычислить расстояние до поверхности, используя неравенство между изображениями, которые получают два ваших глаза. Но вы не хотите учиться производить этот расчет расстояния, постоянно спотыкаясь и корректируя параметры вашей визуальной системы каждый раз, когда вы споткнулись. Вам пришлось бы спотыкаться очень большое количество раз и существуют намного лучшие способы научиться соединять два изображения, основываясь исключительно на информации из входных данных. Другие цели обучения без учителя - предоставить компактные, малой размерности представления входных данных. Так, такие входные данные большой размерности, как изображения, обычно, соотносятся прямо или косвенно с множеством образов малой размерности, или с несколькими такими множествами, как в случае с рукописными цифрами. Это значит, что даже если у вас есть миллион пикселей, то в действительности нет миллиона степеней свободы в том, что может получиться в результате. Возможно, будет лишь несколько сотен степеней свободы в результате, тогда наша задача - уйти от представления в миллион пикселей к сотням тысяч степеней свободы, которые будут говорить, соответственно, где мы находимся в множестве образов. Также нам нужно знать, какое множество мы рассматриваем. Очень ограниченная форма данного подхода - метод главных компонент, который является линейным. Он предполагает, что есть одно множество образов, и это множество - плоскость в пространстве высокой размерности. Другое определение обучения без учителя или другая цель обучения без учителя - получить экономичное представление входных данных c точки зрения выявленных признаков. Если, например, мы можем представить входные данные в бинарном виде, то это обычно экономично, так как тогда используется только один бит для обозначения состояния бинарного признака. Или же мы могли бы использовать большое количество признаков с вещественными значениями, но утверждать, что для каждого входного значения почти все эти признаки - нули. В этом случае для каждого входного значения нам нужно только предмтавить несколько вещественных чисел, и это экономично. Как я говорил ранее, другим определением обучения без учителя или другой целью обучения без учителя является нахождение кластеров входных данных, и кластеризация могла бы рассмартиваться в очень разделенном коде, когда мы имеем один признак на кластер и утверждаем, что все признаки, кроме одного, нулевые, и что один признак имеет значение единица. Так, кластеризация - действительно только крайний случай поиска разделенных параметров.