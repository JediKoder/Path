В цьому відео я збираюся описати деякі відносно прості моделі нейронів Я буду описувати декілька різних моделей починаючи з простої лінійної і порогового нейронів і потім, описшу трохи більш складні моделі. Ці значно простіші ніж справжні нейрони, але вони досі достатньо складні, щоб дозволити нам створювати нейронні мережі, що роблять дуже цікаві види машинного навчання. В порядку розуміння будь-чого складного, ми повинні ідеалізувати його. Саме так, ми повинні зробити спрощення, що дозволять нам мати розуміння того як воно могло б працювати. З атомами, наприклад, ми спрощуємо їх тим, що вини ведуть себе як маленька сонячна система Ідеалізація відкидає складні деталі, що не є суттєвими для розуміння головних принципів. Вона дозволяє нам використати математику для створення аналогів до інших відомих систем. І як тільки ми зрозуміємо основні принципи, це легко  - додати складності і зробити модель більш реалістичною звичайно, ми повинні бути обережними коли ми ідеалізуємо щось, не відкидаючи речі, які дають його головні властивості. Це часто додає зрозумілості моделям, які завідомо направильні, але ми повинні не забувати, що вони неправильні Наприклад, багато робіт по нейронних мережах використовує нейрони, що спілкуються дробними числами, замість дискретних імпульсів активності, і ми знаємо, що нейрони кори ведуть себе не так, але це досі більш зрозумілі системи і на практиці вони можуть бути корисні для машинного навчання. перший тип нейрону, про який я хочу розказати, це найпростіший, лінійний нейрон. Це просто Він обчислювально обмежений в тому, що він може робити Він може дозволити нам отримати розуміння більш складних нейронів Але він може ввестив оману. Так, в лінійному нейроні, вихід це Y. Це функція суми зсуву(константи b) і суми всіх вхідних зв'язків активності на вхідній лінії помножена на ваги на цих лініях, що є синаптичними вагами на вході і якщо ви намалюєте криву, тоді на осі Х, зсув(b) плюс зважені активності на вхідній лінії ми отримаємо пряму що проходить через нуль. Дуже відрізняється від лінійного нейрону бінарний пороговий нейрон, що був представлений Мак-Каллоком  і Пітсом. Вони насправді були натхненні Вон Ройманом, коли той думав про те, як створити універсальний комп'ютер В бінарному пороговому нейроні ви спочатку розраховуєте зважену сумму входів і потім ви посилаєте імпульс активності якщо ця зважена сума перевищть порог Мак-Каллок і Піт думали, що імпульси були лише правдивими значеннями з предикатів.  Так, кожен нейрон комбінуючи правдиві значення які отримані від інших нейронів для того щоб продукувати власні правдиві значення. І це як комбінуваня деяких предикатів для того щоб обчислити правдиве значення іншого предикату. В цей час в 1940 роках логіка була головною парадігмою стосовно того, як мозок повинен працювати. З тих пір люди що думали про те як мозок працює, стали більше цікавитися ідеєю того, що мозок комбінуючи багато різних джерел ненадійних доказів І так логіка це не така добра парадігма для того що мозок робить. Для двійкового порогового нейрону, ви можете думати про його вхідну/вихідну функцію як про зважений вхід що вище порогу дає вихідне значення для нього. В іншому разі, ві дає результат нуль. Це насправді два еквівалентні шляхи написати рівняння для бінарного порогового нейрону. Ми можемо сказати, що сумарний вхід Z це просто активність на вході помножена на ваги. І потім вихід Y це один з Z що вище порогу, або нуль в іншому випадку. Альтернатвно, ми можемо сказати, що загальний вхід включає поняття зсуву. Так, загальний вхід що приходить в вхідні лінії помножений на ваги плюз константа(b) І тоді ми зможемо сказати, що вихід одиниця якщо загальна сумма входів більша нуля і нуль в іншому випадку. І еквівалентність проста, тому що порог в першому формулюванні дорівнює негативному зсуву в другому формулюванні. Вид нейронів що комбінує властивості обох лінійних і бінарного порогового нейрону це пороговий(випрямлений) лінійний нейрон. Він спочатку розраховує лінійну зважену сумму його входів, а потім дає на виході таку нелінійну функцію цієї зваженої суми. Так ми обчислюємо Z так само як  іраныше. Якщо Z менше нуля, ми даємо вихід нуль. В іншому випадку ми даємо результат, що дорівнює Z Так, більше нуля  - це лінійний, и це нуль. Це родить вибір важким. Таким чином графік входу-виходу виглядає так. Це точно нелінійна (функція),  але вище нуля вона лінійна. Тож, з нейроном ек цей, ми можемо отримати велику кількість приємних властивостей лінійних систем коли він більше нуля Ми також можемо дати можливість приймати рішення в нулі Нейрони які ми будемо часто використовувати в цьому курсі і можливо найпоширеніший вид нейронів, що використовується в штучних нейронних мережах це сигмоїдні нейрони Вони дають дробові значення виходу, які є гладкою і обмеженою функцією їх сумарного входу. Типово використовують логістичну функцію, де суммарний вхід розраховується як раніше, як зсув плюс те що приходить з вхідних ліній, зважене. Вихід для логістичного нейрону це один на одиницю плюс е в ступені мінус суммарний вхід Якщо ви подумаєте про це, то суммарний вхід великий і позитивний Е в мінус великому позитивному ступені це нуль І так, вихід буде один. Якщо сумарний вхід великий і негативний, Е в мінус негативному ступені це велике число, і так вихід буде нулем. Так виглядає функція входу-виходу. Коли, загальний вхід нуль, Е в ступені мінус нуль це один, так вихід дорівнює половині. І добра відомість про сигмоїд, це те, що він має гладку похідну. Похідна змінюється монотонно І так вона добре себе поводить і вона робить навчання легшим, як ми побачимо в лекції три. Нарешті, стохастичні бінарні нейрони. Вони використовують таке саме рівняння як і логістичні елементи. Вони розраховують їх суммарний вхід так само і використовують логістичну функцію для розрахунку дробових значень, які є ймовірністю, що вони видадуть імпульс. Але замість того щоб видавати ймовірність як дробове число, вони насправді роблять ймовірністне рішення, і так ось що вони насправді виводять це тільки одиниця або нуль. Вони внутрішньо випадкові. Тобто, вони розцінюють P як ймовірність видачі одиниці, не дробове число. Звичайно, якщо вхід дуже великий, і позитивний вони майже завжди дають одиницю Якщо вхід великий і негативний, вони майже завжди повертають нуль. Ми можемо робити схожий трюк з пороговими лінійними  нейронами Ми можемо сказати що вихід це дробове значення , що приходить з порогового лінійного елементу, якщо його вихід більше нуля, це рівень продукування сигналу Це детерміністично. Але як тільки ми перевершили цей рівень продукування сигналу, насправді, варіанти в в яких сигнал буде згенеровано є випадковим процесом. Це Пуасонівський процес. Так, пороговий лінійний нейрон визначає рівень, але внутрішня випадковість в елементі визначає коли сигнал насправді виникне.