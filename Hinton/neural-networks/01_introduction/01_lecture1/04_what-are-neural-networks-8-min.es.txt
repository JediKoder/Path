En este vídeo voy a hablar un poco de 
las neuronas reales y el cerebro real que son fuente de inspiración para 
las redes neuronales artificiales que vamos a estudiar en este curso.
En gran parte del curso no hablaremos mucho sobre las neuronas reales pero quería 
darles un breve panorama en el comienzo. Hay varias razones para estudiar
como las neuronas pueden resolver cosas. Primero necesitamos 
entender cómo el cerebro trabaja en ralidad. Se podría 
pensar que podemos hacerlo haciendo experimentos en el cerebro. 
Pero es muy grande y complicado y muere cuando hurgamos en él. Necesitamos 
usar simulaciones en computadores que nos ayuden a entender qué estamos 
descubriendo en los estudios empíricos. En segundo término es necesario entender el estilo de 
computación en paralelo que se inspira en el hecho de que el cerebro resuelve con una 
gran red en paralelo un mundo de neuronas relativamente lentas.
Si podemos entender ese estilo de computación en paralelo podremos ser capaces 
de hacer mejores computadores paralelos Es una manera muy diferente de cómo 
se hace computación en un procesador convencional en serie. 
Debería ser muy bueno para esas cosas para las que el cerebro es muy bueno como la visión y 
debería ser malo para esas cosas en las que el cerebro es malo como la multiplicación de dos números entre sí La tercera razón que es la más relevante 
para este curso es el resolver problemas prácticos usando nuevos algoritmos
de aprendizaje que se inspiraron en el cerebro. Esos algoritmos 
pueden ser muy útiles aun cuando no sea la forma en 
que el cerebro realmente trabaja En gran parte del curso no hablaremos mucho 
sobre cómo el cerebro realmente trabaja. Solo lo usaremos como fuente de inspiración 
que nos dice como grandes redes de neuronas en paralelo pueden resolver 
cuestiones muy complicadas Hablaré más en este vídeo sobre 
cómo el cerebro realmente trabaja. Una neurona cortical típica tiene una 
estructura física gruesa que consiste en el cuerpo de la célula, un axón por el que envía 
mensajes a otras neuronas y un árbol de dendritas por las que recibe mensajes 
de otras neuronas Donde el axón de una neurona entra en 
contacto con el árbol de dendritas de otra hay una estructura llamada sinapsis.
Un pico de actividad viajando a lo largo del axón hace que se inyecte carga 
en la neurona post-sináptica en la sinapsis.
Una neurona genera picos cuando recibe suficiente carga en su árbol de dendritas 
para despolarizar una parte del cuerpo de la célula llamado el montículo del axón.
Y cuando eso resulta despolarizado, la neurona envía un pico a través de su axón.
El pico es una onda de despolarización que viaja 
a lo largo del axón Las propias sinapsis tienen 
una estructura interesante. Contienen pequeñas vesículas de 
transmisores químicos y cuando llega un pico en el axón provoca que esas 
vesículas emigren hacia la supervicie y sean liberadas dentro de la hendidura 
sináptica. Hay varias clases de transmisores químicos. 
Hay unos que implementan pesos positivos y hay otros 
que implementan pesos negativos Las moléculas transmisoras se difunden a través 
de la hendidura sináptica y se enlazan con las moléculas receptoras en el la membrana 
de la neurona post-sináptica y al enlazarse con esas moléculas grandes en la 
membrana cambian su forma y crean agujeros en la membrana. Esos agujeros 
permiten que determinados iones fluyan hacia dentro y hacia afuera de la neurona 
post-sináptica cambiando su estado de despolarización. Las sinapsis se adaptan, 
y eso es lo que la mayor parte del aprendizaje es, cambiando 
la efectividad de la sinapsis. Se pueden adaptar cambiando el número 
de vesículas que resultan liberadas cuando el pico llega, o cambiando 
el número de moléculas receptoras que son sensibles a las 
moléculas transmisoras liberadas. Las sinapsis son muy lentas en comparación 
con la memoria de un computador pero tienen gran cantidad de ventajas 
sobre la memoria RAM de un computador. son muy pequeñas y de muy bajo 
consumo de energía. Y se pueden adaptar. Esa es la propiedad más importante.
Usan señales disponibles localmente para cambiar su fuerza y así es como
aprendemos a realizar cálculos complicados. La cuestión, por supuesto, es 
cómo deciden como cambiar su fuerza. Cuáles son las reglas que siguen para adaptarse. En una sola diapositiva, así es 
como funciona el cerebro. Cada neurona recibe entradas de otras neuronas. Algunas neuronas reciben entradas 
desde los receptores Es un gran número de neuornas pero 
solo una pequeña fracción de ellas. Y las neuronas se comunican entre ellas 
en la corteza cerebral enviando estos picos de actividad. La efectividad 
en la entrada de una neurona está controlada por el peso sináptico 
que puede ser positivo o negativo. Y esos pesos sinápticos se adaptan. 
Y al adaptarse la red completa aprende a realizar diferentes clases de cálculos. Por ejemplo a reconocer objetos, 
entender el lenguaje, hacer planes, controlar los movimientos de tu cuerpo.
Tienes alrededor de diez a la once neuronas, cada una de las cuales tiene 
alrededor de diez a la cuarta pesos. Probablemente tengas diez a la quince 
o quizás diez a la catorce pesos sinápticos. Y un enorme número 
de esos pesos, una gran parte pueden incidir en el cálculo que se 
está efectuando en una muy pequeña fracción de segundo, en algunos milisegundos. Es un ancho de banda para almacenar 
conocimiento mucho mejor que el que tiene la mejor y más moderna estación de trabajo.
Por último podemos señalar que la corteza cerebral es modular. 
Al menos aprende a ser modular Porciones diferentes de la corteza 
terminan haciendo cosas diferentes Genéticamente, las entradas desde los sentidos 
van a diferentes porciones del cerebro y eso determina mucho de lo que terminan haciendo. Si se daña una parte del cerebro de un adulto,
ese daño puntual tiene un efecto específico.
El daño en un sitio puede hacerte perder tu habilidad de entender el lenguaje.
El daño en otro punto podría provocarte la pérdida de capacidad de reconocer objetos.
Sabemos mucho sobre dónde están localizadas las funciones en el cerebro porque cuando
usas una parte del cerebro para hacer algo gastas energía y eso demanda más flujo de sangre
y se puede ver el flujo sanguíneo en un escáner cerebral.
Te permite ver qué porciones estás usando para realizar una determinada tarea.
Pero lo remarcable acerca de la corteza cerebral es que se ve igual en todas partes 
y eso sugiere fuertemente que  contiene un algoritmo de aprendizaje universal y bastante flexible Y eso también surge del hecho de que si 
el daño en el cerebro es a temprana edad esas funciones relocalizarán en otras partes del cerebro.
De modo que no está genéticamente predeterminado, al menos, no directamente, qué 
parte del cerebro realiza qué función Hay experimentos convincentes en 
crías de hurones que demuestran que si cortas la entrada a la corteza cerebral 
que llega de los oídos, y en su lugar se la reencamina la entrada visual a la corteza auditiva, 
entonces la corteza auditiva que estaba destinada a procesar sonidos aprenderá a 
tratar con entradas visuales y producirá neuronas que se verán similares a las del sistema visual. Eso sugiere que la corteza está hecha de 
materia de propósito general que tiene la habilidad de transformarse en un hardware de próposito 
específico para una tarea en particular, en respuesta a la experiencia.
Y nos da una linda combinación de cálculo paralelo veloz, una vez que 
se ha aprendido, más flexibilidad de modo que se puede aprender nuevas funciones;
estás aprendiendo a ejecutar cálculos en paralelo. Es como la tecnología FPGA donde se  
construye un hardware paralelo estándar, y luego de construido, se le pone información 
que le dice que cálculo paralelo en particular debe hacer. Los computadores convencionales logran flexibilidad ejecutando un programa secuencial almacenado. Pero eso requiere de un procesador central 
muy rápido que acceda a las líneas de programa secuencial y realicen 
largos cálculos secuenciales.