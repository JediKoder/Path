大家好, 欢迎来到Coursera上的 机器学习的神经网络课程。在我们学习神经网络学习算法的细节之前， 我想先谈一谈机器学习， 为什么我们需要机器学习，我们利用其所做的事情，此外我还会 展示一些具体例子。我们需要机器学习，是因为 有些问题，非常难以（直接）编写代码来解决, 比如 识别三维物体。在杂乱无章的场景，每个视角和 光照的变化都让问题无比困难。 我们不知道如何编写代码，是因为我们还不知道我们的大脑是如何做到这一点的。 就算我们知道如何编写这个程序， 其势必会异常的复杂。 另一个例子是检测信用卡交易中的欺诈行为，这里应该 不存在任何简单，可靠的规则来判断一笔交易是否欺诈。 你必须组合大量不那么可靠的规则来实现判断。 还有，这些规则必须时时更新，因为坏人也会变化欺诈的手法。 所以，我们需要实现一个复杂的程序 其能够组合不可靠的规则，
同时我们能够方便的对规则进行修改。 机器学习，简言之，并不针对每一个特定的任务 来编写特定的程序，
相反，我们收集了大量的样例， 对给定的输入给出正确的输出。 然后机器学习算法可以利用这些样例，
生成一个能够完成指定任务的程序。 线性算法产生的程序 和典型的手工完成的程序有着非常大的差异。 比如，其可能包含了上百万个参数，
这些参数定义了各种输入证据的权重。 如果一切顺利，这个程序应该能够 不仅在训练数据，同时在新的数据上也工作的很好。 如果数据发生变化，我们能够很容易的
通过重新训练来对程序进行升级。 如今大规模计算所需代价越来越小 如今大规模计算所需代价越来越小 所以我们能够负担使用复杂的机器学习程序
来产生针对特定任务的程序。 机器学习最擅长的事情， 比如模式识别， 在真实的场景中识别物体，
人脸或者表情 或者所说的话。
此外还有异常检测， 比如一系列不寻常的信用卡交易
可能是异常的。 在比如核电站传感器上读取出来的不寻常的模式
也是异常的一个例子。 这些场景监督学习 往往不是很适用。 当什么地方出了差错，
你试图找出其中的原因。 你要在没有任何样本信号的情况下找出 让人感兴趣的东西，它们表现的和正常情况大不一样。 第三种任务是预测。比如预测股票价格 或者外汇牌价，
或者根据人们喜欢的电影来预测 其对其他电影的喜好。
或者预测那些电影是被特定人群喜欢的。 在这个课程里，我们使用一个标准的例子 来解释一系列的机器学习算法。 在科学研究中这是很普遍的情形。
比如在基因研究中， 很多工作在果蝇上进行。
原因是这样很方便。 果蝇繁殖很快，而且我们对果蝇的基因
所知甚多。 MNIST手写数字数据集
在机器学习领域等同于果蝇。 其可以公开获取。
我们可以让机器学习算法 快速的学习如何识别这些手写体，
从而让我们可以尝试算法的多种变化。 我们已经对各种算法 在MNIST数据集上的表现所知甚多。 特别的，这些特定算法都是由相信它们的人来实现的， 我们可以信任相应的结果。 所以，我们会使用MNIST作为我们的标准任务。 这里是MNIST数据集中的一些例子。 神经网络可以在第一次看见这些
数字的时候就可以准确的识别他们， 但是神经网络对识别结果的置信度并不高。 这样也是显而易见的。 我安装标准扫描线次序排列了这些数字。 这里有0，1，2以及其他的数字。 如果你已经知道这里有100个数字， 你可能会猜测这些是2. 如果你已经知道这里有100个数字， 他们之间并没有共同的简单特征。 如果将这些符号两两重叠起来，
你会发现他们并不重合。 你甚至可以将符号进行轻微的扭曲，
但是还是很难将其两年重叠在一起。 所以，模板在这里并不能解决问题。
一个特定的模板 很难识别绿色方框中的‘2’，
但却有误识别红色方框中的其他符号。 这就使得手写数字识别 是机器学习能够解决的一个好任务。 这些梳理 实际上，这对我们的机器学习系统而言，
是相对简单的事。 为了让大家更了解课程 比如当前我们的神经网络具有上亿个参数，
能够识别 具有上亿个参数，
能够识别 从网络上获取的130万张高清图片中的
1千种不同的物体类别。 2010年开始，有一个相关的竞赛 当时最好的系统在只输出一个选择的时候
能达到47%的错误率。 在输出5个选择，只要其中之一命中的情况下，
错误率为25% 对于1000个类别来说，这个成绩算不错了。 Jitendra Malik是一个著名的神经网络怀疑论者，
计算机视觉研究的领军人物， 曾经说这个竞赛是一个
验证深度神经网络能否很好的适用于 物体识别的好机会 如今，深度神经网络能 赢得竞赛的系统做的更好。
输出一个结果的时候，错误率低于40% 输出5个结果的时候，
错误率低于20%。 我将在讲座5进行更详细的介绍。 这里有有一些你要识别的
图像的例子 这些图像来自测试集，
之前（即训练时）没有出现过。 在图片下方，
是神经网络输出其认为的正确结果。 横条的长度代表 相应答案的可靠程度，然后正确的
答案会被标红。 所以中间一幅图片中，雪犁
被正确的识别了出来。 但是你如果观察其他答案，
其实也是相关的。 其看上去很像一个钻井
平台。 如果你看第三个答案，
救生艇，这个图片看上去很像救生艇。 你可以看到救生艇首的旗帜, 救生艇的舰桥，艇尾的旗帜 所以这个错误答案能够告诉我们很多 其是如何工作 如果你观察左边的图片，
其出错大概是因为鸟的嘴部不在图片内， 而且鸟的羽毛
看上去很像潮湿的水濑的皮毛。 但是正确答案在最高的五个输出中，
而且其表现的比我好。 我并不知道这张图片是否是鹌鹑，
流苏松鸡或者是鹧鸪。 如果你看右边，
答案完全错误。 一个断头台，你应该知道其为什说。
你也应该能够知道 猩猩也是答案，因为
背景中大片的丛林以及中间的橙色。 但是其没有给出正确的答案。 但是，其能够识别很大范围内的不同物体。 如果看左侧，
我会说微波炉是我的首选答案 标签并没有体系化，
所以正确的答案是电磁炉灶。 这个答案在5个输出中。 中间，是十字闸机，
是一个分体的物体。 所以其不仅仅能够识别
紧凑的物体。 起不仅仅能处理图片，
也能在真实场景有效，比如右侧的防弹背心。 其也能犯一些非常有意思的错误， 看左边的图片，
这是一副耳机。 没有任何输出结果和耳机相似，
但是如果请注意第四个答案， 其认为这是蚂蚁。
这真让人惊叹！ 如果你仔细观察，
你可以看到这是一个从地下视角看到的蚂蚁。 蚂蚁的眼睛向下盯着你， 你能看到之后的触角。
It's not the kind of view of an ant you'd 不是你希望看到的蚂蚁。
如果你看右侧， 其并没有输出正确答案。
但是其所有的答案都是圆柱体。 神经网络现在擅长的另一个领域 是语音识别，或者说语音识别系统的一部分。 一个语音识别系统可以有几个步骤， 首先是声波的预处理， 将每10毫秒的声波
转换成声音系数的向量。 我们每秒中可以得到100个这种向量。 然后取出相邻的一系列向量，
开始判断 这是发音的那个音素的那一部分。 所以他们考察这个小窗口，
在窗口的中间 这是应该是哪一个音素，
是音素的那一部分？ 一个好的语音识别系统
对于一个音素，应该有许多供选择的模型。 每个模型，有三个不同的部分。 所以你可能会有成千上万个 供选择的片段。 你不得不对其都进行相应的判断。 进行判断后，
进入解码阶段， 选择合情合理的判断，
将其组织成一个判断结果的序列 从而和人们所说的话对应起来。 目前, George Dahl 和 Abdel-rahman Mohammed
探索的深度神经网络 比之前其他机器学习声学模型表现都要好。 并已经开始在实际系统中使用。 Dahl和Mohammed，开发了一个系统 使用了很多层二元神经元的网络，
以声学 他们是在一个相对很小的数据库上实现的 使用了183个可选的标签。 为了让系统更好的工作，
他们做了预训练，这将 在课程的后半部分进行描述。 使用标准的后处理环节后，
他们得到20.7%的错误率。 该基础测试相当于语音领域的MNIST。 之前在该基础测试集上最好的语音识别结果 是24.4%。
来自微软的资深语音识别专家 意识到，
这是一个突破性的提高， 足以改变语音识别系统的构建方式。 实际上的确是这样。 微软展示了这种深度神经网络 将其用于语音识别系统的声学模型 将错误率从27.4%降为18.5%，
或者换算成所需的训练数据， 你所需的训练数据将从2,000小时减少到309小时 但是还能得到相似的性能。
IBM拥有最好的 标准语音识别系统， 高度优化以后错误率为18.8%，
可以被 深度神经网络击败。 此外，Google最近使用了
近5800小时的语音数据 训练了一个神经网络，
这比他们训练混合模型使用的数据小得多。 即使用了少的多的数据， 其性能要不之前的模型好得多。 其将错误率从16%降至12.3%, 
并还在持续改进中。 在最新一代Android中，
如果你 使用语音搜索，
深度神经网络将会被用到， 以提供很好的语音识别。