В цьому відео я збираюсь показати вам приклад машинного навчання Це дуже простий вид нейронних мереж і він буде навчений розпізнаванню цифр І ви зможете побачити як ваги еволіюціонують так як ми запустили дуже простий алгоритм навчання Так, ми збираємся подивитися дуже простий алгоритм навчання дуже простої мережі для розпізнавання рукописних знаків. Мережа  має два шари нейронів Вона має вхідні нейрони чия активність показує інтенсивність пікселів і вихідних нейронів, чия активність репрезетує класи Це буде схоже на те, коли ми показуємо конкретний символ, вихідний нейрон для цього символу активується Якщо піксел активний, він голосує за конкретний символ Формально, символи складаються з символів Кожен піксел може голосувати за декілька символів і голоси будуть мати різну інтенсивність, символ який отримає більше голосів - переможе Так, ми вважаємо що це буде змагання між вхідними елементами і ще дещо, що я ще досі не пояснив. буду пояснювати пізніше в лекціях Перш за все, нам необхідно вирішити як відображати ваги. І природно виглядає писати ваги на з'єднаннях між вхідними елементами та вихідними. Але ми не будемо мати можливості що відбувається, якщо ми це отримаємо. Нам необхідно відображати так, щоб ми могли бачити значення тисяч ваг. Ідея для кожного виходу ми зробимо маленьку карту. І на цій карті ми покажемо силу з'єднання, що приходить з кожного вхідного піксела з місця розташування вхідного піксела. І ми покажемо силу з'єднання використовуючи чорно-білі ділянки, чия площа буде показувати магнітуду. і чий знак буде представлятися кольором. Так, початкові ваги що ви бачите це просто малі випадкові ваги Зараз, що ми збираємось робити, це показати мережі певну кількість даних і відправити її вивчати ваги, що є кращим за випадкові ваги. шлях, який ми збираємся розглянути, це коли ми показуємо зображення ми збираємося збільшити ваги активних пікселів зображення, для коригуваня классу. як тільки ми  це зробимо, ваги можуть збільшуватися яке б ми зображення не показали. Таким чином, мипотребуємо способу тримання ваг під контролем Що ми збираємось робити  - ми також будемо зменшувати ваги активних пікселів, классу до якого віднесе нейронна мережа. Таким чиномми тренуємо робити правильний вибір, замість того, до яких вона має схильність. Якщо, звичайно вона робить правильний вибір, тоді збільшення, що миробимо на першому кроці навчального правила будуть повністю скасовувати зменшення, так нічого не зміниться, цете що ми хотіли. Ось  це  початкові ваги. Зараз мизбираємось показати декілька сот тренувальних зразків і потім подивимся на ваги знову. Зараз ваги змінилися, вони починають формувати звичайні символи. Покажемо ще декілька сот зразків Ваги трохи змігились, і ще декілька сот зразків. і ще декілька сот зразків. Ще трохи сотень. І зараз ваги значно( кращі ) в їх фінальних значеннях Я розкажу більше в майбутніх лекціях про обчислювальні деталі навчального алгоритму Але що ви можете побачити це те, що ваги зараз виглядають як маленькі шаблони символів. Якщо ви поглянете на ваги елемента один, наприклад, це не геть шаблон для ідентифікації одиниці. Це не просто зразок. Якщо ви подивитесь на ваги елемента дев'ять вони не мають жодної позитивної ваги нижче середньої лінії це для того щоб позначити різницю між 9ою і 7ою, ваги нижче середине не дуже використовувалися. Ви повинні сказати різницю вирішуючи чи є петля зверху, чи горизонтальноа полоса зверху. Таким чином, ці вихідні елементи сфокусовані на дискримінації Одна річ про цей алгоритм навчання пов'язана з тим, що мережа дуже проста, немає можливості вивчити дуже добрий спосіб відділення символів. Все що вона вчить еквівалентно маленкому шаблону для кожного з символів. І потім, вибір переможця базужться на тому, який з символів має шаблон, шо покриває більшу частину з написаного. Проблема в тому, що ваги в яких рукописні символи розрізняються занадто складні для розпізнавання простим шаблоном всього символа. Ви маєте модель що дозволяє варіацію цифр. Визначіть спочатку властивості і потім знайдіть розташування цих властивостей Цеприклади, якіми вже бачили. Якщо ви подивитеся на цю двійку в зеленому квадраті, ви зможете побачити що тут немає шаблону, що добре все покриває і дає збій покриваючи трійку в червоному квадраті. Тобто задача просто не може бути розв'язана такою простою мережею як ця. Нейронна мережа робить найкраще з того, що може, але не може розв'язати проблему.