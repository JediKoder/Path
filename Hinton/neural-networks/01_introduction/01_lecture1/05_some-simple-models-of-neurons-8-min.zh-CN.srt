1
00:00:00,000 --> 00:00:05,013
在这个视频中 我将介绍一些相对简单的神经元模型

2
00:00:05,013 --> 00:00:10,081
我将介绍几种不同的模型
首先是简单的线性阈值神经元

3
00:00:10,081 --> 00:00:14,088
然后还会介绍一些稍显复杂的模型

4
00:00:14,088 --> 00:00:20,028
虽然这些模型比真正的神经元简单得多
但它们仍然具有足够的复杂性

5
00:00:20,028 --> 00:00:25,035
足以允许我们用来构成神经网络
开展一些有趣的机器学习

6
00:00:25,035 --> 00:00:28,083
为了理解一个复杂的东西

7
00:00:28,083 --> 00:00:34,050
我们必须对其进行理想化
即做一些简化

8
00:00:34,050 --> 00:00:38,036
使得我们能够初步理解它是如何工作的

9
00:00:38,036 --> 00:00:44,025
打个比方 我们把原子内部运行简化成微小的太阳系

10
00:00:45,015 --> 00:00:49,019
理想化的过程去除了那些对于理解主要规律
并不关键的复杂细节

11
00:00:49,019 --> 00:00:54,010
这使得我们能够对其进行数学处理

12
00:00:54,010 --> 00:00:58,096
并与其他相似系统进行类比
一旦我们理解了基本原理

13
00:00:58,096 --> 00:01:03,088
就可以增加模型的复杂性
让它能更好地还原现实

14
00:01:03,088 --> 00:01:07,003
当然 在理想化的过程中 我们要特别小心

15
00:01:07,003 --> 00:01:11,055
不能简化掉那关系到主要性质的东西

16
00:01:11,055 --> 00:01:15,060
去了解那些已经被认为是错误的模型

17
00:01:15,060 --> 00:01:19,035
常常是值得的 只要我们别忘了它是错的

18
00:01:19,035 --> 00:01:24,000
比如说 很多神经网络的研究使用的神经元
相互传递的是实值

19
00:01:24,000 --> 00:01:28,083
而不是离散的活动峰值
我们知道真正的脑细胞并不是这样工作的

20
00:01:28,083 --> 00:01:33,060
但这些系统依然值得我们去理解

21
00:01:33,060 --> 00:01:37,000
在机器学习中他们其实是非常有用的

22
00:01:37,095 --> 00:01:42,081
我要介绍的第一种神经元是最简单的线性神经元

23
00:01:42,081 --> 00:01:44,055
它很简单

24
00:01:44,055 --> 00:01:47,089
它所能做的在计算上有所限制

25
00:01:47,089 --> 00:01:52,030
它能让我们深入探究更复杂的神经元

26
00:01:52,052 --> 00:01:59,085
但它也可能会有一点误导倾向
回到正题 在一个线性神经元中 输出Y

27
00:02:00,018 --> 00:02:05,067
是这个神经元的偏置 (bias) b 以及

28
00:02:05,067 --> 00:02:11,075
所有的输入连接与其对应的突触权值的乘积
的函数

29
00:02:11,075 --> 00:02:17,069
如果将它画出来

30
00:02:17,069 --> 00:02:23,062
X轴是偏置加上加权和

31
00:02:23,062 --> 00:02:26,081
将会得到一条过原点的直线

32
00:02:30,069 --> 00:02:34,086
和线性神经有很大不同的
是阈值型神经元

33
00:02:34,086 --> 00:02:39,014
这个模型由麦卡洛克和皮兹发明
他们实际上在冯诺依曼思考如何设计通用计算机时

34
00:02:39,014 --> 00:02:42,036
对其造成了不少影响

35
00:02:43,090 --> 00:02:49,096
在阈值型神经元中
你首先计算输入信号的加权和

36
00:02:49,096 --> 00:02:56,009
如果加权和超过了阈值
则发出一个峰值信号

37
00:02:56,069 --> 00:03:01,040
麦卡洛克和皮兹认为
这些峰值就像是一系列命题的真值

38
00:03:01,040 --> 00:03:04,057
每个神经元

39
00:03:04,057 --> 00:03:09,003
通过组合它从其他神经元得到的真值
来产生它自己的真值

40
00:03:09,003 --> 00:03:13,062
这就像组合一些命题
来计算另外一个命题的真值

41
00:03:13,062 --> 00:03:17,078
在1940年代 逻辑被认为是大脑工作的主要模式

42
00:03:17,078 --> 00:03:24,006
从那时起 那些在思考大脑如何工作的人

43
00:03:24,006 --> 00:03:29,039
将兴趣更多地转移到了

44
00:03:29,039 --> 00:03:33,069
大脑是如何组合大量不同来源的不可靠的数据

45
00:03:33,069 --> 00:03:38,052
所以逻辑并不是决定大脑如何运行的一个好的模式

46
00:03:39,043 --> 00:03:44,041
对于一个阈值型神经元来说
你可以把它的输入输出函数

47
00:03:44,041 --> 00:03:48,070
看做决定于加权和是否高于阈值
如果是的话 则输出为1

48
00:03:48,070 --> 00:03:55,022
否则 输出为0
实际上有两种等价的方式

49
00:03:55,022 --> 00:03:57,097
来给出阈值型神经元的激活方程

50
00:03:58,024 --> 00:04:04,087
我们可以说 
总的输入z 就是各输入信号乘上对应的权重 之和

51
00:04:04,087 --> 00:04:09,024
如果z 大于阈值 则输出Y为1

52
00:04:09,024 --> 00:04:15,031
否则为0
或者我们也可以说

53
00:04:15,031 --> 00:04:20,018
输入还包含了一个偏置量
所以总的输入就等于

54
00:04:20,018 --> 00:04:23,066
各输入信号乘上对应权重 之和
再加上一个偏置量

55
00:04:23,066 --> 00:04:29,063
然后如果 总输入大于0 则输出为1

56
00:04:29,063 --> 00:04:33,004
否则 输出为0
等价性是显而易见的

57
00:04:33,004 --> 00:04:38,074
第一个方程中的阈值
就等于第二个方程中的偏置量的负值

58
00:04:38,074 --> 00:04:44,049
一种结合了

59
00:04:44,049 --> 00:04:49,033
线性和阈值型神经元性质的神经元
就是分段线性神经元

60
00:04:49,033 --> 00:04:54,051
它首先计算所有输入的权重和

61
00:04:54,051 --> 00:04:59,025
但是它的输出并不是这个权重和的线性函数

62
00:04:59,025 --> 00:05:04,042
即我们按照之前的方法计算权重和 z

63
00:05:05,010 --> 00:05:08,054
如果 z 小于0 则输出为0

64
00:05:08,054 --> 00:05:12,006
否则 输出为z

65
00:05:12,006 --> 00:05:16,073
可以看到 z大于0的部分是线性的
而等于0时 则是不连续的

66
00:05:16,073 --> 00:05:23,016
所以输入输出的曲线看起来是这样的
它显然不是线性的 但对大于0的部分

67
00:05:23,016 --> 00:05:27,022
它却是线性的
使用这样一个神经元

68
00:05:27,022 --> 00:05:32,027
我们能在大于0的部分
得到线性系统的很多优良性质

69
00:05:32,027 --> 00:05:36,063
我们也可以在等于0的地方
做出决策

70
00:05:40,036 --> 00:05:45,032
这门课程中我们使得很多的一种神经元
可能也是在人工神经网络中

71
00:05:45,032 --> 00:05:50,016
使用得最广泛的神经元
是S型神经元

72
00:05:50,016 --> 00:05:55,044
这种神经元的输出它的总输入的
一个平滑而有界的函数

73
00:05:55,044 --> 00:05:59,051
通常使用的是逻辑函数 (logistic function)

74
00:05:59,051 --> 00:06:05,042
总输入z 的计算方式和之前相同
即偏置量

75
00:06:05,042 --> 00:06:10,046
加上权重和
其输出则是

76
00:06:10,046 --> 00:06:13,095
1 加上 e的负z次方分之一

77
00:06:14,025 --> 00:06:19,014
想一想 如果权重和是个很大的正数

78
00:06:19,014 --> 00:06:22,069
取反之后放到e的指数位
结果将接近0

79
00:06:22,069 --> 00:06:28,021
所以整个输出将会是1
如果权重和是个绝对值很大的负数

80
00:06:28,021 --> 00:06:34,044
那么指数项将会是个很大的正数
整个输出将会是0

81
00:06:34,044 --> 00:06:38,045
所以输入输出函数看起来就像这样

82
00:06:38,045 --> 00:06:42,016
当总输入时0时

83
00:06:42,016 --> 00:06:48,074
e 的0次方是1 所以输出就是0.5
S型曲线的一个优良性质是

84
00:06:48,074 --> 00:06:53,047
它有光滑的导函数
即它的导函数是连续的

85
00:06:53,047 --> 00:06:59,089
这些优良性质 
让我们更容易使用它来进行学习

86
00:06:59,089 --> 00:07:04,069
正如我们将在第三讲里看到的那样
最后是随机性阈值型神经元

87
00:07:04,069 --> 00:07:07,098
这种神经元使用与逻辑型神经元一样的方程

88
00:07:07,098 --> 00:07:13,027
它首先按同样的方法计算出总输入
然后用逻辑函数计算出一个实数

89
00:07:13,027 --> 00:07:18,018
这个实数将作为输出信号的概率

90
00:07:18,018 --> 00:07:23,028
它并不是直接输出这个概率

91
00:07:23,028 --> 00:07:28,070
而是基于这个概率做一个选择
它的输出实际上是要么1 要么0

92
00:07:28,070 --> 00:07:30,089
从本质上来说 这个输出的随机的

93
00:07:32,025 --> 00:07:36,075
所以这种神经元将 p 作为输出为1 的概率
而不是一个实际的输出

94
00:07:36,075 --> 00:07:39,089
当然 如果总输入是非常大的正数

95
00:07:39,089 --> 00:07:42,079
输出将几乎总是1

96
00:07:42,079 --> 00:07:47,004
如果输入是一个绝对值很大的负数
那么输出将几乎总是0

97
00:07:48,045 --> 00:07:52,067
我们可以对分段线性神经元做类似的处理

98
00:07:52,067 --> 00:07:59,015
我们可以说 分段函数的输出值
那个实数值

99
00:07:59,015 --> 00:08:04,014
如果大于0的话 就是产生信号的速率

100
00:08:04,014 --> 00:08:08,076
这是决定性的
但是如果我们把信号产生的速率

101
00:08:08,076 --> 00:08:13,016
即信号实际上产生了多少次
看成一个随机过程

102
00:08:13,016 --> 00:08:14,098
它其实就是泊松分布

103
00:08:14,098 --> 00:08:19,073
所以分段线性函数决定了信号产生的速率
而它内在的随机性

104
00:08:19,073 --> 00:08:22,089
则决定了这些信号什么时候产生 
 翻译 Pan Zhimeng