1
00:00:00,000 --> 00:00:05,009
Sada ćemo malo govoriti o
pitanju koje je prema naučnicima

2
00:00:05,009 --> 00:00:08,050
od velikog značaja, ali možda i 
ne znači toliko inženjerima.

3
00:00:08,050 --> 00:00:11,090
Ukoliko ste inženjer, možete 
slobodno da ignorišete ovaj video.

4
00:00:12,040 --> 00:00:18,058
U računarskim naukama već oko 100 
godina se vodi jedna debata o

5
00:00:18,058 --> 00:00:23,066
vezi između prikazivanja kocepata 
preko vektorske funkcije i

6
00:00:23,066 --> 00:00:28,050
prikazivanja koncepata preko njihove
veze sa drugim konceptima.

7
00:00:28,050 --> 00:00:34,069
I učeći algoritam koji smo upravo
videli za porodična stabla može reći

8
00:00:34,069 --> 00:00:38,072
dosta o toj debati.
Sada ćemo napraviti kratku diverziju

9
00:00:38,072 --> 00:00:43,024
u kognitivne nauke.
Vodila se duga debata između dve

10
00:00:43,024 --> 00:00:46,042
rivalne teorije o tome šta znači
imati koncept.

11
00:00:47,020 --> 00:00:52,006
Integraciona teorija kaže da je koncept
veliki skup semantičkih oznaka.

12
00:00:52,035 --> 00:00:56,012
To je dobro za objašnjenje sličnosti
između koncepata.

13
00:00:56,012 --> 00:00:59,057
I pogodno je za stvari kao 
što je mašinsko učenje.

14
00:00:59,057 --> 00:01:02,088
Zato što volimo da radimo sa
vektorima znakovnih aktivnosti.

15
00:01:02,088 --> 00:01:07,056
Strukturalna teorija kaže da
značenje koncepta leži u njegovoj

16
00:01:07,056 --> 00:01:13,026
vezi sa drugim konceptima.
Znači konceptualno znanje je najbolje izraženo

17
00:01:13,026 --> 00:01:16,051
ne kao veliki vektor, već kao relacioni graf.

18
00:01:16,051 --> 00:01:22,044
Ranih 70tih, Marvin Minski je iskoristio
ograničenost perceptrona kao dokaz

19
00:01:22,044 --> 00:01:27,056
protiv funkcijskih aktora u korist
reprezentacije relacionim grafom.

20
00:01:27,056 --> 00:01:32,044
Ja lično verujem da su obe strane u ovoj
debati pogrešne, zato što obe strane

21
00:01:32,044 --> 00:01:37,020
veruju da su ove dve teorije rivali
a one nisu rivali uopšte.

22
00:01:37,020 --> 00:01:42,069
Neuronska mreža može da koristi vektor
semantičkih funkcija da implementira relacioni graf.

23
00:01:42,069 --> 00:01:48,018
U neuronskoj mreži koja uči porodično
stablo, možemo smisliti konkretnu inferencu

24
00:01:48,018 --> 00:01:53,073
kada Vam ja zadam osobu jedan i dam vam
vezu, onda mi Vi kažete osobu dva.

25
00:01:54,012 --> 00:01:59,073
A da dođe do tog zaključka, 
neuronska mreža ne prati gomilu

26
00:01:59,073 --> 00:02:04,007
pravila o inferencama. 
Ona samo predaje informaciju dalje kroz

27
00:02:04,007 --> 00:02:09,009
samu mrežu.
Dokle god je neuronska mreža u pitanju,

28
00:02:09,009 --> 00:02:14,035
odgovor je intuitivno očigledan.
Sada ako pogledamo detalje o tome

29
00:02:14,035 --> 00:02:19,040
šta se dešava, postoji mnogo funkcija
verovatnoće koje utiču jedna na drugu.

30
00:02:19,040 --> 00:02:24,007
Pozivamo te mikrofunkcije da 
uveličaju to da nisu eksplicitne

31
00:02:24,007 --> 00:02:28,059
kao svesne funkcije. 
U pravom mozgu, mogu postojati milioni

32
00:02:28,059 --> 00:02:34,025
njih i milioni interakcija, i
kao rezultat svih tih interakcija

33
00:02:34,025 --> 00:02:39,091
možemo napraviti jedan korak eksplicitne interference.
I to je ono što mislimo da je uključeno

34
00:02:39,091 --> 00:02:45,022
u viđenje samo jednog odgovora na nešto.
Ne postoje svesni koraci koji se mešaju,

35
00:02:45,022 --> 00:02:50,040
ali ipak postoji mnogo 
računanja koje se dešava u interakcijama

36
00:02:50,040 --> 00:02:55,044
sa neuronima. 
Tako da možemo koristiti eksplicitna pravila za svesno

37
00:02:55,044 --> 00:03:00,045
konkretno razumevanje, ali veliki deo
našeg zdravorazumnog razmišljanja,

38
00:03:00,045 --> 00:03:06,007
naročito analitičko razmišljanje, funkcioniše
tako što samo vidimo odgovor, bez nekih

39
00:03:06,007 --> 00:03:09,018
svesnih koraka. A čak i kad svesno razmišljamo

40
00:03:09,018 --> 00:03:14,052
imamo nekako jednostavno znamo 
koja pravila da primenimo, da bismo izbegli

41
00:03:14,052 --> 00:03:19,077
beskonačnu regresiju. Tako da, 
mnogi ljudi, kada razmišljaju o tome

42
00:03:19,077 --> 00:03:25,009
da li da primene relacioni graf u
neuronskim mrežama, jednostavno predpostave

43
00:03:25,009 --> 00:03:30,096
da bi trebalo da učine da neuron odgovara čvoru u 
relacionom grafu, a konekcija između,

44
00:03:30,096 --> 00:03:34,033
dva neurona odgovara binarnoj vezi.

45
00:03:34,033 --> 00:03:39,026
Ali ova metoda ne radi. 
Za početak, postoji veliki

46
00:03:39,026 --> 00:03:42,047
broj različitih veza. One dolaze u različitim

47
00:03:42,047 --> 00:03:45,347
oblicima. Kao na primer,
nečija majka, ili nečija tetka,

48
00:03:45,347 --> 00:03:48,050
i veza u neuronskoj mreži ima samo snagu.

49
00:03:48,050 --> 00:03:54,087
Ona ne dolazi u različitim oblicima.
Takođe treba da okrenemo te veze

50
00:03:54,087 --> 00:03:57,074
na primer, "a" je između "b" i "c".

51
00:03:58,034 --> 00:04:03,080
Još uvek ne znamo pravi način
da implementiramo relaciono znanje u

52
00:04:03,080 --> 00:04:07,060
neuronsku mrežu. 
Ali čini se jako moguće da

53
00:04:07,060 --> 00:04:13,042
su mnogi neuroni korišćeni u prikazivanju svakog od
koncepata koje znamo, i da svaki

54
00:04:13,042 --> 00:04:18,039
od tih neurona verovatno učestvuje u 
kreiranju velikog broja različitih koncepata.

55
00:04:18,039 --> 00:04:21,056
To se zove distribuirana
reprezentacija.

56
00:04:22,013 --> 00:04:26,043
To je mnogo na mnogo mapiranje između
koncepata i neurona.