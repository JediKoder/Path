Nous allons maintenant parler d'un problème qui intéresse les chercheurs en sciences cognitives, mais peut etre moins les ingénieurs Alors si vous êtes un ingénieur, vous pouver ignorer cetter vidéo. En science cognitives, il y a un débat qui dure bientôt depuis 100 ans, à propos de la relation entre la représentation de concepts
sous forme de vecteurs de caractéristiques et la representation de concepts de par leur relations avec d'autres concepts. et le précédent algorithme d'apprentissage que nous
avons vu pour les arbres généalogiques informe beaucoup ce débat. Nous allons maintenant entreprendre une courte diversion, en science cognitives. Il y a un long débat entre deux théories rivales, sur ce qu'avoir un concept signifie. La théorie des caractéristiques définit un concept comme étant un large ensemble de caractéristiques sémantiques. Cela est bien lorsque l'on veut expliquer les similarités entres concepts et est pratique pour des domaines tel l'apprentissage par machines parce qu'on aime bien travailler avec des vecteurs d'activités. La théorie structurelle dit que le sens d'un concept trouve dans sa relation avec d'autres concepts. Le savoir conceptuelle s'exprime bien mieux non pas comme un large vecteur, mais comme un graphe de relation. Dans le début des années 1970, Marvin Minsky utilise les limites des perceptrons comme evidence contre la théorie des vecteurs caractéristiques, en faveur des représentations de graphe relationnel Mon opinion est que les deux camps de ce debats sont erronées parce que les deux jugent leurs théories comme étant rivales alors qu'elles ne le sont vraiment pas. Un réseau neuronal peut utiliser des vecteurs de caractéristiques
sémantiques pour implémenter un graphe relationnel. Concernant le réseau de neurones qui apprend les arbres généalogiques, on peut comprendre comme inférence explicite lorsque je vous donne une personne 1, vous me donnez une
personne 2 et je vous dis quelle relation elles ont entre elles. Et pour arriver à cette conclusion, le réseau ne suit pas
un paquet de règles d'inférence, Il se contente de passer au suivants de l'information à travers le réseau Quant au réseau, la réponse est évidente intuitivement. Maintenant si vous vous intéressez aux détails de ce qui se passe, il y a beaucoup de caractéristiques probabilistes qui s'influencent entre elles. On les appellent "micro-caractéristiques" afin d'accentuer
le fait qu'elles ne sont pas comme des caractéristiques explicites et conscientes. Dans un vrai cerveau, il y en aurait des millions et des millions d'interactions et en tant que résultat de toutes ces interactions, on peut faire un pas d'inférence explicite. Et c'est ce que nous pensons se produit lorsqu'on réalise la réponse à quelque chose.
Il n'y a pas d'étapes conscientes intermédiaires, Et pourtant il y a beaucoup de calculs qui se produisent
dans ces interactions entre neurones. Donc, on peut utiliser des règles explicites du raisonnement conscient et délibéré mais la plupart de nos raisonnements de bon sens, particulièrement les raisonnements analogiques s'opèrent par réalisation de la réponse,
sans aucune étape intermédiaire consciente. Et même quand on opère des raisonnements conscients, il nous faut un moyen pour réaliser quelle règle s'applique,
afin d'éviter de tourner en rond Donc, beaucoup de gens, lorsqu'ils imaginent
l'implémentation d'un graphe relationnel par un réseau de neurones, se figurent qu'il faille faire correspondre un neurone à un noeud du graphe relationnel et à une connection entre deux neurones une relation binaire. Mais cette méthode ne marche pas. D'abord, les relations se déclinent en modes variés.
Il y plusieurs genres de relations comme "mère de" ou "tante de" et la connection dans un réseau de neurone n'a qu'une intensité. Elle n'a pas plusieurs genres. En plus, il faut nous préoccuper des relations ternaires comme "a" est entre "b" et "c". On ne sait pas encore bien comment implémenter l'information sur les relations avec un réseau de neurones. Mais il est fort probable que beaucoup de neurones sont utilisés pour
représenter chacun des concepts que l'on connaît. Et chacun de ces neurones participe probablement à
beaucoup de concepts différents. Cela s'appelle une représentation distribuée. C'est une correspondance de beaucoup à beaucoup entre concepts et neurones.