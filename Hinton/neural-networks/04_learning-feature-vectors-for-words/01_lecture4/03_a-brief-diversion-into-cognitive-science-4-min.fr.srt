1
00:00:00,000 --> 00:00:05,009
Nous allons maintenant parler d'un problème qui intéresse 

2
00:00:05,009 --> 00:00:08,050
les chercheurs en sciences cognitives, mais peut etre moins les ingénieurs

3
00:00:08,050 --> 00:00:11,090
Alors si vous êtes un ingénieur, vous pouver ignorer cetter vidéo.

4
00:00:12,040 --> 00:00:18,058
En science cognitives, il y a un débat qui dure bientôt depuis 100 ans,

5
00:00:18,058 --> 00:00:23,066
à propos de la relation entre la représentation de concepts
sous forme de vecteurs de caractéristiques

6
00:00:23,066 --> 00:00:28,050
et la representation de concepts de par leur relations avec d'autres concepts.

7
00:00:28,050 --> 00:00:34,069
et le précédent algorithme d'apprentissage que nous
avons vu pour les arbres généalogiques

8
00:00:34,069 --> 00:00:38,072
informe beaucoup ce débat. Nous allons maintenant entreprendre une courte diversion,

9
00:00:38,072 --> 00:00:43,024
en science cognitives. Il y a un long débat entre deux

10
00:00:43,024 --> 00:00:46,042
théories rivales, sur ce qu'avoir un concept signifie.

11
00:00:47,020 --> 00:00:52,006
La théorie des caractéristiques définit un concept comme étant un large ensemble de caractéristiques sémantiques.

12
00:00:52,035 --> 00:00:56,012
Cela est bien lorsque l'on veut expliquer les similarités entres concepts

13
00:00:56,012 --> 00:00:59,057
et est pratique pour des domaines tel l'apprentissage par machines

14
00:00:59,057 --> 00:01:02,088
parce qu'on aime bien travailler avec des vecteurs d'activités.

15
00:01:02,088 --> 00:01:07,056
La théorie structurelle dit que le sens d'un concept trouve dans 

16
00:01:07,056 --> 00:01:13,026
sa relation avec d'autres concepts. Le savoir conceptuelle s'exprime bien mieux

17
00:01:13,026 --> 00:01:16,051
non pas comme un large vecteur, mais comme un graphe de relation. 

18
00:01:16,051 --> 00:01:22,044
Dans le début des années 1970, Marvin Minsky utilise les limites des perceptrons comme evidence

19
00:01:22,044 --> 00:01:27,056
contre la théorie des vecteurs caractéristiques, en faveur des représentations de graphe relationnel

20
00:01:27,056 --> 00:01:32,044
Mon opinion est que les deux camps de ce debats sont erronées parce que les deux 

21
00:01:32,044 --> 00:01:37,020
jugent leurs théories comme étant rivales alors qu'elles ne le sont vraiment pas.

22
00:01:37,020 --> 00:01:42,069
Un réseau neuronal peut utiliser des vecteurs de caractéristiques
sémantiques pour implémenter un graphe relationnel.

23
00:01:42,069 --> 00:01:48,018
Concernant le réseau de neurones qui apprend les arbres généalogiques, on peut comprendre comme inférence explicite

24
00:01:48,018 --> 00:01:53,073
lorsque je vous donne une personne 1, vous me donnez une
personne 2 et je vous dis quelle relation elles ont entre elles.

25
00:01:54,012 --> 00:01:59,073
Et pour arriver à cette conclusion, le réseau ne suit pas
un paquet de règles d'inférence, 

26
00:01:59,073 --> 00:02:04,007
Il se contente de passer au suivants de l'information à travers le réseau

27
00:02:04,007 --> 00:02:09,009
Quant au réseau, la réponse est évidente intuitivement. 

28
00:02:09,009 --> 00:02:14,035
Maintenant si vous vous intéressez aux détails de ce qui se passe, 

29
00:02:14,035 --> 00:02:19,040
il y a beaucoup de caractéristiques probabilistes qui s'influencent entre elles.

30
00:02:19,040 --> 00:02:24,007
On les appellent "micro-caractéristiques" afin d'accentuer
le fait qu'elles ne sont pas comme des caractéristiques explicites

31
00:02:24,007 --> 00:02:28,059
et conscientes. Dans un vrai cerveau, il y en aurait des millions 

32
00:02:28,059 --> 00:02:34,025
et des millions d'interactions et en tant que résultat de toutes ces interactions,

33
00:02:34,025 --> 00:02:39,091
on peut faire un pas d'inférence explicite. Et c'est ce que nous pensons se produit

34
00:02:39,091 --> 00:02:45,022
lorsqu'on réalise la réponse à quelque chose.
Il n'y a pas d'étapes conscientes intermédiaires,

35
00:02:45,022 --> 00:02:50,040
Et pourtant il y a beaucoup de calculs qui se produisent
dans ces interactions entre neurones.

36
00:02:50,040 --> 00:02:55,044
Donc, on peut utiliser des règles explicites du raisonnement conscient et délibéré

37
00:02:55,044 --> 00:03:00,045
mais la plupart de nos raisonnements de bon sens, particulièrement

38
00:03:00,045 --> 00:03:06,007
les raisonnements analogiques s'opèrent par réalisation de la réponse,
sans aucune étape intermédiaire consciente.

39
00:03:06,007 --> 00:03:09,018
Et même quand on opère des raisonnements conscients,

40
00:03:09,018 --> 00:03:14,052
il nous faut un moyen pour réaliser quelle règle s'applique,
afin d'éviter de tourner en rond

41
00:03:14,052 --> 00:03:19,077
Donc, beaucoup de gens, lorsqu'ils imaginent
l'implémentation d'un graphe relationnel

42
00:03:19,077 --> 00:03:25,009
par un réseau de neurones, se figurent qu'il faille faire correspondre un neurone 

43
00:03:25,009 --> 00:03:30,096
à un noeud du graphe relationnel et à une connection entre deux neurones

44
00:03:30,096 --> 00:03:34,033
une relation binaire.

45
00:03:34,033 --> 00:03:39,026
Mais cette méthode ne marche pas. 

46
00:03:39,026 --> 00:03:42,047
D'abord, les relations se déclinent en modes variés.
Il y plusieurs genres de relations

47
00:03:42,047 --> 00:03:45,347
comme "mère de" ou "tante de"

48
00:03:45,347 --> 00:03:48,050
et la connection dans un réseau de neurone n'a qu'une intensité.

49
00:03:48,050 --> 00:03:54,087
Elle n'a pas plusieurs genres. 

50
00:03:54,087 --> 00:03:57,074
En plus, il faut nous préoccuper des relations ternaires comme "a" est entre "b" et "c".

51
00:03:58,034 --> 00:04:03,080
On ne sait pas encore bien comment implémenter l'information sur les relations

52
00:04:03,080 --> 00:04:07,060
avec un réseau de neurones. Mais il est fort probable

53
00:04:07,060 --> 00:04:13,042
que beaucoup de neurones sont utilisés pour
représenter chacun des concepts que l'on connaît. 

54
00:04:13,042 --> 00:04:18,039
Et chacun de ces neurones participe probablement à
beaucoup de concepts différents.

55
00:04:18,039 --> 00:04:21,056
Cela s'appelle une représentation distribuée.

56
00:04:22,013 --> 00:04:26,043
C'est une correspondance de beaucoup à beaucoup entre concepts et neurones.